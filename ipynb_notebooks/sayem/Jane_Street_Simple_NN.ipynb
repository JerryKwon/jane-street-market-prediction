{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Jane-Street-Simple NN.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "svcGMnzM4PcL"
      },
      "source": [
        "from google.colab import files\r\n",
        "\r\n",
        "uploaded = files.upload()\r\n",
        "\r\n",
        "for fn in uploaded.keys():\r\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\r\n",
        "      name=fn, length=len(uploaded[fn])))\r\n",
        "  \r\n",
        "# Then move kaggle.json into the folder where the API expects to find it.\r\n",
        "!mkdir -p ~/.kaggle/ && mv kaggle.json ~/.kaggle/ && chmod 600 ~/.kaggle/kaggle.json"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rFPB6bPG4cFb",
        "outputId": "d5c6f4de-83f6-483a-bfe7-f58f41fa336e"
      },
      "source": [
        "!kaggle competitions download -c jane-street-market-prediction"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Warning: Looks like you're using an outdated API Version, please consider updating (server 1.5.10 / client 1.5.4)\n",
            "competition.cpython-37m-x86_64-linux-gnu.so: Skipping, found more recently modified local copy (use --force to force download)\n",
            "__init__.py: Skipping, found more recently modified local copy (use --force to force download)\n",
            "example_test.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "train.csv.zip: Skipping, found more recently modified local copy (use --force to force download)\n",
            "example_sample_submission.csv: Skipping, found more recently modified local copy (use --force to force download)\n",
            "features.csv: Skipping, found more recently modified local copy (use --force to force download)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "f0PtJ9lF4gel",
        "outputId": "97aea3b1-9296-4725-efd0-eb75b4b91108"
      },
      "source": [
        "!unzip train.csv.zip"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Archive:  train.csv.zip\n",
            "replace train.csv? [y]es, [n]o, [A]ll, [N]one, [r]ename: n\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ACO51zRO41iE"
      },
      "source": [
        "\"\"\"\r\n",
        "Reduce Memory Usage by 75%\r\n",
        "https://www.kaggle.com/tomwarrens/nan-values-depending-on-time-of-day\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "## Reduce Memory\r\n",
        "\r\n",
        "def reduce_memory_usage(df):\r\n",
        "    \r\n",
        "    start_memory = df.memory_usage().sum() / 1024**2\r\n",
        "    print(f\"Memory usage of dataframe is {start_memory} MB\")\r\n",
        "    \r\n",
        "    for col in df.columns:\r\n",
        "        col_type = df[col].dtype\r\n",
        "        \r\n",
        "        if col_type != 'object':\r\n",
        "            c_min = df[col].min()\r\n",
        "            c_max = df[col].max()\r\n",
        "            \r\n",
        "            if str(col_type)[:3] == 'int':\r\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\r\n",
        "                    df[col] = df[col].astype(np.int8)\r\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\r\n",
        "                    df[col] = df[col].astype(np.int16)\r\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\r\n",
        "                    df[col] = df[col].astype(np.int32)\r\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\r\n",
        "                    df[col] = df[col].astype(np.int64)\r\n",
        "            \r\n",
        "            else:\r\n",
        "#                 reducing float16 for calculating numpy.nanmean\r\n",
        "#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\r\n",
        "#                     df[col] = df[col].astype(np.float16)\r\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\r\n",
        "                    df[col] = df[col].astype(np.float32)\r\n",
        "                else:\r\n",
        "                    pass\r\n",
        "        else:\r\n",
        "            df[col] = df[col].astype('category')\r\n",
        "    \r\n",
        "    end_memory = df.memory_usage().sum() / 1024**2\r\n",
        "    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\r\n",
        "    print(f\"Reduced by {100 * (start_memory - end_memory) / start_memory} % \")\r\n",
        "    return df\r\n",
        "\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WeAwzmIt5gI0",
        "outputId": "8fe70c8b-2c28-4615-da40-a08af3977efc"
      },
      "source": [
        "!pip install keras-tuner"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting keras-tuner\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/20/ec/1ef246787174b1e2bb591c95f29d3c1310070cad877824f907faba3dade9/keras-tuner-1.0.2.tar.gz (62kB)\n",
            "\r\u001b[K     |█████▏                          | 10kB 24.8MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 20kB 31.8MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 30kB 24.5MB/s eta 0:00:01\r\u001b[K     |████████████████████▉           | 40kB 21.8MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 51kB 22.6MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▎| 61kB 16.6MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 71kB 8.7MB/s \n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (20.8)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.16.0)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.19.5)\n",
            "Requirement already satisfied: tabulate in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.8.7)\n",
            "Collecting terminaltables\n",
            "  Downloading https://files.pythonhosted.org/packages/9b/c4/4a21174f32f8a7e1104798c445dacdc1d4df86f2f26722767034e4de4bff/terminaltables-3.1.0.tar.gz\n",
            "Collecting colorama\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (4.41.1)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (2.23.0)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (1.4.1)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.6/dist-packages (from keras-tuner) (0.22.2.post1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging->keras-tuner) (2.4.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2020.12.5)\n",
            "Requirement already satisfied: chardet<4,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (3.0.4)\n",
            "Requirement already satisfied: urllib3!=1.25.0,!=1.25.1,<1.26,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (1.24.3)\n",
            "Requirement already satisfied: idna<3,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests->keras-tuner) (2.10)\n",
            "Requirement already satisfied: joblib>=0.11 in /usr/local/lib/python3.6/dist-packages (from scikit-learn->keras-tuner) (1.0.0)\n",
            "Building wheels for collected packages: keras-tuner, terminaltables\n",
            "  Building wheel for keras-tuner (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for keras-tuner: filename=keras_tuner-1.0.2-cp36-none-any.whl size=78939 sha256=14f9483f440a81e375a7ffb58629431ff4156b913b0382606ef1d1b54131f65b\n",
            "  Stored in directory: /root/.cache/pip/wheels/bb/a1/8a/7c3de0efb3707a1701b36ebbfdbc4e67aedf6d4943a1f463d6\n",
            "  Building wheel for terminaltables (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for terminaltables: filename=terminaltables-3.1.0-cp36-none-any.whl size=15358 sha256=2e70bda9ad2dbfd57ee6269daa74c6a480c5bf152370a8e3090946c8f417381d\n",
            "  Stored in directory: /root/.cache/pip/wheels/30/6b/50/6c75775b681fb36cdfac7f19799888ef9d8813aff9e379663e\n",
            "Successfully built keras-tuner terminaltables\n",
            "Installing collected packages: terminaltables, colorama, keras-tuner\n",
            "Successfully installed colorama-0.4.4 keras-tuner-1.0.2 terminaltables-3.1.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T-ikT0g75l2D"
      },
      "source": [
        "import tensorflow as tf\r\n",
        "import keras\r\n",
        "from tensorflow.keras.layers import Input, Dense, BatchNormalization, Dropout, Concatenate, Lambda, GaussianNoise, Activation\r\n",
        "from tensorflow.keras.models import Model, Sequential\r\n",
        "from tensorflow.keras.losses import BinaryCrossentropy\r\n",
        "from tensorflow.keras.optimizers import Adam\r\n",
        "from tensorflow.keras.callbacks import EarlyStopping\r\n",
        "from tensorflow.keras.layers.experimental.preprocessing import Normalization\r\n",
        "import kerastuner as kt\r\n",
        "from keras import layers\r\n",
        "import tensorflow_addons as tfa\r\n",
        "\r\n",
        "from kerastuner.tuners import RandomSearch, Hyperband\r\n",
        "from tensorflow.keras.callbacks import Callback, ReduceLROnPlateau, ModelCheckpoint, EarlyStopping\r\n",
        "from keras.wrappers.scikit_learn import KerasClassifier\r\n",
        "from sklearn.model_selection import GridSearchCV\r\n",
        "\r\n",
        "from sklearn.model_selection import GroupKFold\r\n",
        "from sklearn.model_selection import KFold\r\n",
        "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\r\n",
        "from sklearn.utils.validation import _deprecate_positional_args\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "from random import choices\r\n",
        "from tqdm import tqdm\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "\r\n",
        "# import janestreet"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1dc5Dh-r72WR",
        "outputId": "56a575ed-69cd-46f5-a6b6-3c07eae1a07f"
      },
      "source": [
        "# Check GPU\r\n",
        "!nvidia-smi"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Wed Feb  3 19:11:31 2021       \n",
            "+-----------------------------------------------------------------------------+\n",
            "| NVIDIA-SMI 460.39       Driver Version: 418.67       CUDA Version: 10.1     |\n",
            "|-------------------------------+----------------------+----------------------+\n",
            "| GPU  Name        Persistence-M| Bus-Id        Disp.A | Volatile Uncorr. ECC |\n",
            "| Fan  Temp  Perf  Pwr:Usage/Cap|         Memory-Usage | GPU-Util  Compute M. |\n",
            "|                               |                      |               MIG M. |\n",
            "|===============================+======================+======================|\n",
            "|   0  Tesla T4            Off  | 00000000:00:04.0 Off |                    0 |\n",
            "| N/A   50C    P8    10W /  70W |      0MiB / 15079MiB |      0%      Default |\n",
            "|                               |                      |                 ERR! |\n",
            "+-------------------------------+----------------------+----------------------+\n",
            "                                                                               \n",
            "+-----------------------------------------------------------------------------+\n",
            "| Processes:                                                                  |\n",
            "|  GPU   GI   CI        PID   Type   Process name                  GPU Memory |\n",
            "|        ID   ID                                                   Usage      |\n",
            "|=============================================================================|\n",
            "|  No running processes found                                                 |\n",
            "+-----------------------------------------------------------------------------+\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3WZmKtOD7iYU"
      },
      "source": [
        "# import pynvml\r\n",
        "\r\n",
        "# pynvml.nvmlInit()\r\n",
        "# handle = pynvml.nvmlDeviceGetHandleByIndex(0)\r\n",
        "# device_name = pynvml.nvmlDeviceGetName(handle)\r\n",
        "\r\n",
        "# if device_name != b'Tesla T4':\r\n",
        "#   raise Exception(\"\"\"\r\n",
        "#     Unfortunately this instance does not have a T4 GPU.\r\n",
        "    \r\n",
        "#     Please make sure you've configured Colab to request a GPU instance type.\r\n",
        "    \r\n",
        "#     Sometimes Colab allocates a Tesla K80 instead of a T4. Resetting the instance.\r\n",
        "\r\n",
        "#     If you get a K80 GPU, try Runtime -> Reset all runtimes...\r\n",
        "#   \"\"\")\r\n",
        "# else:\r\n",
        "#   print('Woo! You got the right kind of GPU!')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "q1EmITUV8NDd"
      },
      "source": [
        "# # Install RAPIDS\r\n",
        "# !git clone https://github.com/rapidsai/rapidsai-csp-utils.git\r\n",
        "# !bash rapidsai-csp-utils/colab/rapids-colab.sh\r\n",
        "\r\n",
        "# import sys, os\r\n",
        "\r\n",
        "# dist_package_index = sys.path.index('/usr/local/lib/python3.6/dist-packages')\r\n",
        "# sys.path = sys.path[:dist_package_index] + ['/usr/local/lib/python3.6/site-packages'] + sys.path[dist_package_index:]\r\n",
        "# sys.path\r\n",
        "# exec(open('rapidsai-csp-utils/colab/update_modules.py').read(), globals())\r\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BY8RhgaD8NKh"
      },
      "source": [
        "# import cudf"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "J0DcAcHC8NNY"
      },
      "source": [
        "# %%time\r\n",
        "\r\n",
        "# train = cudf.read_csv('train.csv')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ylG-b7IvDpZH",
        "outputId": "56ce381a-d9bf-4b54-e6f7-347c9f5c362f"
      },
      "source": [
        "# def reduce_memory_usage(df):\r\n",
        "train = pd.read_csv('train.csv')\r\n",
        "train = reduce_memory_usage(train)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2516.843978881836 MB\n",
            "Memory usage of dataframe after reduction 1247.0233011245728 MB\n",
            "Reduced by 50.45289610369131 % \n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "f2030XRDEBGj"
      },
      "source": [
        "train.fillna(train.mean(),inplace=True)\r\n",
        "train = train.query('weight > 0').reset_index(drop = True)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TNOd-IvAEn6q"
      },
      "source": [
        "train['action'] =  (  (train['resp_1'] > 0.00001 ) & (train['resp_2'] > 0.00001 ) & (train['resp_3'] > 0.00001 ) & (train['resp_4'] > 0.00001 ) &  (train['resp'] * train['weight'] > 0.001 )).astype('int')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "khYNMuYmFjbq"
      },
      "source": [
        "def lower_sample_data(df, percent=1):\r\n",
        "    data1 = df[df['action'] == 1]\r\n",
        "    data0 = df[df['action'] == 0]\r\n",
        "    index = np.random.randint(len(data0), size=percent * (len(df) - len(data0))) #randomly pick the sample with action=0\r\n",
        "    lower_data0 = data0.iloc[list(index)]\r\n",
        "    return(pd.concat([lower_data0, data1]))\r\n",
        "\r\n",
        "train = lower_sample_data(train)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 253
        },
        "id": "P3pvOCJRF8aZ",
        "outputId": "f837dabe-9c4e-42de-e779-81b92bd5107f"
      },
      "source": [
        "train.head()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>date</th>\n",
              "      <th>weight</th>\n",
              "      <th>resp_1</th>\n",
              "      <th>resp_2</th>\n",
              "      <th>resp_3</th>\n",
              "      <th>resp_4</th>\n",
              "      <th>resp</th>\n",
              "      <th>feature_0</th>\n",
              "      <th>feature_1</th>\n",
              "      <th>feature_2</th>\n",
              "      <th>feature_3</th>\n",
              "      <th>feature_4</th>\n",
              "      <th>feature_5</th>\n",
              "      <th>feature_6</th>\n",
              "      <th>feature_7</th>\n",
              "      <th>feature_8</th>\n",
              "      <th>feature_9</th>\n",
              "      <th>feature_10</th>\n",
              "      <th>feature_11</th>\n",
              "      <th>feature_12</th>\n",
              "      <th>feature_13</th>\n",
              "      <th>feature_14</th>\n",
              "      <th>feature_15</th>\n",
              "      <th>feature_16</th>\n",
              "      <th>feature_17</th>\n",
              "      <th>feature_18</th>\n",
              "      <th>feature_19</th>\n",
              "      <th>feature_20</th>\n",
              "      <th>feature_21</th>\n",
              "      <th>feature_22</th>\n",
              "      <th>feature_23</th>\n",
              "      <th>feature_24</th>\n",
              "      <th>feature_25</th>\n",
              "      <th>feature_26</th>\n",
              "      <th>feature_27</th>\n",
              "      <th>feature_28</th>\n",
              "      <th>feature_29</th>\n",
              "      <th>feature_30</th>\n",
              "      <th>feature_31</th>\n",
              "      <th>feature_32</th>\n",
              "      <th>...</th>\n",
              "      <th>feature_92</th>\n",
              "      <th>feature_93</th>\n",
              "      <th>feature_94</th>\n",
              "      <th>feature_95</th>\n",
              "      <th>feature_96</th>\n",
              "      <th>feature_97</th>\n",
              "      <th>feature_98</th>\n",
              "      <th>feature_99</th>\n",
              "      <th>feature_100</th>\n",
              "      <th>feature_101</th>\n",
              "      <th>feature_102</th>\n",
              "      <th>feature_103</th>\n",
              "      <th>feature_104</th>\n",
              "      <th>feature_105</th>\n",
              "      <th>feature_106</th>\n",
              "      <th>feature_107</th>\n",
              "      <th>feature_108</th>\n",
              "      <th>feature_109</th>\n",
              "      <th>feature_110</th>\n",
              "      <th>feature_111</th>\n",
              "      <th>feature_112</th>\n",
              "      <th>feature_113</th>\n",
              "      <th>feature_114</th>\n",
              "      <th>feature_115</th>\n",
              "      <th>feature_116</th>\n",
              "      <th>feature_117</th>\n",
              "      <th>feature_118</th>\n",
              "      <th>feature_119</th>\n",
              "      <th>feature_120</th>\n",
              "      <th>feature_121</th>\n",
              "      <th>feature_122</th>\n",
              "      <th>feature_123</th>\n",
              "      <th>feature_124</th>\n",
              "      <th>feature_125</th>\n",
              "      <th>feature_126</th>\n",
              "      <th>feature_127</th>\n",
              "      <th>feature_128</th>\n",
              "      <th>feature_129</th>\n",
              "      <th>ts_id</th>\n",
              "      <th>action</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>865316</th>\n",
              "      <td>228</td>\n",
              "      <td>0.485024</td>\n",
              "      <td>0.006512</td>\n",
              "      <td>0.000428</td>\n",
              "      <td>-0.006964</td>\n",
              "      <td>-0.012145</td>\n",
              "      <td>-0.011132</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.067063</td>\n",
              "      <td>1.758998</td>\n",
              "      <td>-0.946981</td>\n",
              "      <td>-1.056832</td>\n",
              "      <td>-1.151208</td>\n",
              "      <td>-1.385745</td>\n",
              "      <td>0.051773</td>\n",
              "      <td>0.026825</td>\n",
              "      <td>-0.278389</td>\n",
              "      <td>0.131507</td>\n",
              "      <td>-1.997445</td>\n",
              "      <td>-3.748260</td>\n",
              "      <td>-3.732770</td>\n",
              "      <td>-3.817390</td>\n",
              "      <td>-1.031656</td>\n",
              "      <td>-1.300626</td>\n",
              "      <td>0.121220</td>\n",
              "      <td>0.113582</td>\n",
              "      <td>-0.972639</td>\n",
              "      <td>-1.588603</td>\n",
              "      <td>-4.080263</td>\n",
              "      <td>-3.410172</td>\n",
              "      <td>-3.324315</td>\n",
              "      <td>-5.063827</td>\n",
              "      <td>-1.214634</td>\n",
              "      <td>-1.836943</td>\n",
              "      <td>0.135482</td>\n",
              "      <td>0.160878</td>\n",
              "      <td>0.908344</td>\n",
              "      <td>1.557845</td>\n",
              "      <td>0.372436</td>\n",
              "      <td>0.703770</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.229309</td>\n",
              "      <td>-0.155368</td>\n",
              "      <td>-0.229395</td>\n",
              "      <td>-2.302408</td>\n",
              "      <td>0.402257</td>\n",
              "      <td>-1.338859</td>\n",
              "      <td>0.764688</td>\n",
              "      <td>0.856174</td>\n",
              "      <td>-1.194013</td>\n",
              "      <td>-1.198947</td>\n",
              "      <td>0.405025</td>\n",
              "      <td>-0.940190</td>\n",
              "      <td>0.109524</td>\n",
              "      <td>0.407665</td>\n",
              "      <td>-1.781693</td>\n",
              "      <td>-2.031842</td>\n",
              "      <td>0.399989</td>\n",
              "      <td>-0.902339</td>\n",
              "      <td>0.359242</td>\n",
              "      <td>0.483226</td>\n",
              "      <td>-1.289019</td>\n",
              "      <td>-1.840845</td>\n",
              "      <td>0.407116</td>\n",
              "      <td>-1.670158</td>\n",
              "      <td>-0.104203</td>\n",
              "      <td>0.149757</td>\n",
              "      <td>-2.056890</td>\n",
              "      <td>-1.555642</td>\n",
              "      <td>0.773427</td>\n",
              "      <td>2.109244</td>\n",
              "      <td>0.251341</td>\n",
              "      <td>0.383942</td>\n",
              "      <td>0.768659</td>\n",
              "      <td>2.323401</td>\n",
              "      <td>0.941635</td>\n",
              "      <td>1.463951</td>\n",
              "      <td>0.946444</td>\n",
              "      <td>1.395075</td>\n",
              "      <td>1078076</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>893211</th>\n",
              "      <td>235</td>\n",
              "      <td>2.176115</td>\n",
              "      <td>0.011735</td>\n",
              "      <td>0.009464</td>\n",
              "      <td>0.003452</td>\n",
              "      <td>-0.001319</td>\n",
              "      <td>0.003178</td>\n",
              "      <td>1</td>\n",
              "      <td>-0.114411</td>\n",
              "      <td>-0.717512</td>\n",
              "      <td>0.993715</td>\n",
              "      <td>0.656452</td>\n",
              "      <td>1.268570</td>\n",
              "      <td>0.929699</td>\n",
              "      <td>0.051773</td>\n",
              "      <td>0.026825</td>\n",
              "      <td>-0.099017</td>\n",
              "      <td>-0.502824</td>\n",
              "      <td>0.089116</td>\n",
              "      <td>0.049479</td>\n",
              "      <td>1.027177</td>\n",
              "      <td>0.426471</td>\n",
              "      <td>0.191417</td>\n",
              "      <td>-0.334537</td>\n",
              "      <td>0.121220</td>\n",
              "      <td>0.113582</td>\n",
              "      <td>1.340595</td>\n",
              "      <td>1.173040</td>\n",
              "      <td>0.186911</td>\n",
              "      <td>0.176981</td>\n",
              "      <td>1.995923</td>\n",
              "      <td>1.967844</td>\n",
              "      <td>1.761728</td>\n",
              "      <td>1.503628</td>\n",
              "      <td>0.135482</td>\n",
              "      <td>0.160878</td>\n",
              "      <td>-1.087858</td>\n",
              "      <td>-1.174936</td>\n",
              "      <td>0.220559</td>\n",
              "      <td>0.250122</td>\n",
              "      <td>...</td>\n",
              "      <td>0.404779</td>\n",
              "      <td>0.863946</td>\n",
              "      <td>-0.302553</td>\n",
              "      <td>-1.948853</td>\n",
              "      <td>0.402257</td>\n",
              "      <td>0.788332</td>\n",
              "      <td>0.406779</td>\n",
              "      <td>0.372027</td>\n",
              "      <td>0.425962</td>\n",
              "      <td>-1.695694</td>\n",
              "      <td>0.405025</td>\n",
              "      <td>1.999594</td>\n",
              "      <td>0.402193</td>\n",
              "      <td>1.764927</td>\n",
              "      <td>2.226700</td>\n",
              "      <td>-1.490595</td>\n",
              "      <td>0.399989</td>\n",
              "      <td>-0.623777</td>\n",
              "      <td>0.400732</td>\n",
              "      <td>0.002031</td>\n",
              "      <td>-0.699650</td>\n",
              "      <td>-2.677060</td>\n",
              "      <td>0.407116</td>\n",
              "      <td>1.130506</td>\n",
              "      <td>0.404427</td>\n",
              "      <td>1.860816</td>\n",
              "      <td>1.029689</td>\n",
              "      <td>-1.229184</td>\n",
              "      <td>0.335134</td>\n",
              "      <td>0.268782</td>\n",
              "      <td>-0.409049</td>\n",
              "      <td>0.356614</td>\n",
              "      <td>-0.345410</td>\n",
              "      <td>0.679605</td>\n",
              "      <td>-0.511296</td>\n",
              "      <td>0.452887</td>\n",
              "      <td>-0.373402</td>\n",
              "      <td>0.504219</td>\n",
              "      <td>1111263</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1055679</th>\n",
              "      <td>278</td>\n",
              "      <td>0.181485</td>\n",
              "      <td>-0.002526</td>\n",
              "      <td>-0.000264</td>\n",
              "      <td>0.010809</td>\n",
              "      <td>0.025885</td>\n",
              "      <td>0.015172</td>\n",
              "      <td>1</td>\n",
              "      <td>-3.172026</td>\n",
              "      <td>-3.093182</td>\n",
              "      <td>0.405788</td>\n",
              "      <td>0.284262</td>\n",
              "      <td>-0.355784</td>\n",
              "      <td>-0.285833</td>\n",
              "      <td>0.051773</td>\n",
              "      <td>0.026825</td>\n",
              "      <td>-5.219111</td>\n",
              "      <td>-3.614536</td>\n",
              "      <td>3.137135</td>\n",
              "      <td>4.384707</td>\n",
              "      <td>5.083986</td>\n",
              "      <td>4.325328</td>\n",
              "      <td>-3.463443</td>\n",
              "      <td>-4.221748</td>\n",
              "      <td>0.121220</td>\n",
              "      <td>0.113582</td>\n",
              "      <td>0.426817</td>\n",
              "      <td>0.333303</td>\n",
              "      <td>5.340745</td>\n",
              "      <td>3.855617</td>\n",
              "      <td>5.346605</td>\n",
              "      <td>6.340704</td>\n",
              "      <td>0.448363</td>\n",
              "      <td>0.305265</td>\n",
              "      <td>0.135482</td>\n",
              "      <td>0.160878</td>\n",
              "      <td>-3.274225</td>\n",
              "      <td>-4.077749</td>\n",
              "      <td>-1.467694</td>\n",
              "      <td>-2.421895</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.986136</td>\n",
              "      <td>-0.304707</td>\n",
              "      <td>0.012932</td>\n",
              "      <td>-3.696177</td>\n",
              "      <td>0.402257</td>\n",
              "      <td>1.175231</td>\n",
              "      <td>1.156861</td>\n",
              "      <td>1.844782</td>\n",
              "      <td>0.635880</td>\n",
              "      <td>-1.739762</td>\n",
              "      <td>0.405025</td>\n",
              "      <td>0.283076</td>\n",
              "      <td>0.207415</td>\n",
              "      <td>1.053692</td>\n",
              "      <td>-0.052598</td>\n",
              "      <td>-3.013555</td>\n",
              "      <td>0.399989</td>\n",
              "      <td>0.866758</td>\n",
              "      <td>0.351278</td>\n",
              "      <td>1.091217</td>\n",
              "      <td>0.489977</td>\n",
              "      <td>-2.867470</td>\n",
              "      <td>0.407116</td>\n",
              "      <td>-0.012478</td>\n",
              "      <td>-0.344630</td>\n",
              "      <td>0.713313</td>\n",
              "      <td>-0.435405</td>\n",
              "      <td>-2.362762</td>\n",
              "      <td>21.775967</td>\n",
              "      <td>25.966114</td>\n",
              "      <td>3.187879</td>\n",
              "      <td>2.451068</td>\n",
              "      <td>5.031921</td>\n",
              "      <td>6.229637</td>\n",
              "      <td>6.216775</td>\n",
              "      <td>4.706024</td>\n",
              "      <td>3.991561</td>\n",
              "      <td>2.738759</td>\n",
              "      <td>1303265</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>400986</th>\n",
              "      <td>85</td>\n",
              "      <td>1.805121</td>\n",
              "      <td>-0.012062</td>\n",
              "      <td>-0.022928</td>\n",
              "      <td>-0.056298</td>\n",
              "      <td>-0.111667</td>\n",
              "      <td>-0.085250</td>\n",
              "      <td>-1</td>\n",
              "      <td>-1.010386</td>\n",
              "      <td>-1.749416</td>\n",
              "      <td>-0.716776</td>\n",
              "      <td>-0.421528</td>\n",
              "      <td>-1.300052</td>\n",
              "      <td>-0.820254</td>\n",
              "      <td>0.051773</td>\n",
              "      <td>0.026825</td>\n",
              "      <td>0.840923</td>\n",
              "      <td>-0.144863</td>\n",
              "      <td>0.365274</td>\n",
              "      <td>-0.021438</td>\n",
              "      <td>1.317865</td>\n",
              "      <td>0.385957</td>\n",
              "      <td>1.137982</td>\n",
              "      <td>0.411316</td>\n",
              "      <td>0.121220</td>\n",
              "      <td>0.113582</td>\n",
              "      <td>-1.320409</td>\n",
              "      <td>-1.220728</td>\n",
              "      <td>-4.687186</td>\n",
              "      <td>-2.463820</td>\n",
              "      <td>-1.340741</td>\n",
              "      <td>-1.251441</td>\n",
              "      <td>-1.655838</td>\n",
              "      <td>-1.397531</td>\n",
              "      <td>0.135482</td>\n",
              "      <td>0.160878</td>\n",
              "      <td>2.008292</td>\n",
              "      <td>1.617754</td>\n",
              "      <td>1.587884</td>\n",
              "      <td>1.684338</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.319131</td>\n",
              "      <td>-0.429792</td>\n",
              "      <td>0.305721</td>\n",
              "      <td>-2.446978</td>\n",
              "      <td>0.463773</td>\n",
              "      <td>-1.338859</td>\n",
              "      <td>0.345776</td>\n",
              "      <td>-1.257774</td>\n",
              "      <td>-1.194013</td>\n",
              "      <td>-1.380657</td>\n",
              "      <td>-0.448610</td>\n",
              "      <td>-0.940190</td>\n",
              "      <td>-0.301667</td>\n",
              "      <td>-1.510224</td>\n",
              "      <td>-1.781693</td>\n",
              "      <td>-2.482175</td>\n",
              "      <td>0.669280</td>\n",
              "      <td>0.353362</td>\n",
              "      <td>0.221968</td>\n",
              "      <td>-0.475836</td>\n",
              "      <td>-0.002227</td>\n",
              "      <td>-1.978619</td>\n",
              "      <td>-0.394305</td>\n",
              "      <td>-0.570486</td>\n",
              "      <td>-0.542444</td>\n",
              "      <td>-2.031889</td>\n",
              "      <td>-0.973060</td>\n",
              "      <td>-1.772838</td>\n",
              "      <td>2.656627</td>\n",
              "      <td>1.864221</td>\n",
              "      <td>2.852338</td>\n",
              "      <td>1.398268</td>\n",
              "      <td>2.378454</td>\n",
              "      <td>1.795895</td>\n",
              "      <td>3.597935</td>\n",
              "      <td>1.571765</td>\n",
              "      <td>3.414866</td>\n",
              "      <td>1.558767</td>\n",
              "      <td>515267</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>526749</th>\n",
              "      <td>124</td>\n",
              "      <td>4.917284</td>\n",
              "      <td>-0.000834</td>\n",
              "      <td>-0.000888</td>\n",
              "      <td>-0.001045</td>\n",
              "      <td>-0.000947</td>\n",
              "      <td>-0.000577</td>\n",
              "      <td>-1</td>\n",
              "      <td>1.993604</td>\n",
              "      <td>5.245586</td>\n",
              "      <td>-0.638016</td>\n",
              "      <td>-1.123263</td>\n",
              "      <td>0.075409</td>\n",
              "      <td>0.186832</td>\n",
              "      <td>0.124346</td>\n",
              "      <td>0.687342</td>\n",
              "      <td>0.951121</td>\n",
              "      <td>2.916475</td>\n",
              "      <td>0.213003</td>\n",
              "      <td>1.578597</td>\n",
              "      <td>0.563027</td>\n",
              "      <td>1.974775</td>\n",
              "      <td>0.632952</td>\n",
              "      <td>3.308710</td>\n",
              "      <td>-0.448722</td>\n",
              "      <td>-1.038378</td>\n",
              "      <td>-1.367525</td>\n",
              "      <td>-3.093187</td>\n",
              "      <td>-1.274009</td>\n",
              "      <td>-1.180594</td>\n",
              "      <td>-1.387460</td>\n",
              "      <td>-3.044199</td>\n",
              "      <td>-1.714363</td>\n",
              "      <td>-3.466603</td>\n",
              "      <td>0.334316</td>\n",
              "      <td>1.140776</td>\n",
              "      <td>1.589042</td>\n",
              "      <td>4.601795</td>\n",
              "      <td>0.634231</td>\n",
              "      <td>2.326715</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.858642</td>\n",
              "      <td>-0.125666</td>\n",
              "      <td>0.685166</td>\n",
              "      <td>-1.262613</td>\n",
              "      <td>-2.161254</td>\n",
              "      <td>-1.338859</td>\n",
              "      <td>-1.551716</td>\n",
              "      <td>-1.257774</td>\n",
              "      <td>-1.194013</td>\n",
              "      <td>-0.071406</td>\n",
              "      <td>-4.169781</td>\n",
              "      <td>-0.940190</td>\n",
              "      <td>-1.417041</td>\n",
              "      <td>-1.510224</td>\n",
              "      <td>-1.781693</td>\n",
              "      <td>-1.914669</td>\n",
              "      <td>-1.959252</td>\n",
              "      <td>3.524964</td>\n",
              "      <td>0.051171</td>\n",
              "      <td>0.814131</td>\n",
              "      <td>2.879211</td>\n",
              "      <td>0.541099</td>\n",
              "      <td>-3.336379</td>\n",
              "      <td>0.017720</td>\n",
              "      <td>-2.177554</td>\n",
              "      <td>-1.474883</td>\n",
              "      <td>-0.406930</td>\n",
              "      <td>-1.130178</td>\n",
              "      <td>-0.250730</td>\n",
              "      <td>-1.395801</td>\n",
              "      <td>-0.030325</td>\n",
              "      <td>-0.590197</td>\n",
              "      <td>-0.161616</td>\n",
              "      <td>-1.318074</td>\n",
              "      <td>-0.177989</td>\n",
              "      <td>-0.882838</td>\n",
              "      <td>-0.088160</td>\n",
              "      <td>-0.683795</td>\n",
              "      <td>667836</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 139 columns</p>\n",
              "</div>"
            ],
            "text/plain": [
              "         date    weight    resp_1  ...  feature_129    ts_id  action\n",
              "865316    228  0.485024  0.006512  ...     1.395075  1078076       0\n",
              "893211    235  2.176115  0.011735  ...     0.504219  1111263       0\n",
              "1055679   278  0.181485 -0.002526  ...     2.738759  1303265       0\n",
              "400986     85  1.805121 -0.012062  ...     1.558767   515267       0\n",
              "526749    124  4.917284 -0.000834  ...    -0.683795   667836       0\n",
              "\n",
              "[5 rows x 139 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oD4H6WPLF-1G"
      },
      "source": [
        "features = [c for c in train.columns if 'feature' in c]\r\n",
        "X = train[['date'] + features]\r\n",
        "y = train[['date', 'action']]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "urjnQNYiGewZ"
      },
      "source": [
        "X_train = X.loc[(X['date']>=0) & (X['date']<=462)][features].values\r\n",
        "X_validation = X.loc[X['date']>462][features].values\r\n",
        "\r\n",
        "y_train = y.loc[(y['date']>=0) & (y['date']<=462)]['action'].values\r\n",
        "y_validation = y[y['date']>462]['action'].values"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wvH8rGVuYIe5",
        "outputId": "5b2a29c9-10af-4b6f-e42d-8af99359607d"
      },
      "source": [
        "X_train.shape"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(889056, 130)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 68
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-044cBf1GrUJ",
        "outputId": "cf0df5bf-ec44-428d-bbf3-454b3d5e535f"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(tf.keras.layers.BatchNormalization())\r\n",
        "model.add(Dense(320,input_shape = (X_train.shape[-1],),activation='relu',kernel_regularizer = 'l2'))\r\n",
        "model.add(layers.Dropout(rate=0.236))\r\n",
        "model.add(Dense(128,activation='relu'))\r\n",
        "model.add(layers.Dropout(rate=0.231))\r\n",
        "model.add(Dense(1312,activation='relu',kernel_regularizer=\"l2\"))\r\n",
        "model.add(layers.Dropout(rate=0.418))\r\n",
        "model.add(Dense(32,activation='relu'))\r\n",
        "model.add(Dense(1,activation='sigmoid'))\r\n",
        "\r\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.001)\r\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "history = model.fit(X_train,y_train,\r\n",
        "                    validation_data=(X_validation,y_validation),\r\n",
        "                    batch_size=2048, epochs=350,\r\n",
        "                   callbacks=[EarlyStopping('val_loss',patience=10,restore_best_weights=True)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/350\n",
            "435/435 [==============================] - 4s 7ms/step - loss: 1.3335 - accuracy: 0.5346 - val_loss: 0.6929 - val_accuracy: 0.5398\n",
            "Epoch 2/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6900 - accuracy: 0.5452 - val_loss: 0.6949 - val_accuracy: 0.5270\n",
            "Epoch 3/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6888 - accuracy: 0.5475 - val_loss: 0.6888 - val_accuracy: 0.5453\n",
            "Epoch 4/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6878 - accuracy: 0.5500 - val_loss: 0.6898 - val_accuracy: 0.5455\n",
            "Epoch 5/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6874 - accuracy: 0.5507 - val_loss: 0.6902 - val_accuracy: 0.5312\n",
            "Epoch 6/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6871 - accuracy: 0.5487 - val_loss: 0.6868 - val_accuracy: 0.5509\n",
            "Epoch 7/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6868 - accuracy: 0.5496 - val_loss: 0.6865 - val_accuracy: 0.5506\n",
            "Epoch 8/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6865 - accuracy: 0.5504 - val_loss: 0.6879 - val_accuracy: 0.5454\n",
            "Epoch 9/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6863 - accuracy: 0.5514 - val_loss: 0.6872 - val_accuracy: 0.5475\n",
            "Epoch 10/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6858 - accuracy: 0.5511 - val_loss: 0.6862 - val_accuracy: 0.5526\n",
            "Epoch 11/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6860 - accuracy: 0.5498 - val_loss: 0.6857 - val_accuracy: 0.5513\n",
            "Epoch 12/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6857 - accuracy: 0.5514 - val_loss: 0.6856 - val_accuracy: 0.5484\n",
            "Epoch 13/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6855 - accuracy: 0.5521 - val_loss: 0.6854 - val_accuracy: 0.5508\n",
            "Epoch 14/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6856 - accuracy: 0.5510 - val_loss: 0.6861 - val_accuracy: 0.5546\n",
            "Epoch 15/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6853 - accuracy: 0.5522 - val_loss: 0.6848 - val_accuracy: 0.5536\n",
            "Epoch 16/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6852 - accuracy: 0.5522 - val_loss: 0.6869 - val_accuracy: 0.5495\n",
            "Epoch 17/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6854 - accuracy: 0.5520 - val_loss: 0.6846 - val_accuracy: 0.5510\n",
            "Epoch 18/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6852 - accuracy: 0.5508 - val_loss: 0.6847 - val_accuracy: 0.5526\n",
            "Epoch 19/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6853 - accuracy: 0.5514 - val_loss: 0.6851 - val_accuracy: 0.5525\n",
            "Epoch 20/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6854 - accuracy: 0.5518 - val_loss: 0.6860 - val_accuracy: 0.5463\n",
            "Epoch 21/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6851 - accuracy: 0.5515 - val_loss: 0.6834 - val_accuracy: 0.5521\n",
            "Epoch 22/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6847 - accuracy: 0.5517 - val_loss: 0.6863 - val_accuracy: 0.5533\n",
            "Epoch 23/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6854 - accuracy: 0.5509 - val_loss: 0.6853 - val_accuracy: 0.5556\n",
            "Epoch 24/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6850 - accuracy: 0.5517 - val_loss: 0.6843 - val_accuracy: 0.5533\n",
            "Epoch 25/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6848 - accuracy: 0.5524 - val_loss: 0.6845 - val_accuracy: 0.5509\n",
            "Epoch 26/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6851 - accuracy: 0.5506 - val_loss: 0.6849 - val_accuracy: 0.5488\n",
            "Epoch 27/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6848 - accuracy: 0.5521 - val_loss: 0.6855 - val_accuracy: 0.5512\n",
            "Epoch 28/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6850 - accuracy: 0.5521 - val_loss: 0.6951 - val_accuracy: 0.5207\n",
            "Epoch 29/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6850 - accuracy: 0.5531 - val_loss: 0.6863 - val_accuracy: 0.5509\n",
            "Epoch 30/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6849 - accuracy: 0.5515 - val_loss: 0.6854 - val_accuracy: 0.5552\n",
            "Epoch 31/350\n",
            "435/435 [==============================] - 2s 6ms/step - loss: 0.6851 - accuracy: 0.5519 - val_loss: 0.6840 - val_accuracy: 0.5525\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "8kszLBBgGyUB",
        "outputId": "86256e1a-408e-46a1-c3b0-569b0ba1b725"
      },
      "source": [
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "acc = history.history['accuracy']\r\n",
        "val_acc = history.history['val_accuracy']\r\n",
        "\r\n",
        "epochs = range(len(loss))\r\n",
        "\r\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\r\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "plt.axhline(y=0.5,ls=\":\",c=\"gray\")\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend()\r\n",
        "plt.ylim(ymax=0.6,ymin=0.4)\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E8ExC1OdIX-i",
        "outputId": "fb4c85fa-b416-4afa-c5c4-a6200daa7300"
      },
      "source": [
        "from sklearn.metrics import accuracy_score, classification_report\r\n",
        "pred = model.predict(X_validation)\r\n",
        "print(classification_report(y_validation, pred.round(), labels=[True,False]))\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        True       0.55      0.58      0.57     40454\n",
            "       False       0.56      0.53      0.54     40722\n",
            "\n",
            "    accuracy                           0.55     81176\n",
            "   macro avg       0.55      0.55      0.55     81176\n",
            "weighted avg       0.55      0.55      0.55     81176\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wTtjyPDmjXHn",
        "outputId": "a1b2178a-a603-488d-fcad-0734923c7d7a"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "1"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 74
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "03OKzQDpIdrj",
        "outputId": "fb0c9d7d-f53d-438e-a64b-78a62695bb7e"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(tf.keras.layers.BatchNormalization())\r\n",
        "model.add(Dense(512,input_shape = (X_train.shape[-1],),activation='relu',kernel_regularizer = 'l2'))\r\n",
        "model.add(layers.Dropout(rate=0.2))\r\n",
        "model.add(Dense(256,activation='relu'))\r\n",
        "model.add(layers.Dropout(rate=0.231))\r\n",
        "model.add(Dense(1024,activation='relu',kernel_regularizer=\"l2\"))\r\n",
        "model.add(layers.Dropout(rate=0.5))\r\n",
        "# model.add(Dense(2000,activation='relu',kernel_regularizer=\"l2\"))\r\n",
        "# model.add(layers.Dropout(rate=0.564))\r\n",
        "model.add(Dense(32,activation='relu'))\r\n",
        "model.add(Dense(1,activation='sigmoid'))\r\n",
        "\r\n",
        "opt = keras.optimizers.Adam(learning_rate=0.001)\r\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "history = model.fit(X_train,y_train,\r\n",
        "                    validation_data=(X_validation,y_validation),\r\n",
        "                    batch_size=2048, epochs=350,\r\n",
        "                   callbacks=[EarlyStopping('val_loss',patience=10,restore_best_weights=True)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/350\n",
            "435/435 [==============================] - 4s 7ms/step - loss: 1.8416 - accuracy: 0.5379 - val_loss: 0.6883 - val_accuracy: 0.5492\n",
            "Epoch 2/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6897 - accuracy: 0.5457 - val_loss: 0.6866 - val_accuracy: 0.5540\n",
            "Epoch 3/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6886 - accuracy: 0.5483 - val_loss: 0.6868 - val_accuracy: 0.5506\n",
            "Epoch 4/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6879 - accuracy: 0.5484 - val_loss: 0.6868 - val_accuracy: 0.5518\n",
            "Epoch 5/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6868 - accuracy: 0.5501 - val_loss: 0.6858 - val_accuracy: 0.5515\n",
            "Epoch 6/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6867 - accuracy: 0.5492 - val_loss: 0.6863 - val_accuracy: 0.5515\n",
            "Epoch 7/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6862 - accuracy: 0.5508 - val_loss: 0.6845 - val_accuracy: 0.5518\n",
            "Epoch 8/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6860 - accuracy: 0.5517 - val_loss: 0.6859 - val_accuracy: 0.5533\n",
            "Epoch 9/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6859 - accuracy: 0.5509 - val_loss: 0.6853 - val_accuracy: 0.5513\n",
            "Epoch 10/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6858 - accuracy: 0.5497 - val_loss: 0.6846 - val_accuracy: 0.5509\n",
            "Epoch 11/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6858 - accuracy: 0.5506 - val_loss: 0.6836 - val_accuracy: 0.5550\n",
            "Epoch 12/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6856 - accuracy: 0.5508 - val_loss: 0.6835 - val_accuracy: 0.5572\n",
            "Epoch 13/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6852 - accuracy: 0.5514 - val_loss: 0.6840 - val_accuracy: 0.5537\n",
            "Epoch 14/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6851 - accuracy: 0.5509 - val_loss: 0.6834 - val_accuracy: 0.5536\n",
            "Epoch 15/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6851 - accuracy: 0.5520 - val_loss: 0.6839 - val_accuracy: 0.5556\n",
            "Epoch 16/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6851 - accuracy: 0.5517 - val_loss: 0.6835 - val_accuracy: 0.5550\n",
            "Epoch 17/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6853 - accuracy: 0.5506 - val_loss: 0.6838 - val_accuracy: 0.5568\n",
            "Epoch 18/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6849 - accuracy: 0.5519 - val_loss: 0.6836 - val_accuracy: 0.5535\n",
            "Epoch 19/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6848 - accuracy: 0.5517 - val_loss: 0.6833 - val_accuracy: 0.5564\n",
            "Epoch 20/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6849 - accuracy: 0.5523 - val_loss: 0.6833 - val_accuracy: 0.5565\n",
            "Epoch 21/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6846 - accuracy: 0.5522 - val_loss: 0.6840 - val_accuracy: 0.5548\n",
            "Epoch 22/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6848 - accuracy: 0.5512 - val_loss: 0.6834 - val_accuracy: 0.5587\n",
            "Epoch 23/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6848 - accuracy: 0.5517 - val_loss: 0.6830 - val_accuracy: 0.5585\n",
            "Epoch 24/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6849 - accuracy: 0.5514 - val_loss: 0.6836 - val_accuracy: 0.5588\n",
            "Epoch 25/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6845 - accuracy: 0.5531 - val_loss: 0.6832 - val_accuracy: 0.5582\n",
            "Epoch 26/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6846 - accuracy: 0.5515 - val_loss: 0.6836 - val_accuracy: 0.5579\n",
            "Epoch 27/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6843 - accuracy: 0.5517 - val_loss: 0.6839 - val_accuracy: 0.5568\n",
            "Epoch 28/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6843 - accuracy: 0.5517 - val_loss: 0.6833 - val_accuracy: 0.5563\n",
            "Epoch 29/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6845 - accuracy: 0.5524 - val_loss: 0.6836 - val_accuracy: 0.5592\n",
            "Epoch 30/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6844 - accuracy: 0.5527 - val_loss: 0.6853 - val_accuracy: 0.5540\n",
            "Epoch 31/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6843 - accuracy: 0.5533 - val_loss: 0.6840 - val_accuracy: 0.5551\n",
            "Epoch 32/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6845 - accuracy: 0.5526 - val_loss: 0.6835 - val_accuracy: 0.5564\n",
            "Epoch 33/350\n",
            "435/435 [==============================] - 3s 6ms/step - loss: 0.6844 - accuracy: 0.5522 - val_loss: 0.6841 - val_accuracy: 0.5570\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 281
        },
        "id": "MXafkrHmIptJ",
        "outputId": "9ab0ff86-29eb-43d7-e56e-7c5f55b2de51"
      },
      "source": [
        "loss = history.history['loss']\r\n",
        "val_loss = history.history['val_loss']\r\n",
        "acc = history.history['accuracy']\r\n",
        "val_acc = history.history['val_accuracy']\r\n",
        "\r\n",
        "epochs = range(len(loss))\r\n",
        "\r\n",
        "plt.plot(epochs, acc, 'r', label='Training accuracy')\r\n",
        "plt.plot(epochs, val_acc, 'b', label='Validation accuracy')\r\n",
        "plt.axhline(y=0.5,ls=\":\",c=\"gray\")\r\n",
        "plt.title('Training and validation accuracy')\r\n",
        "plt.legend()\r\n",
        "plt.ylim(ymax=0.6,ymin=0.4)\r\n",
        "\r\n",
        "plt.show()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "tags": [],
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "z2ENJWNBIvqK",
        "outputId": "afdcd3cb-9ba8-4e67-8aa4-1d8a2bfdaaf8"
      },
      "source": [
        "pred = model.predict(X_validation)\r\n",
        "print(classification_report(y_validation, pred.round(), labels=[True,False]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        True       0.55      0.60      0.57     40454\n",
            "       False       0.56      0.51      0.54     40722\n",
            "\n",
            "    accuracy                           0.56     81176\n",
            "   macro avg       0.56      0.56      0.56     81176\n",
            "weighted avg       0.56      0.56      0.56     81176\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-u-sHB2VlSU7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 953
        },
        "outputId": "c7423c2e-74c8-427d-cfcb-1878beea626b"
      },
      "source": [
        "tf.keras.utils.plot_model(model)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<IPython.core.display.Image object>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KuJhU74Nmb0F",
        "outputId": "ceec5211-ee8d-4aa7-a777-896798ab5a82"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(tf.keras.layers.BatchNormalization())\r\n",
        "model.add(Dense(512,input_shape = (X_train.shape[-1],),activation='relu',kernel_regularizer = 'l2'))\r\n",
        "model.add(layers.Dropout(rate=0.2))\r\n",
        "model.add(Dense(256,activation='swish'))\r\n",
        "model.add(layers.Dropout(rate=0.231))\r\n",
        "model.add(Dense(1024,activation='swish',kernel_regularizer=\"l2\"))\r\n",
        "model.add(layers.Dropout(rate=0.5))\r\n",
        "# model.add(Dense(2000,activation='relu',kernel_regularizer=\"l2\"))\r\n",
        "# model.add(layers.Dropout(rate=0.564))\r\n",
        "model.add(Dense(2))\r\n",
        "model.add(Dense(1,activation='sigmoid'))\r\n",
        "\r\n",
        "opt = tfa.optimizers.RectifiedAdam(learning_rate=0.001)\r\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['AUC'])\r\n",
        "history = model.fit(X_train,y_train,\r\n",
        "                    validation_data=(X_validation,y_validation),\r\n",
        "                    batch_size=2048, epochs=350,\r\n",
        "                   callbacks=[EarlyStopping('val_loss',patience=10,restore_best_weights=True)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/350\n",
            "435/435 [==============================] - 8s 12ms/step - loss: 4.4379 - auc: 0.5418 - val_loss: 0.7114 - val_auc: 0.5706\n",
            "Epoch 2/350\n",
            "435/435 [==============================] - 5s 12ms/step - loss: 0.6958 - auc: 0.5662 - val_loss: 0.6884 - val_auc: 0.5688\n",
            "Epoch 3/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6883 - auc: 0.5686 - val_loss: 0.6871 - val_auc: 0.5737\n",
            "Epoch 4/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6877 - auc: 0.5720 - val_loss: 0.6880 - val_auc: 0.5685\n",
            "Epoch 5/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6881 - auc: 0.5690 - val_loss: 0.6868 - val_auc: 0.5754\n",
            "Epoch 6/350\n",
            "435/435 [==============================] - 5s 12ms/step - loss: 0.6872 - auc: 0.5724 - val_loss: 0.6872 - val_auc: 0.5755\n",
            "Epoch 7/350\n",
            "435/435 [==============================] - 5s 12ms/step - loss: 0.6869 - auc: 0.5724 - val_loss: 0.6864 - val_auc: 0.5785\n",
            "Epoch 8/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6868 - auc: 0.5722 - val_loss: 0.6865 - val_auc: 0.5781\n",
            "Epoch 9/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6861 - auc: 0.5743 - val_loss: 0.6847 - val_auc: 0.5775\n",
            "Epoch 10/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6859 - auc: 0.5746 - val_loss: 0.6846 - val_auc: 0.5793\n",
            "Epoch 11/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6858 - auc: 0.5749 - val_loss: 0.6847 - val_auc: 0.5813\n",
            "Epoch 12/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6858 - auc: 0.5738 - val_loss: 0.6840 - val_auc: 0.5794\n",
            "Epoch 13/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6857 - auc: 0.5738 - val_loss: 0.6836 - val_auc: 0.5807\n",
            "Epoch 14/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6852 - auc: 0.5748 - val_loss: 0.6839 - val_auc: 0.5787\n",
            "Epoch 15/350\n",
            "435/435 [==============================] - 5s 12ms/step - loss: 0.6853 - auc: 0.5743 - val_loss: 0.6849 - val_auc: 0.5826\n",
            "Epoch 16/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6853 - auc: 0.5744 - val_loss: 0.6851 - val_auc: 0.5809\n",
            "Epoch 17/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6852 - auc: 0.5748 - val_loss: 0.6842 - val_auc: 0.5802\n",
            "Epoch 18/350\n",
            "435/435 [==============================] - 5s 12ms/step - loss: 0.6849 - auc: 0.5753 - val_loss: 0.6852 - val_auc: 0.5769\n",
            "Epoch 19/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6850 - auc: 0.5754 - val_loss: 0.6834 - val_auc: 0.5816\n",
            "Epoch 20/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6846 - auc: 0.5766 - val_loss: 0.6832 - val_auc: 0.5804\n",
            "Epoch 21/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6847 - auc: 0.5758 - val_loss: 0.6856 - val_auc: 0.5795\n",
            "Epoch 22/350\n",
            "435/435 [==============================] - 5s 12ms/step - loss: 0.6848 - auc: 0.5753 - val_loss: 0.6840 - val_auc: 0.5773\n",
            "Epoch 23/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6849 - auc: 0.5745 - val_loss: 0.6857 - val_auc: 0.5812\n",
            "Epoch 24/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6846 - auc: 0.5760 - val_loss: 0.6837 - val_auc: 0.5832\n",
            "Epoch 25/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6845 - auc: 0.5760 - val_loss: 0.6838 - val_auc: 0.5808\n",
            "Epoch 26/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6847 - auc: 0.5754 - val_loss: 0.6828 - val_auc: 0.5819\n",
            "Epoch 27/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6843 - auc: 0.5763 - val_loss: 0.6840 - val_auc: 0.5829\n",
            "Epoch 28/350\n",
            "435/435 [==============================] - 5s 12ms/step - loss: 0.6843 - auc: 0.5768 - val_loss: 0.6826 - val_auc: 0.5820\n",
            "Epoch 29/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6844 - auc: 0.5764 - val_loss: 0.6830 - val_auc: 0.5805\n",
            "Epoch 30/350\n",
            "435/435 [==============================] - 5s 12ms/step - loss: 0.6847 - auc: 0.5745 - val_loss: 0.6844 - val_auc: 0.5829\n",
            "Epoch 31/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6840 - auc: 0.5780 - val_loss: 0.6839 - val_auc: 0.5791\n",
            "Epoch 32/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6845 - auc: 0.5756 - val_loss: 0.6833 - val_auc: 0.5833\n",
            "Epoch 33/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6845 - auc: 0.5755 - val_loss: 0.6839 - val_auc: 0.5799\n",
            "Epoch 34/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6844 - auc: 0.5758 - val_loss: 0.6831 - val_auc: 0.5822\n",
            "Epoch 35/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6841 - auc: 0.5771 - val_loss: 0.6823 - val_auc: 0.5820\n",
            "Epoch 36/350\n",
            "435/435 [==============================] - 5s 12ms/step - loss: 0.6841 - auc: 0.5768 - val_loss: 0.6823 - val_auc: 0.5818\n",
            "Epoch 37/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6840 - auc: 0.5774 - val_loss: 0.6841 - val_auc: 0.5792\n",
            "Epoch 38/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6842 - auc: 0.5761 - val_loss: 0.6824 - val_auc: 0.5831\n",
            "Epoch 39/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6842 - auc: 0.5772 - val_loss: 0.6820 - val_auc: 0.5836\n",
            "Epoch 40/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6842 - auc: 0.5761 - val_loss: 0.6834 - val_auc: 0.5789\n",
            "Epoch 41/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6841 - auc: 0.5770 - val_loss: 0.6825 - val_auc: 0.5822\n",
            "Epoch 42/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6844 - auc: 0.5757 - val_loss: 0.6837 - val_auc: 0.5817\n",
            "Epoch 43/350\n",
            "435/435 [==============================] - 5s 12ms/step - loss: 0.6840 - auc: 0.5773 - val_loss: 0.6834 - val_auc: 0.5828\n",
            "Epoch 44/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6838 - auc: 0.5779 - val_loss: 0.6826 - val_auc: 0.5817\n",
            "Epoch 45/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6844 - auc: 0.5759 - val_loss: 0.6824 - val_auc: 0.5813\n",
            "Epoch 46/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6836 - auc: 0.5787 - val_loss: 0.6826 - val_auc: 0.5807\n",
            "Epoch 47/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6839 - auc: 0.5775 - val_loss: 0.6826 - val_auc: 0.5803\n",
            "Epoch 48/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6839 - auc: 0.5775 - val_loss: 0.6831 - val_auc: 0.5782\n",
            "Epoch 49/350\n",
            "435/435 [==============================] - 5s 11ms/step - loss: 0.6841 - auc: 0.5768 - val_loss: 0.6829 - val_auc: 0.5815\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DNLlHNMYnkv2",
        "outputId": "87770d43-0014-4238-e9f8-68906cf32115"
      },
      "source": [
        "pred = model.predict(X_validation)\r\n",
        "print(classification_report(y_validation, pred.round(), labels=[True,False]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        True       0.56      0.53      0.54     40454\n",
            "       False       0.56      0.59      0.57     40722\n",
            "\n",
            "    accuracy                           0.56     81176\n",
            "   macro avg       0.56      0.56      0.56     81176\n",
            "weighted avg       0.56      0.56      0.56     81176\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "shMMNSvWph-R",
        "outputId": "b6c89bd4-e278-4d5a-d73a-62cc89cb36ab"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(tf.keras.layers.BatchNormalization())\r\n",
        "model.add(Dense(512,input_shape = (X_train.shape[-1],),activation='relu',kernel_regularizer = 'l2'))\r\n",
        "model.add(layers.Dropout(rate=0.2))\r\n",
        "model.add(Dense(256,activation='swish'))\r\n",
        "model.add(layers.Dropout(rate=0.231))\r\n",
        "model.add(Dense(1024,activation='swish',kernel_regularizer=\"l2\"))\r\n",
        "model.add(layers.Dropout(rate=0.5))\r\n",
        "# model.add(Dense(2000,activation='relu',kernel_regularizer=\"l2\"))\r\n",
        "# model.add(layers.Dropout(rate=0.564))\r\n",
        "model.add(Dense(32, activation=\"relu\"))\r\n",
        "model.add(layers.BatchNormalization())\r\n",
        "\r\n",
        "model.add(layers.Dense(1))\r\n",
        "model.add(layers.BatchNormalization())\r\n",
        "model.add(layers.Activation(\"sigmoid\"))\r\n",
        "\r\n",
        "opt = tfa.optimizers.RectifiedAdam(learning_rate=0.001)\r\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['AUC'])\r\n",
        "history = model.fit(X_train,y_train,\r\n",
        "                    validation_data=(X_validation,y_validation),\r\n",
        "                    batch_size=2048, epochs=350,\r\n",
        "                   callbacks=[EarlyStopping('val_loss',patience=10,restore_best_weights=True)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/350\n",
            "435/435 [==============================] - 9s 15ms/step - loss: 4.7138 - auc: 0.5380 - val_loss: 0.7723 - val_auc: 0.5510\n",
            "Epoch 2/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.7391 - auc: 0.5636 - val_loss: 0.7244 - val_auc: 0.5679\n",
            "Epoch 3/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.7091 - auc: 0.5644 - val_loss: 0.7014 - val_auc: 0.5657\n",
            "Epoch 4/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.7030 - auc: 0.5638 - val_loss: 0.6911 - val_auc: 0.5766\n",
            "Epoch 5/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6925 - auc: 0.5681 - val_loss: 0.6892 - val_auc: 0.5727\n",
            "Epoch 6/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6887 - auc: 0.5717 - val_loss: 0.6858 - val_auc: 0.5767\n",
            "Epoch 7/350\n",
            "435/435 [==============================] - 7s 15ms/step - loss: 0.6867 - auc: 0.5730 - val_loss: 0.6851 - val_auc: 0.5771\n",
            "Epoch 8/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6865 - auc: 0.5736 - val_loss: 0.6869 - val_auc: 0.5764\n",
            "Epoch 9/350\n",
            "435/435 [==============================] - 6s 15ms/step - loss: 0.6867 - auc: 0.5722 - val_loss: 0.6868 - val_auc: 0.5719\n",
            "Epoch 10/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6867 - auc: 0.5734 - val_loss: 0.6855 - val_auc: 0.5783\n",
            "Epoch 11/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6866 - auc: 0.5740 - val_loss: 0.6869 - val_auc: 0.5764\n",
            "Epoch 12/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6867 - auc: 0.5731 - val_loss: 0.6858 - val_auc: 0.5769\n",
            "Epoch 13/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6867 - auc: 0.5741 - val_loss: 0.6850 - val_auc: 0.5782\n",
            "Epoch 14/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6868 - auc: 0.5729 - val_loss: 0.6877 - val_auc: 0.5787\n",
            "Epoch 15/350\n",
            "435/435 [==============================] - 6s 15ms/step - loss: 0.6863 - auc: 0.5746 - val_loss: 0.6859 - val_auc: 0.5777\n",
            "Epoch 16/350\n",
            "435/435 [==============================] - 7s 15ms/step - loss: 0.6865 - auc: 0.5750 - val_loss: 0.6849 - val_auc: 0.5803\n",
            "Epoch 17/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6863 - auc: 0.5751 - val_loss: 0.6850 - val_auc: 0.5810\n",
            "Epoch 18/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6864 - auc: 0.5747 - val_loss: 0.6843 - val_auc: 0.5806\n",
            "Epoch 19/350\n",
            "435/435 [==============================] - 7s 15ms/step - loss: 0.6861 - auc: 0.5745 - val_loss: 0.6854 - val_auc: 0.5780\n",
            "Epoch 20/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6860 - auc: 0.5752 - val_loss: 0.6860 - val_auc: 0.5795\n",
            "Epoch 21/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6861 - auc: 0.5746 - val_loss: 0.6857 - val_auc: 0.5790\n",
            "Epoch 22/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6864 - auc: 0.5744 - val_loss: 0.6839 - val_auc: 0.5837\n",
            "Epoch 23/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6859 - auc: 0.5758 - val_loss: 0.6852 - val_auc: 0.5795\n",
            "Epoch 24/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6860 - auc: 0.5758 - val_loss: 0.6859 - val_auc: 0.5793\n",
            "Epoch 25/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6861 - auc: 0.5754 - val_loss: 0.6840 - val_auc: 0.5830\n",
            "Epoch 26/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6857 - auc: 0.5756 - val_loss: 0.6851 - val_auc: 0.5809\n",
            "Epoch 27/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6859 - auc: 0.5758 - val_loss: 0.6844 - val_auc: 0.5824\n",
            "Epoch 28/350\n",
            "435/435 [==============================] - 7s 15ms/step - loss: 0.6858 - auc: 0.5760 - val_loss: 0.6853 - val_auc: 0.5806\n",
            "Epoch 29/350\n",
            "435/435 [==============================] - 6s 13ms/step - loss: 0.6856 - auc: 0.5764 - val_loss: 0.6843 - val_auc: 0.5811\n",
            "Epoch 30/350\n",
            "435/435 [==============================] - 6s 14ms/step - loss: 0.6855 - auc: 0.5764 - val_loss: 0.6842 - val_auc: 0.5838\n",
            "Epoch 31/350\n",
            "435/435 [==============================] - 6s 13ms/step - loss: 0.6857 - auc: 0.5771 - val_loss: 0.6854 - val_auc: 0.5812\n",
            "Epoch 32/350\n",
            "435/435 [==============================] - 6s 15ms/step - loss: 0.6853 - auc: 0.5775 - val_loss: 0.6855 - val_auc: 0.5818\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XSbDXDcRUhMQ",
        "outputId": "c304710f-893e-498f-bd3d-265252eb6500"
      },
      "source": [
        "pred = model.predict(X_validation)\r\n",
        "print(classification_report(y_validation, pred.round(), labels=[True,False]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        True       0.56      0.53      0.54     40454\n",
            "       False       0.56      0.58      0.57     40722\n",
            "\n",
            "    accuracy                           0.56     81176\n",
            "   macro avg       0.56      0.56      0.56     81176\n",
            "weighted avg       0.56      0.56      0.56     81176\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ddu2q0x3VX_1",
        "outputId": "d32ff2e3-8ae4-4cee-fbe6-0590b7330308"
      },
      "source": [
        "model = Sequential()\r\n",
        "model.add(tf.keras.layers.BatchNormalization())\r\n",
        "model.add(Dense(320,input_shape = (X_train.shape[-1],),activation='relu',kernel_regularizer = 'l2'))\r\n",
        "model.add(layers.Dropout(rate=0.236))\r\n",
        "model.add(Dense(128,activation='relu'))\r\n",
        "model.add(layers.Dropout(rate=0.231))\r\n",
        "model.add(Dense(1312,activation='relu',kernel_regularizer=\"l2\"))\r\n",
        "model.add(layers.Dropout(rate=0.418))\r\n",
        "model.add(Dense(32,activation='relu'))\r\n",
        "model.add(layers.BatchNormalization())\r\n",
        "\r\n",
        "model.add(layers.Dense(1))\r\n",
        "model.add(layers.BatchNormalization())\r\n",
        "model.add(layers.Activation(\"sigmoid\"))\r\n",
        "\r\n",
        "opt = keras.optimizers.RMSprop(learning_rate=0.001)\r\n",
        "model.compile(optimizer=opt, loss='binary_crossentropy', metrics=['accuracy'])\r\n",
        "history = model.fit(X_train,y_train,\r\n",
        "                    validation_data=(X_validation,y_validation),\r\n",
        "                    batch_size=2048, epochs=350,\r\n",
        "                   callbacks=[EarlyStopping('val_loss',patience=10,restore_best_weights=True)])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Epoch 1/350\n",
            "435/435 [==============================] - 5s 8ms/step - loss: 1.4680 - accuracy: 0.5357 - val_loss: 0.7035 - val_accuracy: 0.5301\n",
            "Epoch 2/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.7015 - accuracy: 0.5451 - val_loss: 0.6930 - val_accuracy: 0.5371\n",
            "Epoch 3/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6891 - accuracy: 0.5482 - val_loss: 0.6910 - val_accuracy: 0.5408\n",
            "Epoch 4/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6879 - accuracy: 0.5494 - val_loss: 0.6884 - val_accuracy: 0.5485\n",
            "Epoch 5/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6872 - accuracy: 0.5500 - val_loss: 0.6911 - val_accuracy: 0.5496\n",
            "Epoch 6/350\n",
            "435/435 [==============================] - 3s 8ms/step - loss: 0.6869 - accuracy: 0.5498 - val_loss: 0.6864 - val_accuracy: 0.5479\n",
            "Epoch 7/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6866 - accuracy: 0.5500 - val_loss: 0.6864 - val_accuracy: 0.5520\n",
            "Epoch 8/350\n",
            "435/435 [==============================] - 3s 8ms/step - loss: 0.6863 - accuracy: 0.5513 - val_loss: 0.6857 - val_accuracy: 0.5533\n",
            "Epoch 9/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6860 - accuracy: 0.5508 - val_loss: 0.6868 - val_accuracy: 0.5502\n",
            "Epoch 10/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6860 - accuracy: 0.5508 - val_loss: 0.6864 - val_accuracy: 0.5474\n",
            "Epoch 11/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6858 - accuracy: 0.5513 - val_loss: 0.6867 - val_accuracy: 0.5372\n",
            "Epoch 12/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6855 - accuracy: 0.5520 - val_loss: 0.6854 - val_accuracy: 0.5522\n",
            "Epoch 13/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6852 - accuracy: 0.5521 - val_loss: 0.6854 - val_accuracy: 0.5558\n",
            "Epoch 14/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6854 - accuracy: 0.5508 - val_loss: 0.6847 - val_accuracy: 0.5526\n",
            "Epoch 15/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6851 - accuracy: 0.5519 - val_loss: 0.6847 - val_accuracy: 0.5519\n",
            "Epoch 16/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6852 - accuracy: 0.5521 - val_loss: 0.6852 - val_accuracy: 0.5432\n",
            "Epoch 17/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6851 - accuracy: 0.5509 - val_loss: 0.6838 - val_accuracy: 0.5566\n",
            "Epoch 18/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6851 - accuracy: 0.5513 - val_loss: 0.6875 - val_accuracy: 0.5477\n",
            "Epoch 19/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6848 - accuracy: 0.5530 - val_loss: 0.6832 - val_accuracy: 0.5564\n",
            "Epoch 20/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6849 - accuracy: 0.5529 - val_loss: 0.6845 - val_accuracy: 0.5510\n",
            "Epoch 21/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6849 - accuracy: 0.5521 - val_loss: 0.6851 - val_accuracy: 0.5507\n",
            "Epoch 22/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6848 - accuracy: 0.5527 - val_loss: 0.6848 - val_accuracy: 0.5535\n",
            "Epoch 23/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6846 - accuracy: 0.5531 - val_loss: 0.6840 - val_accuracy: 0.5546\n",
            "Epoch 24/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6848 - accuracy: 0.5524 - val_loss: 0.6831 - val_accuracy: 0.5570\n",
            "Epoch 25/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6848 - accuracy: 0.5512 - val_loss: 0.6852 - val_accuracy: 0.5506\n",
            "Epoch 26/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6847 - accuracy: 0.5517 - val_loss: 0.6841 - val_accuracy: 0.5550\n",
            "Epoch 27/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6847 - accuracy: 0.5519 - val_loss: 0.6833 - val_accuracy: 0.5550\n",
            "Epoch 28/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6848 - accuracy: 0.5518 - val_loss: 0.6839 - val_accuracy: 0.5523\n",
            "Epoch 29/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6847 - accuracy: 0.5517 - val_loss: 0.6845 - val_accuracy: 0.5550\n",
            "Epoch 30/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6846 - accuracy: 0.5523 - val_loss: 0.6846 - val_accuracy: 0.5520\n",
            "Epoch 31/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6843 - accuracy: 0.5527 - val_loss: 0.6834 - val_accuracy: 0.5563\n",
            "Epoch 32/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6847 - accuracy: 0.5523 - val_loss: 0.6842 - val_accuracy: 0.5547\n",
            "Epoch 33/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6843 - accuracy: 0.5536 - val_loss: 0.6844 - val_accuracy: 0.5518\n",
            "Epoch 34/350\n",
            "435/435 [==============================] - 3s 7ms/step - loss: 0.6848 - accuracy: 0.5519 - val_loss: 0.6843 - val_accuracy: 0.5483\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wftMMo24V2zQ",
        "outputId": "b02fd3e9-c8a8-44ad-a64d-808c42ac411e"
      },
      "source": [
        "pred = model.predict(X_validation)\r\n",
        "print(classification_report(y_validation, predi(pred), labels=[True,False]))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "        True       0.55      0.63      0.59     40454\n",
            "       False       0.57      0.49      0.52     40722\n",
            "\n",
            "    accuracy                           0.56     81176\n",
            "   macro avg       0.56      0.56      0.56     81176\n",
            "weighted avg       0.56      0.56      0.56     81176\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IezP-8e0dPd3"
      },
      "source": [
        "def predi(x):\r\n",
        "  for i in range(len(x)):\r\n",
        "    if x[i] >= 0.5:\r\n",
        "      x[i] = 1\r\n",
        "    else:\r\n",
        "      x[i] = 0\r\n",
        "\r\n",
        "  return x\r\n",
        "  "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lmdayjTbWimm"
      },
      "source": [
        "from kerastuner.tuners import RandomSearch"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qSIBt9VavkEP"
      },
      "source": [
        "def build_model(hp):\r\n",
        "    model = keras.Sequential()\r\n",
        "    for i in range(hp.Int('num_layers', 2, 20)):\r\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\r\n",
        "                                            min_value=32,\r\n",
        "                                            max_value=512,\r\n",
        "                                            step=32),\r\n",
        "                               activation='relu'))\r\n",
        "    model.add(layers.Dense(1, activation='sigmoid'))\r\n",
        "    model.compile(\r\n",
        "        optimizer=keras.optimizers.Adam(\r\n",
        "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\r\n",
        "        loss='binary_crossentropy',\r\n",
        "        metrics=['accuracy'])\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "g42IrW0dwIsG"
      },
      "source": [
        "tuner = RandomSearch(\r\n",
        "    build_model,\r\n",
        "    objective='val_accuracy',\r\n",
        "    max_trials=5,\r\n",
        "    executions_per_trial=3,\r\n",
        "    directory='project',\r\n",
        "    project_name='Jane-Street-Market-Prediction')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GaQRybPVxEUt",
        "outputId": "1f23bb99-d794-4359-be26-097774790221"
      },
      "source": [
        "tuner.search_space_summary()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 4\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iEHcO9sexIy1",
        "outputId": "1a7865f1-9118-4207-9948-7d1bb46d7ff6"
      },
      "source": [
        "tuner.search(X_train, y_train,\r\n",
        "             epochs=5,\r\n",
        "             validation_data=(X_validation,y_validation))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Trial 5 Complete [00h 19m 23s]\n",
            "val_accuracy: 0.5016507506370544\n",
            "\n",
            "Best val_accuracy So Far: 0.5594387451807658\n",
            "Total elapsed time: 01h 49m 36s\n",
            "INFO:tensorflow:Oracle triggered exit\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PqHIulp3xVbG",
        "outputId": "405b13ec-ba35-47d3-af24-17a3e8f888fa"
      },
      "source": [
        "tuner.results_summary()"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Results summary\n",
            "Results in project/Jane-Street-Market-Prediction\n",
            "Showing 10 best trials\n",
            "Objective(name='val_accuracy', direction='max')\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 19\n",
            "units_0: 480\n",
            "units_1: 96\n",
            "learning_rate: 0.0001\n",
            "units_2: 224\n",
            "units_3: 480\n",
            "units_4: 480\n",
            "units_5: 32\n",
            "units_6: 352\n",
            "units_7: 96\n",
            "units_8: 480\n",
            "units_9: 192\n",
            "units_10: 416\n",
            "units_11: 480\n",
            "units_12: 192\n",
            "units_13: 384\n",
            "units_14: 288\n",
            "units_15: 256\n",
            "units_16: 320\n",
            "units_17: 320\n",
            "units_18: 32\n",
            "Score: 0.5594387451807658\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 15\n",
            "units_0: 64\n",
            "units_1: 224\n",
            "learning_rate: 0.0001\n",
            "units_2: 32\n",
            "units_3: 32\n",
            "units_4: 32\n",
            "units_5: 32\n",
            "units_6: 32\n",
            "units_7: 32\n",
            "units_8: 32\n",
            "units_9: 32\n",
            "units_10: 32\n",
            "units_11: 32\n",
            "units_12: 32\n",
            "units_13: 32\n",
            "units_14: 32\n",
            "Score: 0.5585107405980428\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 5\n",
            "units_0: 32\n",
            "units_1: 384\n",
            "learning_rate: 0.01\n",
            "units_2: 480\n",
            "units_3: 32\n",
            "units_4: 160\n",
            "units_5: 128\n",
            "units_6: 416\n",
            "units_7: 448\n",
            "units_8: 480\n",
            "units_9: 224\n",
            "units_10: 416\n",
            "units_11: 480\n",
            "units_12: 192\n",
            "units_13: 192\n",
            "units_14: 384\n",
            "Score: 0.5016507506370544\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 18\n",
            "units_0: 64\n",
            "units_1: 288\n",
            "learning_rate: 0.001\n",
            "units_2: 480\n",
            "units_3: 288\n",
            "units_4: 224\n",
            "units_5: 320\n",
            "units_6: 224\n",
            "units_7: 96\n",
            "units_8: 128\n",
            "units_9: 128\n",
            "units_10: 32\n",
            "units_11: 128\n",
            "units_12: 224\n",
            "units_13: 32\n",
            "units_14: 288\n",
            "units_15: 32\n",
            "units_16: 32\n",
            "units_17: 32\n",
            "Score: 0.5016507506370544\n",
            "Trial summary\n",
            "Hyperparameters:\n",
            "num_layers: 9\n",
            "units_0: 448\n",
            "units_1: 480\n",
            "learning_rate: 0.01\n",
            "units_2: 224\n",
            "units_3: 288\n",
            "units_4: 32\n",
            "units_5: 96\n",
            "units_6: 448\n",
            "units_7: 352\n",
            "units_8: 320\n",
            "units_9: 192\n",
            "units_10: 192\n",
            "units_11: 448\n",
            "units_12: 160\n",
            "units_13: 384\n",
            "units_14: 480\n",
            "units_15: 160\n",
            "units_16: 64\n",
            "units_17: 192\n",
            "units_18: 416\n",
            "Score: 0.5016507506370544\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JB4MgsudKi4K"
      },
      "source": [
        "best_model = tuner.get_best_models()[0]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gPF2XtuLKwSP"
      },
      "source": [
        "def build_model(hp):\r\n",
        "    model = keras.Sequential()\r\n",
        "    model.add(Dense(units = hp.Int(\"Input Layer\", min_value=32, max_value=512),input_shape = (X_train.shape[-1],),activation='relu',kernel_regularizer = 'l2'))\r\n",
        "    model.add(layers.Dropout(rate=hp.Float(\"Drop Out Input\", 0.1, 0.5, 0.1)))\r\n",
        "    for i in range(hp.Int('num_layers', 2, 20)):\r\n",
        "        model.add(layers.Dense(units=hp.Int('units_' + str(i),\r\n",
        "                                            min_value=32,\r\n",
        "                                            max_value=512,\r\n",
        "                                            step=32),\r\n",
        "                               activation='relu'))\r\n",
        "        model.add(layers.Dropout(rate=hp.Float(\"Drop Out \" + str(i), 0.1, 0.5, 0.1)))\r\n",
        "        model.add(layers.BatchNormalization())\r\n",
        "    model.add(layers.Dense(1))\r\n",
        "    model.add(layers.BatchNormalization())\r\n",
        "    model.add(layers.Activation(\"sigmoid\"))\r\n",
        "    model.compile(\r\n",
        "        optimizer=keras.optimizers.Adam(\r\n",
        "            hp.Choice('learning_rate', [1e-2, 1e-3, 1e-4])),\r\n",
        "        loss='binary_crossentropy',\r\n",
        "        metrics=['accuracy'])\r\n",
        "    return model"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "blKHCDX_LBDf"
      },
      "source": [
        "tuner2 = RandomSearch(\r\n",
        "    build_model,\r\n",
        "    objective='val_accuracy',\r\n",
        "    max_trials=5,\r\n",
        "    executions_per_trial=3,\r\n",
        "    directory='project2',\r\n",
        "    project_name='Jane-Street-Market-Prediction')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "UORo1TfeNhDY",
        "outputId": "da7451c7-486a-4cd9-e48f-6cada5229f1c"
      },
      "source": [
        "tuner.search_space_summary()\r\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Search space summary\n",
            "Default search space size: 21\n",
            "num_layers (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 2, 'max_value': 20, 'step': 1, 'sampling': None}\n",
            "units_0 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_1 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "learning_rate (Choice)\n",
            "{'default': 0.01, 'conditions': [], 'values': [0.01, 0.001, 0.0001], 'ordered': True}\n",
            "units_2 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_3 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_4 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_5 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_6 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_7 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_8 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_9 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_10 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_11 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_12 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_13 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_14 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_15 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_16 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_17 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n",
            "units_18 (Int)\n",
            "{'default': None, 'conditions': [], 'min_value': 32, 'max_value': 512, 'step': 32, 'sampling': None}\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q0b_WJyQO0_X",
        "outputId": "8b267925-d2b1-4d22-81d3-cc92c194e88c"
      },
      "source": [
        "tuner2.search(X_train, y_train,\r\n",
        "             epochs=5,\r\n",
        "             validation_data=(X_validation,y_validation))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\n",
            "Search: Running Trial #1\n",
            "\n",
            "Hyperparameter    |Value             |Best Value So Far \n",
            "Input Layer       |157               |?                 \n",
            "Drop Out Input    |0.1               |?                 \n",
            "num_layers        |19                |?                 \n",
            "units_0           |96                |?                 \n",
            "Drop Out 0        |0.1               |?                 \n",
            "units_1           |224               |?                 \n",
            "Drop Out 1        |0.1               |?                 \n",
            "learning_rate     |0.001             |?                 \n",
            "\n",
            "Epoch 1/5\n",
            "27783/27783 [==============================] - 306s 11ms/step - loss: 1.1447 - accuracy: 0.5022 - val_loss: 0.7032 - val_accuracy: 0.5190\n",
            "Epoch 2/5\n",
            "27783/27783 [==============================] - 300s 11ms/step - loss: 0.7030 - accuracy: 0.5163 - val_loss: 0.6970 - val_accuracy: 0.5107\n",
            "Epoch 3/5\n",
            "27783/27783 [==============================] - 298s 11ms/step - loss: 0.6991 - accuracy: 0.5178 - val_loss: 0.7025 - val_accuracy: 0.5089\n",
            "Epoch 4/5\n",
            "27783/27783 [==============================] - 302s 11ms/step - loss: 0.6991 - accuracy: 0.5158 - val_loss: 0.7024 - val_accuracy: 0.5321\n",
            "Epoch 5/5\n",
            "27783/27783 [==============================] - 314s 11ms/step - loss: 0.6996 - accuracy: 0.5261 - val_loss: 0.6959 - val_accuracy: 0.5307\n",
            "Epoch 1/5\n",
            "25030/27783 [==========================>...] - ETA: 30s - loss: 1.1858 - accuracy: 0.5014"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "T0G-vFmdO6se"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}