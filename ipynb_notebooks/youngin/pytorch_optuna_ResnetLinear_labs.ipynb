{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "pytorch-optuna-ResnetLinear-labs",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "a461305ccb9c4bd1bb327230df1f462d": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_7e95676b8cbb45ff94ae52b0fe4704d0",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_f71d706cc10143098fe7224972ade495",
              "IPY_MODEL_ad6695ef5e2b431493337bb250fed038"
            ]
          }
        },
        "7e95676b8cbb45ff94ae52b0fe4704d0": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "f71d706cc10143098fe7224972ade495": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_b05ad2876edc49708d870157d73a3d09",
            "_dom_classes": [],
            "description": "  0%",
            "_model_name": "FloatProgressModel",
            "bar_style": "",
            "max": 100,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 0,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_124a4f2f89fc465aaae8da5a911f3c3b"
          }
        },
        "ad6695ef5e2b431493337bb250fed038": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_8be8ade2b78c40bbb52547fc3e45298c",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 0/100 [00:00&lt;?, ?it/s]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_b6837623a5ab4d6abea18a10d23ad989"
          }
        },
        "b05ad2876edc49708d870157d73a3d09": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "124a4f2f89fc465aaae8da5a911f3c3b": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "8be8ade2b78c40bbb52547fc3e45298c": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "b6837623a5ab4d6abea18a10d23ad989": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Pkyy2FlNoORt",
        "outputId": "4f4a49ab-97e4-42ab-8743-edbdeafb77e3"
      },
      "source": [
        "\"\"\"Colab Drive Connection\"\"\"\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mQHqdTmNoaf3",
        "outputId": "c1dcdcd1-f38d-48d5-ea6a-7d1d78e8b66a"
      },
      "source": [
        "import warnings\r\n",
        "import os \r\n",
        "\r\n",
        "from collections import defaultdict\r\n",
        "from copy import deepcopy\r\n",
        "\r\n",
        "import numpy as np\r\n",
        "import pandas as pd\r\n",
        "import matplotlib.pyplot as plt\r\n",
        "import matplotlib.gridspec as gridspec\r\n",
        "import seaborn as sns\r\n",
        "\r\n",
        "import networkx as nx\r\n",
        "import scipy.cluster.hierarchy as sch\r\n",
        "from scipy.cluster.hierarchy import fcluster\r\n",
        "\r\n",
        "import random\r\n",
        "\r\n",
        "from tqdm import tqdm_notebook\r\n",
        "\r\n",
        "from sklearn.metrics import roc_auc_score\r\n",
        "from sklearn.model_selection import train_test_split\r\n",
        "\r\n",
        "import torch\r\n",
        "import torch.nn as nn\r\n",
        "import torch.optim as optim\r\n",
        "from torch.utils.data import Dataset, DataLoader\r\n",
        "from torch.nn import functional as F\r\n",
        "\r\n",
        "# install datatable\r\n",
        "!pip install datatable\r\n",
        "import datatable as dt\r\n",
        "\r\n",
        "from numba import njit\r\n",
        "\r\n",
        "import gc\r\n",
        "\r\n",
        "warnings.simplefilter(action=\"ignore\")\r\n",
        "\r\n",
        "# project_home = \"/kaggle/input/jane-street-market-prediction\"\r\n",
        "# data_home = project_home\r\n",
        "\r\n",
        "project_home = \"/gdrive/MyDrive/colab/jane-street-market-prediction\"\r\n",
        "data_home = os.path.join(project_home, \"input/data\")\r\n",
        "model_home = os.path.join(project_home, \"output/model\")\r\n",
        "gs_home = os.path.join(project_home, \"output/grid_search\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting datatable\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/80/cb/21810c43b687a19d194c372192049f535fba28c55ce76d37e7e407159c52/datatable-0.11.1-cp36-cp36m-manylinux2010_x86_64.whl (83.7MB)\n",
            "\u001b[K     |████████████████████████████████| 83.7MB 65kB/s \n",
            "\u001b[?25hInstalling collected packages: datatable\n",
            "Successfully installed datatable-0.11.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "gB3wbBBdgLRn"
      },
      "source": [
        "https://github.com/FernandoLpz/Optuna-Sklearn-PyTorch/blob/master/optuna_pytorch.py\r\n",
        "\r\n",
        "https://titanwolf.org/Network/Articles/Article?AID=172eb24c-217d-4c4e-9623-e0e68349f4e2#gsc.tab=0"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fnsxORdUaQGW",
        "outputId": "ab0174d3-60a6-48a6-a892-07bf556c36ec"
      },
      "source": [
        "# https://titanwolf.org/Network/Articles/Article?AID=172eb24c-217d-4c4e-9623-e0e68349f4e2#gsc.tab=0\r\n",
        "!pip install optuna"
      ],
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting optuna\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/88/9c53460b97c61bce926dfe9dce51e4887c283416ff89ed30af0b73f44efa/optuna-2.5.0-py3-none-any.whl (287kB)\n",
            "\r\u001b[K     |█▏                              | 10kB 29.7MB/s eta 0:00:01\r\u001b[K     |██▎                             | 20kB 35.5MB/s eta 0:00:01\r\u001b[K     |███▍                            | 30kB 21.8MB/s eta 0:00:01\r\u001b[K     |████▋                           | 40kB 16.1MB/s eta 0:00:01\r\u001b[K     |█████▊                          | 51kB 14.6MB/s eta 0:00:01\r\u001b[K     |██████▉                         | 61kB 11.6MB/s eta 0:00:01\r\u001b[K     |████████                        | 71kB 12.3MB/s eta 0:00:01\r\u001b[K     |█████████▏                      | 81kB 13.6MB/s eta 0:00:01\r\u001b[K     |██████████▎                     | 92kB 12.3MB/s eta 0:00:01\r\u001b[K     |███████████▍                    | 102kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████▌                   | 112kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████▊                  | 122kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████▉                 | 133kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████                | 143kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████               | 153kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████▎             | 163kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████▍            | 174kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████▌           | 184kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 194kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████▉         | 204kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████        | 215kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 225kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▎     | 235kB 12.2MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▍    | 245kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 256kB 12.2MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▋  | 266kB 12.2MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▉ | 276kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 286kB 12.2MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 296kB 12.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: tqdm in /usr/local/lib/python3.6/dist-packages (from optuna) (4.41.1)\n",
            "Collecting cmaes>=0.6.0\n",
            "  Downloading https://files.pythonhosted.org/packages/01/1f/43b01223a0366171f474320c6e966c39a11587287f098a5f09809b45e05f/cmaes-0.8.2-py3-none-any.whl\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from optuna) (1.19.5)\n",
            "Requirement already satisfied: scipy!=1.4.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.4.1)\n",
            "Collecting alembic\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/53/daab5c96e22e9ed1c9f8ca4e3256e72213ade42d519b6254c32e59610967/alembic-1.5.4.tar.gz (1.1MB)\n",
            "\u001b[K     |████████████████████████████████| 1.1MB 25.8MB/s \n",
            "\u001b[?25hCollecting colorlog\n",
            "  Downloading https://files.pythonhosted.org/packages/5e/39/0230290df0519d528d8d0ffdfd900150ed24e0076d13b1f19e279444aab1/colorlog-4.7.2-py2.py3-none-any.whl\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.6/dist-packages (from optuna) (1.0.0)\n",
            "Requirement already satisfied: sqlalchemy>=1.1.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (1.3.23)\n",
            "Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.6/dist-packages (from optuna) (20.9)\n",
            "Collecting cliff\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a2/d6/7d9acb68a77acd140be7fececb7f2701b2a29d2da9c54184cb8f93509590/cliff-3.7.0-py3-none-any.whl (80kB)\n",
            "\u001b[K     |████████████████████████████████| 81kB 12.7MB/s \n",
            "\u001b[?25hCollecting Mako\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/5c/db/2d2d88b924aa4674a080aae83b59ea19d593250bfe5ed789947c21736785/Mako-1.1.4.tar.gz (479kB)\n",
            "\u001b[K     |████████████████████████████████| 481kB 53.0MB/s \n",
            "\u001b[?25hCollecting python-editor>=0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/c6/d3/201fc3abe391bbae6606e6f1d598c15d367033332bd54352b12f35513717/python_editor-1.0.4-py3-none-any.whl\n",
            "Requirement already satisfied: python-dateutil in /usr/local/lib/python3.6/dist-packages (from alembic->optuna) (2.8.1)\n",
            "Requirement already satisfied: pyparsing>=2.0.2 in /usr/local/lib/python3.6/dist-packages (from packaging>=20.0->optuna) (2.4.7)\n",
            "Requirement already satisfied: PrettyTable>=0.7.2 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (2.0.0)\n",
            "Collecting stevedore>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d4/49/b602307aeac3df3384ff1fcd05da9c0376c622a6c48bb5325f28ab165b57/stevedore-3.3.0-py3-none-any.whl (49kB)\n",
            "\u001b[K     |████████████████████████████████| 51kB 8.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=3.12 in /usr/local/lib/python3.6/dist-packages (from cliff->optuna) (3.13)\n",
            "Collecting cmd2>=1.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/15/8b/15061b32332bb35ea2a2f6263d0f616779d576e82739ec8e7fcf3c94abf5/cmd2-1.5.0-py3-none-any.whl (133kB)\n",
            "\u001b[K     |████████████████████████████████| 143kB 50.2MB/s \n",
            "\u001b[?25hCollecting pbr!=2.1.0,>=2.0.0\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fb/48/69046506f6ac61c1eaa9a0d42d22d54673b69e176d30ca98e3f61513e980/pbr-5.5.1-py2.py3-none-any.whl (106kB)\n",
            "\u001b[K     |████████████████████████████████| 112kB 80.3MB/s \n",
            "\u001b[?25hRequirement already satisfied: MarkupSafe>=0.9.2 in /usr/local/lib/python3.6/dist-packages (from Mako->alembic->optuna) (1.1.1)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil->alembic->optuna) (1.15.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from PrettyTable>=0.7.2->cliff->optuna) (53.0.0)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.6/dist-packages (from PrettyTable>=0.7.2->cliff->optuna) (0.2.5)\n",
            "Requirement already satisfied: importlib-metadata>=1.7.0; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from stevedore>=2.0.1->cliff->optuna) (3.4.0)\n",
            "Collecting colorama>=0.3.7\n",
            "  Downloading https://files.pythonhosted.org/packages/44/98/5b86278fbbf250d239ae0ecb724f8572af1c91f4a11edf4d36a206189440/colorama-0.4.4-py2.py3-none-any.whl\n",
            "Collecting pyperclip>=1.6\n",
            "  Downloading https://files.pythonhosted.org/packages/6f/4c/0b1d507ad7e8bc31d690d04b4f475e74c2002d060f7994ce8c09612df707/pyperclip-1.8.1.tar.gz\n",
            "Requirement already satisfied: attrs>=16.3.0 in /usr/local/lib/python3.6/dist-packages (from cmd2>=1.0.0->cliff->optuna) (20.3.0)\n",
            "Requirement already satisfied: zipp>=0.5 in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna) (3.4.0)\n",
            "Requirement already satisfied: typing-extensions>=3.6.4; python_version < \"3.8\" in /usr/local/lib/python3.6/dist-packages (from importlib-metadata>=1.7.0; python_version < \"3.8\"->stevedore>=2.0.1->cliff->optuna) (3.7.4.3)\n",
            "Building wheels for collected packages: alembic, Mako, pyperclip\n",
            "  Building wheel for alembic (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for alembic: filename=alembic-1.5.4-py2.py3-none-any.whl size=156314 sha256=6fa474fd6db16f63fcdce056389d0b2366c9631f42d6b02e3f79e5dbac2a215c\n",
            "  Stored in directory: /root/.cache/pip/wheels/fd/2d/ec/5a1b1e2363ed68392d292d215facf588d5448198edd8078bc1\n",
            "  Building wheel for Mako (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Mako: filename=Mako-1.1.4-py2.py3-none-any.whl size=75675 sha256=2ba523ea244d3742c0e371546cbdeec9794fa91f5b0ddb5bb1129858b8eae3b4\n",
            "  Stored in directory: /root/.cache/pip/wheels/ad/10/d3/aeb26e20d19045e2a68e5d3cbb57432e11b5d9c92c99f98d47\n",
            "  Building wheel for pyperclip (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for pyperclip: filename=pyperclip-1.8.1-cp36-none-any.whl size=11120 sha256=c293c75f2906e682edbc62499c139af396597ffd2548a670477e81674bc10891\n",
            "  Stored in directory: /root/.cache/pip/wheels/44/10/3a/c830e9bb3db2c93274ea1f213a41fabde0d8cf3794251fad0c\n",
            "Successfully built alembic Mako pyperclip\n",
            "Installing collected packages: cmaes, Mako, python-editor, alembic, colorlog, pbr, stevedore, colorama, pyperclip, cmd2, cliff, optuna\n",
            "Successfully installed Mako-1.1.4 alembic-1.5.4 cliff-3.7.0 cmaes-0.8.2 cmd2-1.5.0 colorama-0.4.4 colorlog-4.7.2 optuna-2.5.0 pbr-5.5.1 pyperclip-1.8.1 python-editor-1.0.4 stevedore-3.3.0\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XO3GVDBeoeM1"
      },
      "source": [
        "entire_seed = 1029\r\n",
        "\r\n",
        "def seed_torch(seed=1029):\r\n",
        "    random.seed(seed)\r\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\r\n",
        "    np.random.seed(seed)\r\n",
        "    torch.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed(seed)\r\n",
        "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\r\n",
        "    torch.backends.cudnn.benchmark = False\r\n",
        "#     torch.backends.cudnn.deterministic = True\r\n",
        "    torch.backends.cudnn.deterministic = False\r\n",
        "    \r\n",
        "seed_torch(entire_seed)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fSss_fkAoewy"
      },
      "source": [
        "train_file = os.path.join(data_home,'train.csv')\r\n",
        "features_file = os.path.join(data_home,'features.csv')\r\n",
        "example_test_file = os.path.join(data_home,'example_test.csv')\r\n",
        "example_sample_submission_file = os.path.join(data_home,'example_sample_submission.csv')\r\n",
        "\r\n",
        "train_data_datatable = dt.fread(train_file)\r\n",
        "\r\n",
        "df_train = train_data_datatable.to_pandas()\r\n",
        "df_features = pd.read_csv(features_file)\r\n",
        "df_example_test = pd.read_csv(example_test_file)\r\n",
        "df_example_sample_submission = pd.read_csv(example_sample_submission_file)"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EfWSyoVaogSk"
      },
      "source": [
        "features = [ col for col in df_train.columns if \"feature\" in col ]\r\n",
        "resps = [ col for col in df_train.columns if \"resp\" in col ]\r\n",
        "target_resp = [resp_ for resp_ in resps if \"_\" not in resp_]\r\n",
        "target = [\"weight\"] + target_resp + features "
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BvJ4EJefohR-",
        "outputId": "7bdf5d4e-00da-4340-8714-0fcc970ca7e0"
      },
      "source": [
        "\"\"\"\r\n",
        "Reduce Memory Usage by 75%\r\n",
        "https://www.kaggle.com/tomwarrens/nan-values-depending-on-time-of-day\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "## Reduce Memory\r\n",
        "\r\n",
        "def reduce_memory_usage(df):\r\n",
        "    \r\n",
        "    start_memory = df.memory_usage().sum() / 1024**2\r\n",
        "    print(f\"Memory usage of dataframe is {start_memory} MB\")\r\n",
        "    \r\n",
        "    for col in df.columns:\r\n",
        "        col_type = df[col].dtype\r\n",
        "        \r\n",
        "        if col_type != 'object':\r\n",
        "            c_min = df[col].min()\r\n",
        "            c_max = df[col].max()\r\n",
        "            \r\n",
        "            if str(col_type)[:3] == 'int':\r\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\r\n",
        "                    df[col] = df[col].astype(np.int8)\r\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\r\n",
        "                    df[col] = df[col].astype(np.int16)\r\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\r\n",
        "                    df[col] = df[col].astype(np.int32)\r\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\r\n",
        "                    df[col] = df[col].astype(np.int64)\r\n",
        "            \r\n",
        "            else:\r\n",
        "#                 reducing float16 for calculating numpy.nanmean\r\n",
        "#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\r\n",
        "#                     df[col] = df[col].astype(np.float16)\r\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\r\n",
        "                    df[col] = df[col].astype(np.float32)\r\n",
        "                else:\r\n",
        "                    pass\r\n",
        "        else:\r\n",
        "            df[col] = df[col].astype('category')\r\n",
        "    \r\n",
        "    end_memory = df.memory_usage().sum() / 1024**2\r\n",
        "    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\r\n",
        "    print(f\"Reduced by {100 * (start_memory - end_memory) / start_memory} % \")\r\n",
        "    return df\r\n",
        "\r\n",
        "df_train = reduce_memory_usage(df_train)\r\n",
        "df_train.info()"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2489.4869804382324 MB\n",
            "Memory usage of dataframe after reduction 1247.0233011245728 MB\n",
            "Reduced by 49.908422461199 % \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2390491 entries, 0 to 2390490\n",
            "Columns: 138 entries, date to ts_id\n",
            "dtypes: float32(135), int16(1), int32(1), int8(1)\n",
            "memory usage: 1.2 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Zhwf_DPjoirS"
      },
      "source": [
        "# drop before 85days\r\n",
        "df_train = df_train.loc[df_train.date>85]\r\n",
        "# drop weight 0 for training\r\n",
        "df_train = df_train.loc[df_train.weight > 0]\r\n",
        "\r\n",
        "# df_labels = df_train[['date','weight','resp_1','resp_2','resp_3','resp_4','resp']]\r\n",
        "\r\n",
        "# df_train = df_train.drop(df_labels.columns,axis=1)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "la3gybr8ojx7"
      },
      "source": [
        "\"\"\"\r\n",
        "The codes from 'Optimise Speed of Filling-NaN Function'\r\n",
        "https://www.kaggle.com/gogo827jz/optimise-speed-of-filling-nan-function\r\n",
        "\"\"\"\r\n",
        "\r\n",
        "def for_loop(method, matrix, values):\r\n",
        "    for i in range(matrix.shape[0]):\r\n",
        "        matrix[i] = method(matrix[i], values)\r\n",
        "    return matrix\r\n",
        "\r\n",
        "def for_loop_ffill(method, matrix):\r\n",
        "    tmp = np.zeros(matrix.shape[1],dtype=np.float32)\r\n",
        "    for i in range(matrix.shape[0]):\r\n",
        "        matrix[i] = method(matrix[i], tmp)\r\n",
        "        tmp = matrix[i]\r\n",
        "    return matrix\r\n",
        "\r\n",
        "@njit\r\n",
        "def fillna_npwhere_njit(array, values):\r\n",
        "    if np.isnan(array.sum()):\r\n",
        "        array = np.where(np.isnan(array), values, array)\r\n",
        "    return array"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EDEuzCrEokro",
        "outputId": "bb9f35c5-e500-414a-e259-32389ca01734"
      },
      "source": [
        "# converting numpy for efficient calcualtion.\r\n",
        "# ft 1~129\r\n",
        "np_ft_train = df_train.loc[:,features[1:]].values\r\n",
        "np_ft_train.shape\r\n",
        "\r\n",
        "# ft 0\r\n",
        "# np_train_ft0 = df_train.loc[:,features[0]].values"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1571415, 129)"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sHTK0yrKolky"
      },
      "source": [
        "f_mean = np.nanmean(np_ft_train,axis=0)"
      ],
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fQ9ZH_b4omeK"
      },
      "source": [
        "np_train = df_train.values"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "50K0K0mooot0",
        "outputId": "3160c928-dfb1-4e40-b53e-91e6bf401bd5"
      },
      "source": [
        "print('fillna_npwhere_njit (mean-filling):')\r\n",
        "np_train[:,8:-1] = for_loop(fillna_npwhere_njit, np_train[:,8:-1], f_mean)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fillna_npwhere_njit (mean-filling):\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "JGNVk8Niopp0"
      },
      "source": [
        "dict_features = {col:idx for idx, col in enumerate(df_train.columns.tolist())}"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ox2oNmBPoqv_"
      },
      "source": [
        "np_d_w = np_train[:,:2]\r\n",
        "# ['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp']\r\n",
        "idx_resps = list()\r\n",
        "for resp in resps:\r\n",
        "    idx_col = dict_features[resp]\r\n",
        "    idx_resps.append(idx_col)\r\n",
        "np_resps = np_train[:,idx_resps]"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hAcWsZiTotn9",
        "outputId": "147ab7ea-a55d-48d2-9226-8c5b5968aa7c"
      },
      "source": [
        "resps_prcntls = [50, 49, 49, 50, 50]\r\n",
        "resps_prcntls = [np.percentile(np_resps[:,idx], prcntls) for idx, prcntls in enumerate(resps_prcntls)]\r\n",
        "resps_prcntls"
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[2.3540282199974172e-05,\n",
              " -2.6968382262566605e-05,\n",
              " -6.920687970705338e-05,\n",
              " 7.239638944156468e-05,\n",
              " 4.7192643251037225e-05]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "COT6wiYlovTP"
      },
      "source": [
        "list_resps = list()\r\n",
        "for idx, resps_prcntl in enumerate(resps_prcntls):\r\n",
        "    result = list(map(lambda x: 1 if x > resps_prcntl else 0, np_resps[:,idx]))\r\n",
        "    list_resps.append(result)\r\n",
        "np_targets = np.stack(list_resps).T"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "uRgCf91aowKo"
      },
      "source": [
        "idx_target = [(\"resp_\" not in key) and (\"ts_\" not in key) for key in dict_features.keys()]\r\n",
        "idx_target = np.arange(np_train.shape[1])[idx_target]\r\n",
        "X_np_train = np_train[:,idx_target]"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "G0SDJyk4oxJw"
      },
      "source": [
        "X = X_np_train\r\n",
        "y = np_targets"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "hBfKXHyOo8yI"
      },
      "source": [
        "from collections import Counter, defaultdict\r\n",
        "from sklearn import model_selection\r\n",
        "\r\n",
        "# ---- StratifiedGroupKFold ----\r\n",
        "class StratifiedGroupKFold(object):\r\n",
        "    \"\"\"\r\n",
        "    StratifiedGroupKFold with random shuffle with a sklearn-like structure\r\n",
        "    \"\"\"\r\n",
        "\r\n",
        "    def __init__(self, n_splits=4, shuffle=True, random_state=42):\r\n",
        "        self.n_splits = n_splits\r\n",
        "        self.shuffle = shuffle\r\n",
        "        self.random_state = random_state\r\n",
        "\r\n",
        "    def get_n_splits(self, X=None, y=None, group=None):\r\n",
        "        return self.n_splits\r\n",
        "\r\n",
        "    def split(self, X, y, group):\r\n",
        "        labels_num = np.max(y) + 1\r\n",
        "        y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\r\n",
        "        y_distr = Counter()\r\n",
        "        # groups = X[group].values\r\n",
        "        groups = group\r\n",
        "        for label, g in zip(y, groups):\r\n",
        "            y_counts_per_group[g][label] += 1\r\n",
        "            y_distr[label] += 1\r\n",
        "\r\n",
        "        y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\r\n",
        "        groups_per_fold = defaultdict(set)\r\n",
        "\r\n",
        "        def eval_y_counts_per_fold(y_counts, fold):\r\n",
        "            y_counts_per_fold[fold] += y_counts\r\n",
        "            std_per_label = []\r\n",
        "            for label in range(labels_num):\r\n",
        "                label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(self.n_splits)])\r\n",
        "                std_per_label.append(label_std)\r\n",
        "            y_counts_per_fold[fold] -= y_counts\r\n",
        "            return np.mean(std_per_label)\r\n",
        "        \r\n",
        "        groups_and_y_counts = list(y_counts_per_group.items())\r\n",
        "        random.Random(self.random_state).shuffle(groups_and_y_counts)\r\n",
        "\r\n",
        "        for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\r\n",
        "            best_fold = None\r\n",
        "            min_eval = None\r\n",
        "            for i in range(self.n_splits):\r\n",
        "                fold_eval = eval_y_counts_per_fold(y_counts, i)\r\n",
        "                if min_eval is None or fold_eval < min_eval:\r\n",
        "                    min_eval = fold_eval\r\n",
        "                    best_fold = i\r\n",
        "            y_counts_per_fold[best_fold] += y_counts\r\n",
        "            groups_per_fold[best_fold].add(g)\r\n",
        "\r\n",
        "        all_groups = set(groups)\r\n",
        "        for i in range(self.n_splits):\r\n",
        "            train_groups = all_groups - groups_per_fold[i]\r\n",
        "            test_groups = groups_per_fold[i]\r\n",
        "\r\n",
        "            train_idx = [i for i, g in enumerate(groups) if g in train_groups]\r\n",
        "            test_idx = [i for i, g in enumerate(groups) if g in test_groups]\r\n",
        "\r\n",
        "            yield train_idx, test_idx"
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "twv7hakjo-hI"
      },
      "source": [
        "cv = StratifiedGroupKFold(n_splits=3, random_state=entire_seed)"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uBQkYeuyo_ub",
        "outputId": "0a65d128-22b2-41ef-c176-8a4807204f6c"
      },
      "source": [
        "cv_idxes = [ (train_idx, test_idx) for train_idx, test_idx in cv.split(X, y[:,-1], group=X[:,0])]\r\n",
        "for idx, cv_idx in enumerate(cv_idxes):\r\n",
        "    train_idx, test_idx = cv_idx\r\n",
        "    train_dates = np.unique(X[train_idx, 0]) \r\n",
        "    test_dates = np.unique(X[test_idx, 0])\r\n",
        "    print(f\"fold {idx+1}\"+\"*\"*30)\r\n",
        "    print(train_dates)\r\n",
        "    print(test_dates)"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 1******************************\n",
            "[ 87.  89.  90.  92.  93.  95.  96.  98. 100. 101. 102. 103. 104. 107.\n",
            " 109. 110. 111. 113. 116. 117. 118. 119. 120. 122. 124. 126. 127. 129.\n",
            " 131. 133. 135. 137. 138. 139. 140. 141. 142. 143. 144. 145. 146. 147.\n",
            " 148. 150. 151. 152. 156. 157. 161. 162. 163. 164. 166. 168. 170. 172.\n",
            " 173. 174. 175. 177. 181. 183. 184. 185. 188. 193. 195. 196. 197. 203.\n",
            " 204. 205. 206. 207. 208. 209. 210. 211. 212. 213. 214. 215. 216. 217.\n",
            " 218. 220. 222. 224. 225. 228. 231. 233. 234. 237. 239. 240. 242. 243.\n",
            " 246. 247. 248. 250. 251. 252. 253. 254. 256. 257. 260. 262. 263. 264.\n",
            " 265. 266. 267. 268. 269. 272. 274. 275. 276. 278. 279. 280. 281. 284.\n",
            " 285. 287. 288. 291. 292. 295. 296. 297. 298. 300. 301. 303. 304. 305.\n",
            " 306. 307. 308. 310. 311. 313. 318. 320. 321. 323. 324. 325. 327. 329.\n",
            " 331. 332. 333. 335. 336. 338. 339. 340. 341. 342. 344. 345. 346. 347.\n",
            " 348. 349. 350. 351. 353. 354. 355. 357. 359. 360. 362. 363. 364. 365.\n",
            " 367. 368. 369. 370. 371. 373. 374. 375. 377. 378. 379. 380. 381. 382.\n",
            " 384. 388. 389. 390. 393. 394. 395. 396. 401. 405. 408. 409. 411. 413.\n",
            " 414. 415. 417. 418. 419. 420. 421. 423. 424. 425. 427. 428. 430. 431.\n",
            " 433. 434. 435. 437. 438. 440. 441. 442. 443. 444. 445. 447. 448. 451.\n",
            " 453. 454. 455. 456. 458. 459. 460. 461. 462. 463. 464. 465. 466. 467.\n",
            " 468. 469. 470. 472. 474. 475. 476. 477. 478. 481. 482. 483. 484. 485.\n",
            " 486. 490. 496. 497. 498. 499.]\n",
            "[ 86.  88.  91.  94.  97.  99. 105. 106. 108. 112. 114. 115. 121. 123.\n",
            " 125. 128. 130. 132. 134. 136. 149. 153. 154. 155. 158. 159. 160. 165.\n",
            " 167. 169. 171. 176. 178. 179. 180. 182. 186. 187. 189. 190. 191. 192.\n",
            " 194. 198. 199. 200. 201. 202. 219. 221. 223. 226. 227. 229. 230. 232.\n",
            " 235. 236. 238. 241. 244. 245. 249. 255. 258. 259. 261. 270. 271. 273.\n",
            " 277. 282. 283. 286. 289. 290. 293. 294. 299. 302. 309. 312. 314. 315.\n",
            " 316. 317. 319. 322. 326. 328. 330. 334. 337. 343. 352. 356. 358. 361.\n",
            " 366. 372. 376. 383. 385. 386. 387. 391. 392. 397. 398. 399. 400. 402.\n",
            " 403. 404. 406. 407. 410. 412. 416. 422. 426. 429. 432. 436. 439. 446.\n",
            " 449. 450. 452. 457. 471. 473. 479. 480. 487. 488. 489. 491. 492. 493.\n",
            " 494. 495.]\n",
            "fold 2******************************\n",
            "[ 86.  87.  88.  90.  91.  92.  93.  94.  97.  98.  99. 100. 103. 105.\n",
            " 106. 107. 108. 109. 111. 112. 113. 114. 115. 116. 117. 118. 119. 120.\n",
            " 121. 123. 124. 125. 128. 129. 130. 132. 133. 134. 135. 136. 137. 142.\n",
            " 144. 146. 148. 149. 152. 153. 154. 155. 158. 159. 160. 161. 163. 165.\n",
            " 166. 167. 169. 170. 171. 172. 176. 177. 178. 179. 180. 182. 186. 187.\n",
            " 189. 190. 191. 192. 194. 195. 197. 198. 199. 200. 201. 202. 206. 207.\n",
            " 209. 213. 215. 216. 218. 219. 220. 221. 223. 226. 227. 229. 230. 231.\n",
            " 232. 235. 236. 237. 238. 240. 241. 242. 244. 245. 246. 249. 251. 252.\n",
            " 255. 257. 258. 259. 261. 263. 266. 267. 269. 270. 271. 272. 273. 274.\n",
            " 276. 277. 278. 280. 281. 282. 283. 286. 287. 289. 290. 291. 292. 293.\n",
            " 294. 295. 298. 299. 300. 301. 302. 303. 305. 308. 309. 312. 313. 314.\n",
            " 315. 316. 317. 318. 319. 320. 322. 324. 326. 328. 329. 330. 334. 337.\n",
            " 339. 340. 343. 344. 345. 347. 348. 349. 352. 353. 354. 355. 356. 358.\n",
            " 359. 361. 364. 366. 368. 371. 372. 373. 374. 376. 381. 382. 383. 384.\n",
            " 385. 386. 387. 388. 390. 391. 392. 393. 394. 395. 396. 397. 398. 399.\n",
            " 400. 401. 402. 403. 404. 405. 406. 407. 408. 409. 410. 411. 412. 416.\n",
            " 419. 422. 424. 426. 427. 428. 429. 432. 433. 436. 439. 442. 443. 444.\n",
            " 445. 446. 447. 449. 450. 451. 452. 457. 458. 460. 461. 462. 463. 468.\n",
            " 470. 471. 472. 473. 474. 475. 476. 477. 478. 479. 480. 481. 482. 483.\n",
            " 485. 487. 488. 489. 491. 492. 493. 494. 495. 497.]\n",
            "[ 89.  95.  96. 101. 102. 104. 110. 122. 126. 127. 131. 138. 139. 140.\n",
            " 141. 143. 145. 147. 150. 151. 156. 157. 162. 164. 168. 173. 174. 175.\n",
            " 181. 183. 184. 185. 188. 193. 196. 203. 204. 205. 208. 210. 211. 212.\n",
            " 214. 217. 222. 224. 225. 228. 233. 234. 239. 243. 247. 248. 250. 253.\n",
            " 254. 256. 260. 262. 264. 265. 268. 275. 279. 284. 285. 288. 296. 297.\n",
            " 304. 306. 307. 310. 311. 321. 323. 325. 327. 331. 332. 333. 335. 336.\n",
            " 338. 341. 342. 346. 350. 351. 357. 360. 362. 363. 365. 367. 369. 370.\n",
            " 375. 377. 378. 379. 380. 389. 413. 414. 415. 417. 418. 420. 421. 423.\n",
            " 425. 430. 431. 434. 435. 437. 438. 440. 441. 448. 453. 454. 455. 456.\n",
            " 459. 464. 465. 466. 467. 469. 484. 486. 490. 496. 498. 499.]\n",
            "fold 3******************************\n",
            "[ 86.  88.  89.  91.  94.  95.  96.  97.  99. 101. 102. 104. 105. 106.\n",
            " 108. 110. 112. 114. 115. 121. 122. 123. 125. 126. 127. 128. 130. 131.\n",
            " 132. 134. 136. 138. 139. 140. 141. 143. 145. 147. 149. 150. 151. 153.\n",
            " 154. 155. 156. 157. 158. 159. 160. 162. 164. 165. 167. 168. 169. 171.\n",
            " 173. 174. 175. 176. 178. 179. 180. 181. 182. 183. 184. 185. 186. 187.\n",
            " 188. 189. 190. 191. 192. 193. 194. 196. 198. 199. 200. 201. 202. 203.\n",
            " 204. 205. 208. 210. 211. 212. 214. 217. 219. 221. 222. 223. 224. 225.\n",
            " 226. 227. 228. 229. 230. 232. 233. 234. 235. 236. 238. 239. 241. 243.\n",
            " 244. 245. 247. 248. 249. 250. 253. 254. 255. 256. 258. 259. 260. 261.\n",
            " 262. 264. 265. 268. 270. 271. 273. 275. 277. 279. 282. 283. 284. 285.\n",
            " 286. 288. 289. 290. 293. 294. 296. 297. 299. 302. 304. 306. 307. 309.\n",
            " 310. 311. 312. 314. 315. 316. 317. 319. 321. 322. 323. 325. 326. 327.\n",
            " 328. 330. 331. 332. 333. 334. 335. 336. 337. 338. 341. 342. 343. 346.\n",
            " 350. 351. 352. 356. 357. 358. 360. 361. 362. 363. 365. 366. 367. 369.\n",
            " 370. 372. 375. 376. 377. 378. 379. 380. 383. 385. 386. 387. 389. 391.\n",
            " 392. 397. 398. 399. 400. 402. 403. 404. 406. 407. 410. 412. 413. 414.\n",
            " 415. 416. 417. 418. 420. 421. 422. 423. 425. 426. 429. 430. 431. 432.\n",
            " 434. 435. 436. 437. 438. 439. 440. 441. 446. 448. 449. 450. 452. 453.\n",
            " 454. 455. 456. 457. 459. 464. 465. 466. 467. 469. 471. 473. 479. 480.\n",
            " 484. 486. 487. 488. 489. 490. 491. 492. 493. 494. 495. 496. 498. 499.]\n",
            "[ 87.  90.  92.  93.  98. 100. 103. 107. 109. 111. 113. 116. 117. 118.\n",
            " 119. 120. 124. 129. 133. 135. 137. 142. 144. 146. 148. 152. 161. 163.\n",
            " 166. 170. 172. 177. 195. 197. 206. 207. 209. 213. 215. 216. 218. 220.\n",
            " 231. 237. 240. 242. 246. 251. 252. 257. 263. 266. 267. 269. 272. 274.\n",
            " 276. 278. 280. 281. 287. 291. 292. 295. 298. 300. 301. 303. 305. 308.\n",
            " 313. 318. 320. 324. 329. 339. 340. 344. 345. 347. 348. 349. 353. 354.\n",
            " 355. 359. 364. 368. 371. 373. 374. 381. 382. 384. 388. 390. 393. 394.\n",
            " 395. 396. 401. 405. 408. 409. 411. 419. 424. 427. 428. 433. 442. 443.\n",
            " 444. 445. 447. 451. 458. 460. 461. 462. 463. 468. 470. 472. 474. 475.\n",
            " 476. 477. 478. 481. 482. 483. 485. 497.]\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "k0jMMUkTpBLw"
      },
      "source": [
        "class JaneDataset(Dataset):\r\n",
        "    def __init__(self, np_X, np_y):\r\n",
        "        super(JaneDataset,self).__init__()\r\n",
        "        self.X = np_X\r\n",
        "        self.y = np_y\r\n",
        "        \r\n",
        "    def __len__(self):\r\n",
        "        return self.X.shape[0]\r\n",
        "    \r\n",
        "    def __getitem__(self, index):\r\n",
        "        # date, weight, resp\r\n",
        "        X_util = self.X[index, :3]\r\n",
        "        X = torch.tensor(self.X[index, 3:],dtype=torch.float)\r\n",
        "        y = torch.tensor(self.y[index],dtype=torch.float)\r\n",
        "        return X_util, X, y"
      ],
      "execution_count": 23,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "RYHE_MtvcxU-"
      },
      "source": [
        "Trial"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_tdVgsd4boT5"
      },
      "source": [
        "from optuna.trial import Trial"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "zQpjlbG8aTt5"
      },
      "source": [
        "# # Parameters carry out the trial of category\r\n",
        "#   param1  =  Trial . Suggest_categorical ( Name ,  Choices )\r\n",
        "# # Perform trial integer parameter\r\n",
        "#   param2  =  trial . Suggest_int ( name ,  low ,  high )\r\n",
        "# # Perform successive values attempts parameter\r\n",
        "#   param3  =  trial . Suggest_uniform ( name ,  low ,  high )\r\n",
        "# # Performing trial of discrete values parameters\r\n",
        "#   param4  =  trial . Suggest_discrete_uniform ( name ,  low ,  high ,  q )\r\n",
        "# # Parameters perform trial logarithm\r\n",
        "#   param5  =  trial . Suggest_loguniform ( name ,  low ,  high )"
      ],
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "BowNrK5gcw5D"
      },
      "source": [
        "Study"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "62RaCIZScznW"
      },
      "source": [
        "import optuna\r\n",
        "# study = optuna.create_study\r\n",
        "# study.optimize(objective, n_trials=3)"
      ],
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Garm75HJdFiR"
      },
      "source": [
        "Hyper parameters for tuning\r\n",
        "* Number of convolutional layers (3 to 7)\r\n",
        "* Number of filters for each convolutional layer (16, 32, 48, ..., 128)\r\n",
        "* Number of units in all bonding layers (100, 200, 300, 400, 500)\r\n",
        "* Activation function (ReLU, ELU)\r\n",
        "* Optimization method (Adam, MomentumSGD, rmsprop)\r\n",
        "* Learning rate (adam_lr (1e-10 ~ 1e-3), momentum_sgd_lr (1e-5 ~ 1e-1))\r\n",
        "* weight_decay (1e-10 to 1e-3)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YlU9xOi_FkaX"
      },
      "source": [
        "def utility_score(X_d_w,X_r,y):\r\n",
        "    # X for date, weight, resp numpy.array\r\n",
        "    # y for binary action by random threshold or prediction\r\n",
        "    \r\n",
        "    # date\r\n",
        "#     date_min, date_max = np.min(X_d_w[:,0]), np.max(X_d_w[:,0])\r\n",
        "    unq_dates = np.unique(X_d_w[:,0])\r\n",
        "    period = len(unq_dates)\r\n",
        "#     dates = np.arange(date_min, date_max+1)\r\n",
        "    \r\n",
        "    list_p = list()\r\n",
        "    \r\n",
        "    for date in unq_dates:\r\n",
        "        idx_date = X_d_w[:,0] == date\r\n",
        "        X_d = X_d_w[idx_date,0]\r\n",
        "        y_d = y[idx_date]\r\n",
        "        w_d = X_d_w[idx_date,1]\r\n",
        "        r_d = X_r[idx_date]\r\n",
        "        \r\n",
        "        p_d = w_d * r_d * y_d\r\n",
        "        p = p_d.sum()\r\n",
        "        \r\n",
        "        list_p.append(p)\r\n",
        "    \r\n",
        "    np_p = np.array(list_p)\r\n",
        "    \r\n",
        "\r\n",
        "    t = np.sum(np_p) / np.sqrt(np.sum(np.power(np_p,2))) * np.sqrt(250/period)\r\n",
        "    utility_score = min(max(t,0),6)*np_p.sum()\r\n",
        "    return utility_score"
      ],
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DwcVKMo3dFBR"
      },
      "source": [
        "class ResnetLinear(nn.Module):\r\n",
        "    def __init__(self, trial, num_features, num_classes, df_features, device, verbose=False):\r\n",
        "        super(ResnetLinear,self).__init__()\r\n",
        "\r\n",
        "        self.hidden_layer = trial.suggest_categorical(\"hidden_layer\",[512,256,128])\r\n",
        "        self.num_layers = trial.suggest_int('n_layers',2,4)\r\n",
        "        self.decreasing = trial.suggest_categorical(\"decreasing\",[True, False])\r\n",
        "        \r\n",
        "        self.f_act = self.get_activation(trial)\r\n",
        "        self.dropout = trial.suggest_uniform('dropout',0.1,0.5)\r\n",
        "        \r\n",
        "        self.embed_dim = trial.suggest_categorical(\"embed_dim\",[0,5,10])\r\n",
        "\r\n",
        "        self.num_features = num_features\r\n",
        "        self.num_classes = num_classes\r\n",
        "        # self.hidden_layers = hidden_layers\r\n",
        "        # self.dropout = dropout\r\n",
        "        # self.embed_dim = 0\r\n",
        "        self.hidden_layers = None\r\n",
        "        self.emb_mode = None\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "            print(\"ResnetLinear Trial\")\r\n",
        "            print(f\"hidden_layer:{self.hidden_layer}; num_layers:{self.num_layers}; decreasing:{self.decreasing}; f_act:{self.f_act}; dropout:{self.dropout}; embed_dim:{self.embed_dim}\")        \r\n",
        "\r\n",
        "        if self.embed_dim == 0:\r\n",
        "            self.emb_mode = False\r\n",
        "\r\n",
        "        else:\r\n",
        "            self.emb_mode = True\r\n",
        "\r\n",
        "            # df_features tag num is 29(fixed value)\r\n",
        "            self.n_feat_tags = 29\r\n",
        "            # self.embed_dim = selfembed_dim\r\n",
        "            self.device = device\r\n",
        "            \r\n",
        "            self.df_features = df_features.loc[:,df_features.columns[1:]]\r\n",
        "            self.df_features[\"tag_29\"] = np.array([1]+[0] * (self.df_features.shape[0]-1))\r\n",
        "            self.df_features = self.df_features.astype(\"int8\")\r\n",
        "            self.features_tag_matrix = torch.tensor(self.df_features.values).to(self.device)\r\n",
        "            \r\n",
        "            self.n_feat_tags += 1\r\n",
        "            self.tag_embedding = nn.Embedding(self.n_feat_tags+1, self.embed_dim)\r\n",
        "            self.tag_weights = nn.Linear(self.n_feat_tags, 1)\r\n",
        "            \r\n",
        "\r\n",
        "        self.bn_d0 = nn.BatchNorm1d(self.num_features+ self.embed_dim)\r\n",
        "                \r\n",
        "        if self.decreasing:\r\n",
        "          self.hidden_layers = [int(self.hidden_layer/2**(i)) for i in range(self.num_layers)]\r\n",
        "        else:\r\n",
        "          self.hidden_layers = [int(self.hidden_layer) for i in range(self.num_layers)]\r\n",
        "\r\n",
        "        self.hidden_layers = [int(self.num_features + self.embed_dim)] + self.hidden_layers\r\n",
        "\r\n",
        "        denses = list()\r\n",
        "        \r\n",
        "        for i in range(len(self.hidden_layers)-1):\r\n",
        "            if i==0:\r\n",
        "                denses.append(self.make_layers(self.hidden_layers[i], self.hidden_layers[i+1], self.dropout, self.f_act))\r\n",
        "            else:\r\n",
        "                denses.append(self.make_layers(self.hidden_layers[i-1]+self.hidden_layers[i], self.hidden_layers[i+1], self.dropout, self.f_act))\r\n",
        "\r\n",
        "        self.denses = nn.Sequential(*denses)\r\n",
        "        \r\n",
        "        self.out_dense = nn.Linear(self.hidden_layers[-1] + self.hidden_layers[-2], self.num_classes)\r\n",
        "\r\n",
        "    def get_activation(self, trial):\r\n",
        "      f_acts = [\"ReLU\", \"SiLU\", \"LeakyReLU\"]\r\n",
        "      f_act = trial.suggest_categorical('f_act',f_acts)\r\n",
        "      \r\n",
        "      if f_act == f_acts[0]: \r\n",
        "          activation = nn.ReLU()\r\n",
        "      elif f_act == f_acts[1]: \r\n",
        "          activation = nn.SiLU()\r\n",
        "      elif f_act == f_acts[2]: \r\n",
        "          activation = nn.LeakyReLU()\r\n",
        "      \r\n",
        "      return activation\r\n",
        "\r\n",
        "    def make_layers(self, in_channels, out_channels, dropout=None, f_act=nn.ReLU()):\r\n",
        "        layers = list()\r\n",
        "        layers.append(nn.Linear(in_channels, out_channels))\r\n",
        "        layers.append(nn.BatchNorm1d(out_channels))\r\n",
        "        layers.append(f_act)\r\n",
        "        \r\n",
        "        if dropout:\r\n",
        "            layers.append(nn.Dropout(dropout))\r\n",
        "        \r\n",
        "        module = nn.Sequential(*layers)\r\n",
        "        \r\n",
        "        return module\r\n",
        "    \r\n",
        "    # function to make embedding vector of Tag information per Features_0...129\r\n",
        "    def features2emb(self):\r\n",
        "        # one tag embedding to embed_dim dimension (1,embed_dim) per element\r\n",
        "        all_tag_idxs = torch.LongTensor(np.arange(self.n_feat_tags)).to(self.device)\r\n",
        "        tag_bools = self.features_tag_matrix\r\n",
        "        f_emb = self.tag_embedding(all_tag_idxs).repeat(130,1,1)\r\n",
        "        # f_emb에서 tag에 해당하는 값만 f_emb에 남김.\r\n",
        "        f_emb = f_emb * tag_bools[:,:,None]\r\n",
        "        \r\n",
        "        # 각 feature 별로 먗개의 tag가 속하는가?\r\n",
        "        s = torch.sum(tag_bools,dim=1)\r\n",
        "        # 각 feature 별로 tag값에 해당하여 남겨진 embedding 값을 dimension 별로 합산(1,1,29) / 각 featrue별로 구해진 tag 개수와 division\r\n",
        "        f_emb = torch.sum(f_emb, dim=-2) / s[:,None]\r\n",
        "        \r\n",
        "        return f_emb\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        \r\n",
        "        # if embedding\r\n",
        "        if self.emb_mode:\r\n",
        "            f_emb = self.features2emb()\r\n",
        "            x = x.view(-1, self.num_features)\r\n",
        "            x_emb = torch.matmul(x,f_emb)\r\n",
        "            x = torch.hstack((x,x_emb))\r\n",
        "        \r\n",
        "        # num_features + embed_dim \r\n",
        "        x = self.bn_d0(x)\r\n",
        "        \r\n",
        "        x_prev = None\r\n",
        "        x_now = None\r\n",
        "\r\n",
        "        for idx, dense in enumerate(self.denses):\r\n",
        "            if idx == 0:\r\n",
        "                x_prev = x\r\n",
        "                x_now = dense(x_prev)\r\n",
        "                x = torch.cat([x_prev,x_now],1)\r\n",
        "                x_prev = x_now\r\n",
        "            else:\r\n",
        "                x_now = dense(x)\r\n",
        "                x = torch.cat([x_prev,x_now],1)\r\n",
        "                x_prev = x_now\r\n",
        "\r\n",
        "        x5 = self.out_dense(x)\r\n",
        "        \r\n",
        "        return x5"
      ],
      "execution_count": 28,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "x9vGvAvsErq8"
      },
      "source": [
        "class EarlyStopping_GS:\r\n",
        "    def __init__(self, patience=7, mode=\"max\", delta=0.001):\r\n",
        "        self.patience = patience\r\n",
        "        self.counter = 0\r\n",
        "        self.mode = mode\r\n",
        "        self.best_score = None\r\n",
        "        self.early_stop = False\r\n",
        "        self.delta = delta\r\n",
        "        if self.mode == \"min\":\r\n",
        "            self.val_score = np.Inf\r\n",
        "        else:\r\n",
        "            self.val_score = -np.Inf\r\n",
        "\r\n",
        "    def __call__(self, epoch_score, model):\r\n",
        "\r\n",
        "        if self.mode == \"min\":\r\n",
        "            score = -1.0 * epoch_score\r\n",
        "        else:\r\n",
        "            score = np.copy(epoch_score)\r\n",
        "\r\n",
        "        if self.best_score is None:\r\n",
        "            self.best_score = score\r\n",
        "            self.save_checkpoint(epoch_score, model)\r\n",
        "        elif score < self.best_score: #  + self.delta\r\n",
        "            self.counter += 1\r\n",
        "            # print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\r\n",
        "            if self.counter >= self.patience:\r\n",
        "                self.early_stop = True\r\n",
        "        else:\r\n",
        "            self.best_score = score\r\n",
        "            # ema.apply_shadow()\r\n",
        "            # print(f\"Validation score improved ({self.val_score:.4f} --> {epoch_score:.4f}). Saving model!\")\r\n",
        "            self.save_checkpoint(epoch_score, model)\r\n",
        "            # ema.restore()\r\n",
        "            self.counter = 0\r\n",
        "\r\n",
        "    def save_checkpoint(self, epoch_score, model):\r\n",
        "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\r\n",
        "            print(f\"Validation score improved ({self.val_score:.4f} --> {epoch_score:.4f})\")\r\n",
        "            # if not DEBUG:\r\n",
        "            # torch.save(model.state_dict(), model_path)\r\n",
        "        self.val_score = epoch_score"
      ],
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TgMOg0yqn5-a"
      },
      "source": [
        "class Model:\r\n",
        "    def __init__(self, X, y, cv_idxes, epochs, batch_size, earlystop_num, device, verbose=False):\r\n",
        "        self.train_loader = None\r\n",
        "        self.valid_loader = None\r\n",
        "        \r\n",
        "        self.X = X\r\n",
        "        self.y = y\r\n",
        "        \r\n",
        "        self.cv_idxes = cv_idxes\r\n",
        "        self.epochs = epochs\r\n",
        "        self.batch_size = batch_size\r\n",
        "        self.earlystop_num = earlystop_num\r\n",
        "        self.device = device \r\n",
        "        self.verbose = verbose\r\n",
        "\r\n",
        "        self.len_cv = len(cv_idxes)\r\n",
        "\r\n",
        "    def prepare_data(self, idx):\r\n",
        "        train_idx, valid_idx = cv_idxes[idx]\r\n",
        "        X_train = X[train_idx, :]\r\n",
        "        y_train = y[train_idx, :]\r\n",
        "\r\n",
        "        X_valid = X[valid_idx, :]\r\n",
        "        y_valid = y[valid_idx, :]\r\n",
        "        \r\n",
        "        train_dataset = JaneDataset(X_train, y_train)\r\n",
        "        valid_dataset = JaneDataset(X_valid, y_valid)\r\n",
        "\r\n",
        "        self.train_dataloader = DataLoader(train_dataset, self.batch_size, shuffle=False)\r\n",
        "        self.valid_dataloader = DataLoader(valid_dataset, self.batch_size, shuffle=False)\r\n",
        "\r\n",
        "    def get_optimizer(self, trial, model, verbose=False):\r\n",
        "\r\n",
        "        optimizers = [\"Adam\",\"SGD\"]\r\n",
        "        optimizer_name = trial.suggest_categorical('optimizer',optimizers)\r\n",
        "        learning_rate = trial.suggest_loguniform('learning_rate',1e-5, 1e-1)\r\n",
        "        weight_decay = trial.suggest_loguniform('weight_decay',1e-10,1e-3)\r\n",
        "\r\n",
        "        if optimizer_name == optimizers[0]:\r\n",
        "            optimizer = optim.Adam(model.parameters(),lr=learning_rate, weight_decay=weight_decay)\r\n",
        "\r\n",
        "        if optimizer_name == optimizers[1]:\r\n",
        "            optimizer = optim.SGD(model.parameters(),lr=learning_rate, momentum=0.9, weight_decay=weight_decay)\r\n",
        "\r\n",
        "        if verbose:\r\n",
        "            print(\"Optimzer Trial\")          \r\n",
        "            print(f\"optimizer:{optimizer_name}; learning_rate:{learning_rate}; weight_decay:{weight_decay}\")\r\n",
        "\r\n",
        "        return optimizer\r\n",
        "\r\n",
        "    def optimize(self, trial):\r\n",
        "\r\n",
        "        verbosed = None\r\n",
        "        if self.verbose:\r\n",
        "          verbosed = False\r\n",
        "\r\n",
        "        cv_results = []\r\n",
        "\r\n",
        "        for idx in range(self.len_cv):\r\n",
        "            print(f\"fold {idx} processing\"+\"*\"*20)\r\n",
        "            self.prepare_data(idx)\r\n",
        "\r\n",
        "            if verbosed == False:\r\n",
        "                model = ResnetLinear(trial, 130, 5, df_features, self.device, self.verbose)\r\n",
        "                optimizer = self.get_optimizer(trial, model, self.verbose)\r\n",
        "                verbosed = True\r\n",
        "\r\n",
        "            elif (verbosed == True) | (verbosed is None):\r\n",
        "                model = ResnetLinear(trial, 130, 5, df_features, self.device)\r\n",
        "                optimizer = self.get_optimizer(trial, model)\r\n",
        "\r\n",
        "            model = model.to(self.device)\r\n",
        "\r\n",
        "            # optimizer = self.get_optimizer(trial, model, self.verbose)\r\n",
        "            criterion = nn.BCEWithLogitsLoss()\r\n",
        "\r\n",
        "            es = EarlyStopping_GS(self.earlystop_num, mode=\"max\")\r\n",
        "\r\n",
        "            for epoch in tqdm_notebook(range(self.epochs)):\r\n",
        "                running_loss = 0.0\r\n",
        "                running_acc = 0.0\r\n",
        "                running_auc = 0.0\r\n",
        "                running_util = 0.0\r\n",
        "\r\n",
        "                model.train()\r\n",
        "\r\n",
        "                for idx, (X_utils,inputs, labels) in enumerate(self.train_dataloader):\r\n",
        "\r\n",
        "                    optimizer.zero_grad()\r\n",
        "                    X_d_w = X_utils[:,:-1].detach().cpu().numpy()\r\n",
        "                    X_r = X_utils[:,-1].detach().cpu().numpy()\r\n",
        "\r\n",
        "                    inputs = inputs.to(device)\r\n",
        "                    labels = labels.to(device)\r\n",
        "                    \r\n",
        "                    outputs = model(inputs)\r\n",
        "                    \r\n",
        "                    true = labels.detach().cpu().numpy()[:,-1]\r\n",
        "                    target = np.array(list(map(lambda x: 1 if x > 0.5 else 0, outputs.sigmoid().detach().cpu().numpy()[:,-1])),dtype=np.float)\r\n",
        "                    \r\n",
        "                    acc = (true == target).sum() / outputs.shape[0]\r\n",
        "                    auc = roc_auc_score(true, outputs.detach().cpu().numpy()[:,-1])\r\n",
        "                    util = utility_score(X_d_w,X_r,target)\r\n",
        "            \r\n",
        "                    running_acc += acc\r\n",
        "                    running_auc += auc\r\n",
        "                    running_util += util\r\n",
        "\r\n",
        "                    loss = criterion(outputs,labels)\r\n",
        "                    running_loss += loss.detach().item() * inputs.size(0)\r\n",
        "                    loss.backward()\r\n",
        "                    optimizer.step()\r\n",
        "                    \r\n",
        "                epoch_loss = running_loss / len(self.train_dataloader.dataset)\r\n",
        "                epoch_acc = running_acc / len(self.train_dataloader)\r\n",
        "                epoch_auc = running_auc / len(self.train_dataloader)\r\n",
        "                epoch_util = running_util\r\n",
        "\r\n",
        "                model.eval()\r\n",
        "                with torch.no_grad():\r\n",
        "                    \r\n",
        "                    running_loss = 0.0\r\n",
        "                    running_acc = 0.0\r\n",
        "                    running_auc = 0.0\r\n",
        "                    running_util = 0.0\r\n",
        "\r\n",
        "                    for idx, (X_utils, inputs, labels) in enumerate(self.valid_dataloader):\r\n",
        "\r\n",
        "                        X_d_w = X_utils[:,:-1].detach().cpu().numpy()\r\n",
        "                        X_r = X_utils[:,-1].detach().cpu().numpy()\r\n",
        "\r\n",
        "                        inputs = inputs.to(device)\r\n",
        "                        labels = labels.to(device)\r\n",
        "\r\n",
        "                        outputs = model(inputs)\r\n",
        "\r\n",
        "                        true = labels.detach().cpu().numpy()[:,-1]\r\n",
        "                        target = np.array(list(map(lambda x: 1 if x > 0.5 else 0, outputs.sigmoid().detach().cpu().numpy()[:,-1])),dtype=np.float)\r\n",
        "                        \r\n",
        "                        acc = (true == target).sum() / outputs.shape[0]\r\n",
        "                        auc = roc_auc_score(true, outputs.detach().cpu().numpy()[:,-1])\r\n",
        "                        util = utility_score(X_d_w,X_r,target)\r\n",
        "\r\n",
        "                        running_acc += acc\r\n",
        "                        running_auc += auc\r\n",
        "                        running_util += util\r\n",
        "\r\n",
        "                        loss = criterion(outputs, labels)\r\n",
        "                        running_loss += loss.detach().item() * inputs.size(0)\r\n",
        "                        \r\n",
        "                    valid_loss = running_loss / len(self.valid_dataloader.dataset)\r\n",
        "                    valid_acc = running_acc / len(self.valid_dataloader)\r\n",
        "                    valid_auc = running_auc / len(self.valid_dataloader)\r\n",
        "                    valid_util = running_util\r\n",
        "\r\n",
        "                print(f\"EPOCH:{epoch+1}|{epochs}; loss(train/valid):{epoch_loss:.4f}/{valid_loss:.4f}; acc(train/valid):{epoch_acc:.4f}/{valid_acc:.4f}; auc(train/valid):{epoch_auc:.4f}/{valid_auc:.4f}; utility(train/valid):{epoch_util:.4f}/{valid_util:.4f}\")\r\n",
        "\r\n",
        "                es(valid_util, model)\r\n",
        "                if es.early_stop:\r\n",
        "                    print(\"Early stopping\")\r\n",
        "                    cv_results.append(es.best_score)\r\n",
        "                    break\r\n",
        "\r\n",
        "        cv_utility = np.mean(cv_results)\r\n",
        "        print(f\"mean of cv_results: {cv_utility}\")\r\n",
        "        return cv_utility"
      ],
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BHgzYKD5oQPi"
      },
      "source": [
        "epochs = 100\r\n",
        "batch_size = 4096\r\n",
        "earlystop_num = 3\r\n",
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\"\r\n",
        "\r\n",
        "model = Model(X, y, cv_idxes, epochs, batch_size, earlystop_num, device, True)"
      ],
      "execution_count": 31,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DcMbXZNMHwkL",
        "outputId": "9da8006b-9124-466d-ad5c-eab7d50a7dca"
      },
      "source": [
        "study = optuna.create_study(direction=\"maximize\")"
      ],
      "execution_count": 34,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "\u001b[32m[I 2021-02-20 08:39:10,789]\u001b[0m A new study created in memory with name: no-name-9cfc9432-69fb-467e-bfc8-259e0823d3cf\u001b[0m\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 139,
          "referenced_widgets": [
            "a461305ccb9c4bd1bb327230df1f462d",
            "7e95676b8cbb45ff94ae52b0fe4704d0",
            "f71d706cc10143098fe7224972ade495",
            "ad6695ef5e2b431493337bb250fed038",
            "b05ad2876edc49708d870157d73a3d09",
            "124a4f2f89fc465aaae8da5a911f3c3b",
            "8be8ade2b78c40bbb52547fc3e45298c",
            "b6837623a5ab4d6abea18a10d23ad989"
          ]
        },
        "id": "axRvusjtH5EO",
        "outputId": "7274b54e-7d2a-46a7-d528-5781cd1e1bcf"
      },
      "source": [
        "# https://optuna.readthedocs.io/en/v1.4.0/reference/logging.html\r\n",
        "optuna.logging.enable_default_handler()\r\n",
        "study.optimize(model.optimize,n_trials=100)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fold 0 processing********************\n",
            "ResnetLinear Trial\n",
            "hidden_layer:256; num_layers:4; decreasing:False; f_act:LeakyReLU(negative_slope=0.01); dropout:0.3713539211781073; embed_dim:5\n",
            "Optimzer Trial\n",
            "optimizer:SGD; learning_rate:0.0060669990085953545; weight_decay:3.4870532320747824e-08\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a461305ccb9c4bd1bb327230df1f462d",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NcHEbsmjctul"
      },
      "source": [
        "# gs_home = os.path.join(project_home, \"output/grid_search\")\r\n",
        "file_name = \"opt_reslin.pkl\"\r\n",
        "file_path = os.path.join(gs_home, file_name)\r\n",
        "\r\n",
        "df_optuna_result = study.trials_dataframe()\r\n",
        "df_optuna_result.to_pickle(file_path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4LDhWvM3fKfJ"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}