{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3",
      "language": "python"
    },
    "language_info": {
      "name": "python",
      "version": "3.7.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "colab": {
      "name": "pytorch-nn-labs.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "accelerator": "GPU",
    "widgets": {
      "application/vnd.jupyter.widget-state+json": {
        "0bf9fb3524be4b9abe632afe2d611c2b": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HBoxModel",
          "state": {
            "_view_name": "HBoxView",
            "_dom_classes": [],
            "_model_name": "HBoxModel",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "box_style": "",
            "layout": "IPY_MODEL_e1a1777a5ee54b4a898722e198c5cd1f",
            "_model_module": "@jupyter-widgets/controls",
            "children": [
              "IPY_MODEL_3e94184b7e1a4cb5bdd85e2dec910932",
              "IPY_MODEL_682995e39f754c2c96aef79eb1560490"
            ]
          }
        },
        "e1a1777a5ee54b4a898722e198c5cd1f": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "3e94184b7e1a4cb5bdd85e2dec910932": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "FloatProgressModel",
          "state": {
            "_view_name": "ProgressView",
            "style": "IPY_MODEL_a1aa0db12c4f445f98fb6f0442599660",
            "_dom_classes": [],
            "description": "100%",
            "_model_name": "FloatProgressModel",
            "bar_style": "success",
            "max": 10,
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": 10,
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "orientation": "horizontal",
            "min": 0,
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_11b823bab0f74de092b6ac1faf98cebd"
          }
        },
        "682995e39f754c2c96aef79eb1560490": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "HTMLModel",
          "state": {
            "_view_name": "HTMLView",
            "style": "IPY_MODEL_641320434821468eb782ad440eb1f971",
            "_dom_classes": [],
            "description": "",
            "_model_name": "HTMLModel",
            "placeholder": "​",
            "_view_module": "@jupyter-widgets/controls",
            "_model_module_version": "1.5.0",
            "value": " 10/10 [07:20&lt;00:00, 44.05s/it]",
            "_view_count": null,
            "_view_module_version": "1.5.0",
            "description_tooltip": null,
            "_model_module": "@jupyter-widgets/controls",
            "layout": "IPY_MODEL_2a59714164c64d448c7ad8d29c8fa472"
          }
        },
        "a1aa0db12c4f445f98fb6f0442599660": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "ProgressStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "ProgressStyleModel",
            "description_width": "initial",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "bar_color": null,
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "11b823bab0f74de092b6ac1faf98cebd": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        },
        "641320434821468eb782ad440eb1f971": {
          "model_module": "@jupyter-widgets/controls",
          "model_name": "DescriptionStyleModel",
          "state": {
            "_view_name": "StyleView",
            "_model_name": "DescriptionStyleModel",
            "description_width": "",
            "_view_module": "@jupyter-widgets/base",
            "_model_module_version": "1.5.0",
            "_view_count": null,
            "_view_module_version": "1.2.0",
            "_model_module": "@jupyter-widgets/controls"
          }
        },
        "2a59714164c64d448c7ad8d29c8fa472": {
          "model_module": "@jupyter-widgets/base",
          "model_name": "LayoutModel",
          "state": {
            "_view_name": "LayoutView",
            "grid_template_rows": null,
            "right": null,
            "justify_content": null,
            "_view_module": "@jupyter-widgets/base",
            "overflow": null,
            "_model_module_version": "1.2.0",
            "_view_count": null,
            "flex_flow": null,
            "width": null,
            "min_width": null,
            "border": null,
            "align_items": null,
            "bottom": null,
            "_model_module": "@jupyter-widgets/base",
            "top": null,
            "grid_column": null,
            "overflow_y": null,
            "overflow_x": null,
            "grid_auto_flow": null,
            "grid_area": null,
            "grid_template_columns": null,
            "flex": null,
            "_model_name": "LayoutModel",
            "justify_items": null,
            "grid_row": null,
            "max_height": null,
            "align_content": null,
            "visibility": null,
            "align_self": null,
            "height": null,
            "min_height": null,
            "padding": null,
            "grid_auto_rows": null,
            "grid_gap": null,
            "max_width": null,
            "order": null,
            "_view_module_version": "1.2.0",
            "grid_template_areas": null,
            "object_position": null,
            "object_fit": null,
            "grid_auto_columns": null,
            "margin": null,
            "display": null,
            "left": null
          }
        }
      }
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vA5j8tuwnevl",
        "outputId": "78a7c1a4-df5d-47bd-aec3-d5769067bc4b"
      },
      "source": [
        "\"\"\"Colab Drive Connection\"\"\"\r\n",
        "\r\n",
        "from google.colab import drive\r\n",
        "drive.mount('/gdrive')"
      ],
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Drive already mounted at /gdrive; to attempt to forcibly remount, call drive.mount(\"/gdrive\", force_remount=True).\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
        "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IbMkDicinaV9",
        "outputId": "fd552c8f-4186-4d85-8b02-85f3f3030f42"
      },
      "source": [
        "import warnings\n",
        "import os \n",
        "\n",
        "from collections import defaultdict\n",
        "from copy import deepcopy\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.gridspec as gridspec\n",
        "import seaborn as sns\n",
        "\n",
        "import networkx as nx\n",
        "import scipy.cluster.hierarchy as sch\n",
        "from scipy.cluster.hierarchy import fcluster\n",
        "\n",
        "import random\n",
        "\n",
        "from tqdm import tqdm_notebook\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torch.nn import functional as F\n",
        "\n",
        "# install datatable\n",
        "!pip install datatable\n",
        "import datatable as dt\n",
        "\n",
        "from numba import njit\n",
        "\n",
        "import gc\n",
        "\n",
        "warnings.simplefilter(action=\"ignore\")\n",
        "\n",
        "# project_home = \"/kaggle/input/jane-street-market-prediction\"\n",
        "\n",
        "project_home = \"/gdrive/MyDrive/colab/jane-street-market-prediction\"\n",
        "data_home = os.path.join(project_home, \"input/data\")\n",
        "model_home = os.path.join(project_home, \"output/model\")"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: datatable in /usr/local/lib/python3.6/dist-packages (0.11.1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "UAcoB2EqnaV-"
      },
      "source": [
        "entire_seed = 1029\n",
        "\n",
        "def seed_torch(seed=1029):\n",
        "    random.seed(seed)\n",
        "    os.environ['PYTHONHASHSEED'] = str(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed) # if you are using multi-GPU.\n",
        "    torch.backends.cudnn.benchmark = False\n",
        "#     torch.backends.cudnn.deterministic = True\n",
        "    torch.backends.cudnn.deterministic = False\n",
        "    \n",
        "seed_torch(entire_seed)"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "i6690m01naV-"
      },
      "source": [
        "train_file = os.path.join(data_home,'train.csv')\n",
        "features_file = os.path.join(data_home,'features.csv')\n",
        "example_test_file = os.path.join(data_home,'example_test.csv')\n",
        "example_sample_submission_file = os.path.join(data_home,'example_sample_submission.csv')\n",
        "\n",
        "train_data_datatable = dt.fread(train_file)\n",
        "\n",
        "df_train = train_data_datatable.to_pandas()\n",
        "df_features = pd.read_csv(features_file)\n",
        "df_example_test = pd.read_csv(example_test_file)\n",
        "df_example_sample_submission = pd.read_csv(example_sample_submission_file)"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "syvZDP5OnaV-"
      },
      "source": [
        "features = [ col for col in df_train.columns if \"feature\" in col ]\n",
        "resps = [ col for col in df_train.columns if \"resp\" in col ]\n",
        "target_resp = [resp_ for resp_ in resps if \"_\" not in resp_]\n",
        "target = [\"weight\"] + target_resp + features "
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9irkLVhYnaV_",
        "outputId": "901c1a00-44fb-4a11-9ef3-981c2bb51c03"
      },
      "source": [
        "\"\"\"\n",
        "Reduce Memory Usage by 75%\n",
        "https://www.kaggle.com/tomwarrens/nan-values-depending-on-time-of-day\n",
        "\"\"\"\n",
        "\n",
        "## Reduce Memory\n",
        "\n",
        "def reduce_memory_usage(df):\n",
        "    \n",
        "    start_memory = df.memory_usage().sum() / 1024**2\n",
        "    print(f\"Memory usage of dataframe is {start_memory} MB\")\n",
        "    \n",
        "    for col in df.columns:\n",
        "        col_type = df[col].dtype\n",
        "        \n",
        "        if col_type != 'object':\n",
        "            c_min = df[col].min()\n",
        "            c_max = df[col].max()\n",
        "            \n",
        "            if str(col_type)[:3] == 'int':\n",
        "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
        "                    df[col] = df[col].astype(np.int8)\n",
        "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
        "                    df[col] = df[col].astype(np.int16)\n",
        "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
        "                    df[col] = df[col].astype(np.int32)\n",
        "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
        "                    df[col] = df[col].astype(np.int64)\n",
        "            \n",
        "            else:\n",
        "#                 reducing float16 for calculating numpy.nanmean\n",
        "#                 if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
        "#                     df[col] = df[col].astype(np.float16)\n",
        "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
        "                    df[col] = df[col].astype(np.float32)\n",
        "                else:\n",
        "                    pass\n",
        "        else:\n",
        "            df[col] = df[col].astype('category')\n",
        "    \n",
        "    end_memory = df.memory_usage().sum() / 1024**2\n",
        "    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\n",
        "    print(f\"Reduced by {100 * (start_memory - end_memory) / start_memory} % \")\n",
        "    return df\n",
        "\n",
        "df_train = reduce_memory_usage(df_train)\n",
        "df_train.info()"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Memory usage of dataframe is 2489.4869804382324 MB\n",
            "Memory usage of dataframe after reduction 1247.0233011245728 MB\n",
            "Reduced by 49.908422461199 % \n",
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 2390491 entries, 0 to 2390490\n",
            "Columns: 138 entries, date to ts_id\n",
            "dtypes: float32(135), int16(1), int32(1), int8(1)\n",
            "memory usage: 1.2 GB\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "9zAivGb3naV_"
      },
      "source": [
        "# drop before 85days\n",
        "df_train = df_train.loc[df_train.date>85]\n",
        "# drop weight 0 for training\n",
        "df_train = df_train.loc[df_train.weight > 0]\n",
        "\n",
        "df_labels = df_train[['date','weight','resp_1','resp_2','resp_3','resp_4','resp']]\n",
        "\n",
        "df_train = df_train.drop(df_labels.columns,axis=1)"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "daU4lp_qnaV_"
      },
      "source": [
        "\"\"\"\n",
        "The codes from 'Optimise Speed of Filling-NaN Function'\n",
        "https://www.kaggle.com/gogo827jz/optimise-speed-of-filling-nan-function\n",
        "\"\"\"\n",
        "\n",
        "def for_loop(method, matrix, values):\n",
        "    for i in range(matrix.shape[0]):\n",
        "        matrix[i] = method(matrix[i], values)\n",
        "    return matrix\n",
        "\n",
        "def for_loop_ffill(method, matrix):\n",
        "    tmp = np.zeros(matrix.shape[1],dtype=np.float32)\n",
        "    for i in range(matrix.shape[0]):\n",
        "        matrix[i] = method(matrix[i], tmp)\n",
        "        tmp = matrix[i]\n",
        "    return matrix\n",
        "\n",
        "@njit\n",
        "def fillna_npwhere_njit(array, values):\n",
        "    if np.isnan(array.sum()):\n",
        "        array = np.where(np.isnan(array), values, array)\n",
        "    return array"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "vLaxNPOynaV_"
      },
      "source": [
        "# converting numpy for efficient calcualtion.\n",
        "# ft 1~129\n",
        "np_train = df_train.loc[:,features[1:]].values\n",
        "np_train.shape\n",
        "\n",
        "# ft 0\n",
        "np_train_ft0 = df_train.loc[:,features[0]].values"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "LSIsYjKlnaWA"
      },
      "source": [
        "# nead pre-calculate 1.2GB per action\n",
        "f_mean = np.nanmean(np_train,axis=0)"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e5kp4PuMnaWA",
        "outputId": "06c938b7-a665-41b2-b0f6-1396ac219ee8"
      },
      "source": [
        "print('fillna_npwhere_njit (mean-filling):')\n",
        "np_mf_train = for_loop(fillna_npwhere_njit, np_train, f_mean)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "fillna_npwhere_njit (mean-filling):\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "omNSA1JanaWA"
      },
      "source": [
        "np_train = np.concatenate([np_train_ft0.reshape(-1,1),np_mf_train],axis=1)\n",
        "# resp_{1~4}, resp 모두를 고려; 각각을 0과 1로 분류하는 개별적인 Binary Classification 문제로 간주\n",
        "# ['resp_1', 'resp_2', 'resp_3', 'resp_4', 'resp'] 순서\n",
        "np_targets = np.stack([(df_labels[c] > 0).astype('int') for c in resps]).T"
      ],
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "_JKiwv1pnaWA"
      },
      "source": [
        "class JaneDataset(Dataset):\n",
        "    def __init__(self, np_X, np_y):\n",
        "        super(JaneDataset,self).__init__()\n",
        "        self.X = np_X\n",
        "        self.y = np_y\n",
        "        \n",
        "    def __len__(self):\n",
        "        return self.X.shape[0]\n",
        "    \n",
        "    def __getitem__(self, index):\n",
        "        X = torch.tensor(self.X[index,:],dtype=torch.float)\n",
        "        y = torch.tensor(self.y[index],dtype=torch.float)\n",
        "        return X,y"
      ],
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "96fx1qJCnaWA"
      },
      "source": [
        "dataset = JaneDataset(np_train, np_targets)"
      ],
      "execution_count": 14,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "tVfiS1xLnaWB"
      },
      "source": [
        "train_size = int(len(dataset) * 0.8)\n",
        "valid_size = len(dataset) - train_size\n",
        "\n",
        "train_dataset, valid_dataset = torch.utils.data.random_split(dataset, [train_size, valid_size], generator=torch.Generator().manual_seed(entire_seed))"
      ],
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "XyoYSPQDnaWB"
      },
      "source": [
        "* 1d-cnn\n",
        "\n",
        "https://wikidocs.net/80437\n",
        "\n",
        "https://ratsgo.github.io/deep%20learning/2017/10/09/CNNs/\n",
        "\n",
        "https://medium.com/@Rehan_Sayyad/how-to-use-convolutional-neural-networks-for-time-series-classification-80575131a474\n",
        "\n",
        "https://arxiv.org/abs/1905.03554\n",
        "\n",
        "https://www.kaggle.com/pyoungkangkim/1dcnn-pytorch-jstreet\n",
        "\n",
        "https://www.kaggle.com/a763337092/pytorch-resnet-starter-training\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "pzx5V_XRnaWB"
      },
      "source": [
        "dense1 => 130 -> 512\n",
        "\n",
        "512 -> 16ch, 32\n",
        "\n",
        "cnn1 => 16ch,32 => 32ch, 16\n",
        "\n",
        "dense2 => 32,16 -> 512 -> 5\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "It3N1TH-naWB"
      },
      "source": [
        "class Model_1DCNN(nn.Module):\n",
        "    def __init__(self, num_features, num_targets, hidden_size):\n",
        "        super(Model_1DCNN, self).__init__()\n",
        "        \n",
        "        self.hidden_size = hidden_size\n",
        "        # num_channel\n",
        "        self.ch_input = 16\n",
        "        self.ch_output =  32\n",
        "        self.points = int(self.hidden_size / self.ch_input) \n",
        "        \n",
        "        # feature_size to hidden_size\n",
        "        self.bn_dense1 = nn.BatchNorm1d(num_features)\n",
        "        self.dropout_dense1 = nn.Dropout(0.2)\n",
        "        self.dense1 = nn.Linear(num_features, hidden_size)\n",
        "        \n",
        "        # reshaped hidden_size [input_channel, data] to [input_channel, output_channel] \n",
        "        self.bn_c1 = nn.BatchNorm1d(self.ch_output)\n",
        "        self.dropout_c1 = nn.Dropout(0.2)\n",
        "        self.conv1 = nn.Conv1d(self.ch_input, self.ch_output, padding=1, kernel_size=3, stride=1)\n",
        "        self.avg_pool_c1 = nn.MaxPool1d(kernel_size=5,stride=2,padding=2)\n",
        "        \n",
        "        self.flatten = nn.Flatten()\n",
        "        \n",
        "        self.dense2 = nn.Linear(512,num_targets)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.bn_dense1(x)\n",
        "        x = self.dropout_dense1(x)\n",
        "        x = self.dense1(x)\n",
        "        \n",
        "        x = x.reshape(x.size(0), self.ch_input, self.points)\n",
        "        \n",
        "        x = self.conv1(x)\n",
        "        x = F.relu(self.bn_c1(x))\n",
        "        x = self.dropout_c1(x)\n",
        "        x = self.avg_pool_c1(x)\n",
        "       \n",
        "        x = self.flatten(x)\n",
        "\n",
        "        x = self.dense2(x)\n",
        "        x = F.sigmoid(x)\n",
        "\n",
        "        return x"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "kfJcmES4naWC"
      },
      "source": [
        "epochs = 10\n",
        "batch_size = 4096\n",
        "learning_rate = 0.001\n",
        "\n",
        "model = Model_1DCNN(num_features=130, num_targets=5, hidden_size=512)\n",
        "criterion = nn.BCEWithLogitsLoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)"
      ],
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UoogQrbqutcV"
      },
      "source": [
        "# model(torch.tensor(dummy))"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "-JECNElhnaWC"
      },
      "source": [
        "train_dataloader = DataLoader(train_dataset, batch_size=batch_size, shuffle=False) \n",
        "valid_dataloader = DataLoader(valid_dataset, batch_size=batch_size, shuffle=False)"
      ],
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "3a8JrIkVnaWC"
      },
      "source": [
        "device = \"cuda:0\" if torch.cuda.is_available() else \"cpu\""
      ],
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWah5LQJ3oRE"
      },
      "source": [
        "class EarlyStopping:\r\n",
        "    def __init__(self, patience=7, mode=\"max\", delta=0.001):\r\n",
        "        self.patience = patience\r\n",
        "        self.counter = 0\r\n",
        "        self.mode = mode\r\n",
        "        self.best_score = None\r\n",
        "        self.early_stop = False\r\n",
        "        self.delta = delta\r\n",
        "        if self.mode == \"min\":\r\n",
        "            self.val_score = np.Inf\r\n",
        "        else:\r\n",
        "            self.val_score = -np.Inf\r\n",
        "\r\n",
        "    def __call__(self, epoch_score, model, model_path):\r\n",
        "\r\n",
        "        if self.mode == \"min\":\r\n",
        "            score = -1.0 * epoch_score\r\n",
        "        else:\r\n",
        "            score = np.copy(epoch_score)\r\n",
        "\r\n",
        "        if self.best_score is None:\r\n",
        "            self.best_score = score\r\n",
        "            self.save_checkpoint(epoch_score, model, model_path)\r\n",
        "        elif score < self.best_score: #  + self.delta\r\n",
        "            self.counter += 1\r\n",
        "            # print('EarlyStopping counter: {} out of {}'.format(self.counter, self.patience))\r\n",
        "            if self.counter >= self.patience:\r\n",
        "                self.early_stop = True\r\n",
        "        else:\r\n",
        "            self.best_score = score\r\n",
        "            # ema.apply_shadow()\r\n",
        "            self.save_checkpoint(epoch_score, model, model_path)\r\n",
        "            # ema.restore()\r\n",
        "            self.counter = 0\r\n",
        "\r\n",
        "    def save_checkpoint(self, epoch_score, model, model_path):\r\n",
        "        if epoch_score not in [-np.inf, np.inf, -np.nan, np.nan]:\r\n",
        "            print('Validation score improved ({} --> {}). Saving model!'.format(self.val_score:.4f, epoch_score:.4f))\r\n",
        "            # if not DEBUG:\r\n",
        "            torch.save(model.state_dict(), model_path)\r\n",
        "        self.val_score = epoch_score"
      ],
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 247,
          "referenced_widgets": [
            "0bf9fb3524be4b9abe632afe2d611c2b",
            "e1a1777a5ee54b4a898722e198c5cd1f",
            "3e94184b7e1a4cb5bdd85e2dec910932",
            "682995e39f754c2c96aef79eb1560490",
            "a1aa0db12c4f445f98fb6f0442599660",
            "11b823bab0f74de092b6ac1faf98cebd",
            "641320434821468eb782ad440eb1f971",
            "2a59714164c64d448c7ad8d29c8fa472"
          ]
        },
        "id": "1lCkzFX_naWC",
        "outputId": "b39878a5-af5e-4da0-c09c-087b0e04a673"
      },
      "source": [
        "EARLYSTOP_NUM = 7\n",
        "CACHE_PATH = model_home\n",
        "\n",
        "model = model.to(device)\n",
        "\n",
        "es = EarlyStopping(EARLYSTOP_NUM, mode=\"max\")\n",
        "for epoch in tqdm_notebook(range(epochs)):\n",
        "\n",
        "    running_loss = 0.0\n",
        "    running_acc = 0.0\n",
        "    running_auc = 0.0\n",
        "    model.train()\n",
        "    \n",
        "    for idx, (inputs, labels) in enumerate(train_dataloader):\n",
        "    \n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        inputs = inputs.to(device)\n",
        "        labels = labels.to(device)\n",
        "        \n",
        "        outputs = model(inputs)\n",
        "        \n",
        "        true = labels.detach().cpu().numpy()[:,-1]\n",
        "        target = np.array(list(map(lambda x: 1 if x > 0.5 else 0, outputs.detach().cpu().numpy()[:,-1])),dtype=np.float)\n",
        "        \n",
        "        acc = (true == target).sum() / outputs.shape[0]\n",
        "        auc = roc_auc_score(true, outputs.detach().cpu().numpy()[:,-1])\n",
        " \n",
        "        running_acc += acc\n",
        "        running_auc += auc\n",
        "\n",
        "        loss = criterion(outputs,labels)\n",
        "        running_loss += loss.detach().item() * inputs.size(0)\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        \n",
        "    epoch_loss = running_loss / len(train_dataloader.dataset)\n",
        "    epoch_acc = running_acc / len(train_dataloader)\n",
        "    epoch_auc = running_auc / len(train_dataloader)\n",
        "\n",
        "    with torch.no_grad():\n",
        "        model.eval()\n",
        "        running_loss = 0.0\n",
        "        running_acc = 0.0\n",
        "        running_auc = 0.0\n",
        "        for idx, (inputs, labels) in enumerate(valid_dataloader):\n",
        "\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "\n",
        "            true = labels.detach().cpu().numpy()[:,-1]\n",
        "            target = np.array(list(map(lambda x: 1 if x > 0.5 else 0, outputs.detach().cpu().numpy()[:,-1])),dtype=np.float)\n",
        "            \n",
        "            acc = (true == target).sum() / outputs.shape[0]\n",
        "            auc = roc_auc_score(true, outputs.detach().cpu().numpy()[:,-1])\n",
        "\n",
        "            running_acc += acc\n",
        "            running_auc += auc\n",
        "\n",
        "            loss = criterion(outputs, labels)\n",
        "            running_loss += loss.detach().item() * inputs.size(0)\n",
        "            \n",
        "        valid_loss = running_loss / len(valid_dataloader.dataset)\n",
        "        valid_acc = running_acc / len(valid_dataloader)\n",
        "        valid_auc = running_auc / len(valid_dataloader)\n",
        "\n",
        "    print(f\"EPOCH:{epoch+1}|{epochs}; loss(train/valid):{epoch_loss:.4f}/{valid_loss:.4f}; acc(train/valid):{epoch_acc:.4f}/{valid_acc:.4f}; auc(train/valid):{epoch_auc:.4f}/{valid_auc:.4f}\")\n",
        "    \n",
        "    model_weights = os.path.join(model_home,f\"online_model.pth\")\n",
        "    es(valid_auc, model, model_path=model_weights)\n",
        "    if es.early_stop:\n",
        "      print(\"Early stopping\")\n",
        "      break"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0bf9fb3524be4b9abe632afe2d611c2b",
              "version_minor": 0,
              "version_major": 2
            },
            "text/plain": [
              "HBox(children=(FloatProgress(value=0.0, max=10.0), HTML(value='')))"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Validation score improved (-inf --> 0.5261804774011822). Saving model!\n",
            "Validation score improved (0.5261804774011822 --> 0.5292934903823296). Saving model!\n",
            "Validation score improved (0.5292934903823296 --> 0.530568250100935). Saving model!\n",
            "Validation score improved (0.530568250100935 --> 0.5315578757069889). Saving model!\n",
            "Validation score improved (0.5315578757069889 --> 0.5324267436539989). Saving model!\n",
            "Validation score improved (0.5324267436539989 --> 0.5332396648633788). Saving model!\n",
            "Validation score improved (0.5332396648633788 --> 0.5339353862784003). Saving model!\n",
            "Validation score improved (0.5339353862784003 --> 0.5344012815033952). Saving model!\n",
            "Validation score improved (0.5344012815033952 --> 0.5349396695231505). Saving model!\n",
            "Validation score improved (0.5349396695231505 --> 0.5352470403368991). Saving model!\n",
            "\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 388
        },
        "id": "Pj-ubF0enaWC",
        "outputId": "c7126c66-fe9d-4518-9d6c-5dc5c4a945e8"
      },
      "source": [
        "from tqdm import tqdm_notebook\n",
        "\n",
        "import janestreet\n",
        "env = janestreet.make_env()\n",
        "\n",
        "# learn.model.eval()\n",
        "preds = []\n",
        "for (test_df, pred_df) in tqdm_notebook(env.iter_test()):\n",
        "    if test_df['weight'].item() > 0:\n",
        "        test_np = test_df.loc[:, features].values\n",
        "        test_np[:, 1:] = for_loop(fillna_npwhere_njit, test_np[:, 1:], f_mean)\n",
        "        pred = torch.mean(model(torch.tensor(test_np, dtype=torch.float).cuda(device))).item()\n",
        "        preds.append(pred)\n",
        "        action = 1 if pred >= .5 else 0\n",
        "        pred_df.action = action\n",
        "    else:\n",
        "        pred_df.action = 0\n",
        "    env.predict(pred_df)"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ModuleNotFoundError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-23-bd6a4cb6b875>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mtqdm\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtqdm_notebook\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mjanestreet\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0menv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mjanestreet\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_env\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'janestreet'",
            "",
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "trusted": true,
        "id": "IDwfbrhunaWD"
      },
      "source": [
        "preds = np.array(preds)\n",
        "preds.mean(), preds.std(), sum(preds >= .5), sum(preds < 5)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}