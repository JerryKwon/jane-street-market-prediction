{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-16T11:06:00.990072Z",
     "iopub.status.busy": "2021-02-16T11:06:00.989247Z",
     "iopub.status.idle": "2021-02-16T11:06:07.366290Z",
     "shell.execute_reply": "2021-02-16T11:06:07.365631Z"
    },
    "papermill": {
     "duration": 6.419715,
     "end_time": "2021-02-16T11:06:07.366425",
     "exception": false,
     "start_time": "2021-02-16T11:06:00.946710",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import operator\n",
    "import seaborn as sns\n",
    "import sklearn\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from tqdm import tqdm\n",
    "from random import choices\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:06:07.443261Z",
     "iopub.status.busy": "2021-02-16T11:06:07.442448Z",
     "iopub.status.idle": "2021-02-16T11:06:07.446548Z",
     "shell.execute_reply": "2021-02-16T11:06:07.447297Z"
    },
    "papermill": {
     "duration": 0.047703,
     "end_time": "2021-02-16T11:06:07.447461",
     "exception": false,
     "start_time": "2021-02-16T11:06:07.399758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.3.1\n",
      "Accelerated Linear Algebra enabled\n"
     ]
    }
   ],
   "source": [
    "# tf setup\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "MIXED_PRECISION = False\n",
    "XLA_ACCELERATE = True\n",
    "\n",
    "if MIXED_PRECISION:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "    if tpu: policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
    "    else: policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "    mixed_precision.set_policy(policy)\n",
    "    print('Mixed precision enabled')\n",
    "\n",
    "if XLA_ACCELERATE:\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    print('Accelerated Linear Algebra enabled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.036072,
     "end_time": "2021-02-16T11:06:07.519476",
     "exception": false,
     "start_time": "2021-02-16T11:06:07.483404",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:06:07.595007Z",
     "iopub.status.busy": "2021-02-16T11:06:07.594179Z",
     "iopub.status.idle": "2021-02-16T11:06:07.596912Z",
     "shell.execute_reply": "2021-02-16T11:06:07.597348Z"
    },
    "papermill": {
     "duration": 0.042487,
     "end_time": "2021-02-16T11:06:07.597473",
     "exception": false,
     "start_time": "2021-02-16T11:06:07.554986",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CV_STRATEGY = 'StratifiedGroupKFold' # GroupKFold, PurgedGroupTimeSeriesSplit\n",
    "SEED = 2021\n",
    "START_DATE = 86\n",
    "FOLDS = 5\n",
    "\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.068328,
     "end_time": "2021-02-16T11:06:07.699424",
     "exception": false,
     "start_time": "2021-02-16T11:06:07.631096",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV Strategy\n",
    "\n",
    "## PurgedGroupTimeSeriesSplit\n",
    "Click the code button to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-16T11:06:07.798436Z",
     "iopub.status.busy": "2021-02-16T11:06:07.790811Z",
     "iopub.status.idle": "2021-02-16T11:06:07.801339Z",
     "shell.execute_reply": "2021-02-16T11:06:07.800831Z"
    },
    "papermill": {
     "duration": 0.066496,
     "end_time": "2021-02-16T11:06:07.801437",
     "exception": false,
     "start_time": "2021-02-16T11:06:07.734941",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034985,
     "end_time": "2021-02-16T11:06:07.871517",
     "exception": false,
     "start_time": "2021-02-16T11:06:07.836532",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## GroupKFold, StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:06:07.974871Z",
     "iopub.status.busy": "2021-02-16T11:06:07.952095Z",
     "iopub.status.idle": "2021-02-16T11:06:07.978036Z",
     "shell.execute_reply": "2021-02-16T11:06:07.977335Z"
    },
    "papermill": {
     "duration": 0.07095,
     "end_time": "2021-02-16T11:06:07.978140",
     "exception": false,
     "start_time": "2021-02-16T11:06:07.907190",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "from collections import Counter, defaultdict\n",
    "from sklearn import model_selection\n",
    "\n",
    "# ---- GroupKFold ----\n",
    "class GroupKFold(object):\n",
    "    \"\"\"\n",
    "    GroupKFold with random shuffle with a sklearn-like structure\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=4, shuffle=True, random_state=42):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, group=None):\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y, group):\n",
    "        kf = model_selection.KFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state)\n",
    "        unique_ids = X[group].unique()\n",
    "        for fold, (tr_group_idx, va_group_idx) in enumerate(kf.split(unique_ids)):\n",
    "            # split group\n",
    "            tr_group, va_group = unique_ids[tr_group_idx], unique_ids[va_group_idx]\n",
    "            train_idx = np.where(X[group].isin(tr_group))[0]\n",
    "            val_idx = np.where(X[group].isin(va_group))[0]\n",
    "            yield train_idx, val_idx\n",
    "\n",
    "# ---- StratifiedGroupKFold ----\n",
    "class StratifiedGroupKFold(object):\n",
    "    \"\"\"\n",
    "    StratifiedGroupKFold with random shuffle with a sklearn-like structure\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=4, shuffle=True, random_state=42):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, group=None):\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y, group):\n",
    "        labels_num = np.max(y) + 1\n",
    "        y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "        y_distr = Counter()\n",
    "        groups = X[group].values\n",
    "        for label, g in zip(y, groups):\n",
    "            y_counts_per_group[g][label] += 1\n",
    "            y_distr[label] += 1\n",
    "\n",
    "        y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "        groups_per_fold = defaultdict(set)\n",
    "\n",
    "        def eval_y_counts_per_fold(y_counts, fold):\n",
    "            y_counts_per_fold[fold] += y_counts\n",
    "            std_per_label = []\n",
    "            for label in range(labels_num):\n",
    "                label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(self.n_splits)])\n",
    "                std_per_label.append(label_std)\n",
    "            y_counts_per_fold[fold] -= y_counts\n",
    "            return np.mean(std_per_label)\n",
    "        \n",
    "        groups_and_y_counts = list(y_counts_per_group.items())\n",
    "        random.Random(self.random_state).shuffle(groups_and_y_counts)\n",
    "\n",
    "        for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "            best_fold = None\n",
    "            min_eval = None\n",
    "            for i in range(self.n_splits):\n",
    "                fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "                if min_eval is None or fold_eval < min_eval:\n",
    "                    min_eval = fold_eval\n",
    "                    best_fold = i\n",
    "            y_counts_per_fold[best_fold] += y_counts\n",
    "            groups_per_fold[best_fold].add(g)\n",
    "\n",
    "        all_groups = set(groups)\n",
    "        for i in range(self.n_splits):\n",
    "            train_groups = all_groups - groups_per_fold[i]\n",
    "            test_groups = groups_per_fold[i]\n",
    "\n",
    "            train_idx = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "            test_idx = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "            yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.0374,
     "end_time": "2021-02-16T11:06:08.050196",
     "exception": false,
     "start_time": "2021-02-16T11:06:08.012796",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:06:08.129728Z",
     "iopub.status.busy": "2021-02-16T11:06:08.129017Z",
     "iopub.status.idle": "2021-02-16T11:08:33.218693Z",
     "shell.execute_reply": "2021-02-16T11:08:33.216997Z"
    },
    "papermill": {
     "duration": 145.13366,
     "end_time": "2021-02-16T11:08:33.218829",
     "exception": false,
     "start_time": "2021-02-16T11:06:08.085169",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/jane-street-market-prediction/train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:08:33.309253Z",
     "iopub.status.busy": "2021-02-16T11:08:33.307136Z",
     "iopub.status.idle": "2021-02-16T11:08:33.310055Z",
     "shell.execute_reply": "2021-02-16T11:08:33.310590Z"
    },
    "papermill": {
     "duration": 0.056873,
     "end_time": "2021-02-16T11:08:33.310722",
     "exception": false,
     "start_time": "2021-02-16T11:08:33.253849",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    \n",
    "    start_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe is {start_memory} MB\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != 'object':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            \n",
    "            else:\n",
    "                \"\"\"if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\"\"\"\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    end_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\n",
    "    print(f\"Reduced by {100 * (start_memory - end_memory) / start_memory} % \")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:08:33.400573Z",
     "iopub.status.busy": "2021-02-16T11:08:33.398670Z",
     "iopub.status.idle": "2021-02-16T11:09:24.895488Z",
     "shell.execute_reply": "2021-02-16T11:09:24.896051Z"
    },
    "papermill": {
     "duration": 51.55108,
     "end_time": "2021-02-16T11:09:24.896226",
     "exception": false,
     "start_time": "2021-02-16T11:08:33.345146",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2516.843978881836 MB\n",
      "Memory usage of dataframe after reduction 1247.0233011245728 MB\n",
      "Reduced by 50.45289610369131 % \n"
     ]
    }
   ],
   "source": [
    "train = reduce_memory_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:09:24.976569Z",
     "iopub.status.busy": "2021-02-16T11:09:24.975517Z",
     "iopub.status.idle": "2021-02-16T11:09:28.459722Z",
     "shell.execute_reply": "2021-02-16T11:09:28.458655Z"
    },
    "papermill": {
     "duration": 3.528155,
     "end_time": "2021-02-16T11:09:28.459846",
     "exception": false,
     "start_time": "2021-02-16T11:09:24.931691",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train = pd.read_feather('../input/janestreet-save-as-feather/train.feather') # faster data load\n",
    "train = train.query(f'date >= {START_DATE}').reset_index(drop = True) \n",
    "train = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns}) #limit memory use\n",
    "train.fillna(train.mean(),inplace=True)\n",
    "train = train.query('weight > 0').reset_index(drop = True)\n",
    "#train['action'] = (train['resp'] > 0).astype('int')\n",
    "train['action'] =  (  (train['resp_1'] > 0 ) & (train['resp_2'] > 0 ) & (train['resp_3'] > 0 ) & (train['resp_4'] > 0 ) &  (train['resp'] > 0 )   ).astype('int')\n",
    "features = [c for c in train.columns if 'feature' in c]\n",
    "\n",
    "resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:09:28.535247Z",
     "iopub.status.busy": "2021-02-16T11:09:28.534305Z",
     "iopub.status.idle": "2021-02-16T11:09:28.537655Z",
     "shell.execute_reply": "2021-02-16T11:09:28.537115Z"
    },
    "papermill": {
     "duration": 0.042194,
     "end_time": "2021-02-16T11:09:28.537759",
     "exception": false,
     "start_time": "2021-02-16T11:09:28.495565",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    train = train.sample(10000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.034466,
     "end_time": "2021-02-16T11:09:28.606735",
     "exception": false,
     "start_time": "2021-02-16T11:09:28.572269",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.035295,
     "end_time": "2021-02-16T11:09:28.676562",
     "exception": false,
     "start_time": "2021-02-16T11:09:28.641267",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Creating Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:09:28.760266Z",
     "iopub.status.busy": "2021-02-16T11:09:28.759251Z",
     "iopub.status.idle": "2021-02-16T11:09:28.761952Z",
     "shell.execute_reply": "2021-02-16T11:09:28.762573Z"
    },
    "papermill": {
     "duration": 0.050959,
     "end_time": "2021-02-16T11:09:28.762702",
     "exception": false,
     "start_time": "2021-02-16T11:09:28.711743",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_autoencoder(input_dim,output_dim,noise=0.05):\n",
    "    i = tf.keras.layers.Input(input_dim)\n",
    "    encoded = tf.keras.layers.BatchNormalization()(i)\n",
    "    encoded = tf.keras.layers.GaussianNoise(noise)(encoded)\n",
    "    encoded = tf.keras.layers.Dense(64,activation='relu')(encoded)\n",
    "    decoded = tf.keras.layers.Dropout(0.2)(encoded)\n",
    "    decoded = tf.keras.layers.Dense(input_dim,name='decoded')(decoded)\n",
    "    x = tf.keras.layers.Dense(32,activation='relu')(decoded)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(output_dim,activation='sigmoid',name='label_output')(x)\n",
    "    \n",
    "    encoder = tf.keras.models.Model(inputs=i,outputs=encoded)\n",
    "    autoencoder = tf.keras.models.Model(inputs=i,outputs=[decoded,x])\n",
    "    \n",
    "    autoencoder.compile(optimizer=tf.keras.optimizers.Adam(0.001), \n",
    "                        loss={'decoded':'mse','label_output':'binary_crossentropy'})\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03572,
     "end_time": "2021-02-16T11:09:28.833558",
     "exception": false,
     "start_time": "2021-02-16T11:09:28.797838",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Creating 1dcnn \n",
    "Just put 1dcnn before fead-forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-02-16T11:09:28.921909Z",
     "iopub.status.busy": "2021-02-16T11:09:28.920879Z",
     "iopub.status.idle": "2021-02-16T11:09:28.923852Z",
     "shell.execute_reply": "2021-02-16T11:09:28.924338Z"
    },
    "papermill": {
     "duration": 0.054629,
     "end_time": "2021-02-16T11:09:28.924469",
     "exception": false,
     "start_time": "2021-02-16T11:09:28.869840",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_1dcnn(input_dim, output_dim, encoder):\n",
    "    # input\n",
    "    inputs = tf.keras.layers.Input(input_dim)\n",
    "    \n",
    "    x = encoder(inputs)\n",
    "    x = tf.keras.layers.Concatenate()([x,inputs]) #use both raw and encoded features\n",
    "    \n",
    "    # normalize\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    # 1dcnn\n",
    "    x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "    x = tf.keras.layers.Reshape((256, 16))(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=16,\n",
    "                      kernel_size=7,\n",
    "                      strides=1,\n",
    "                      activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    # ffn\n",
    "    for i in range(2):\n",
    "        x = tf.keras.layers.Dense(256 // (2 ** i), activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.GaussianNoise(0.01)(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(output_dim, activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=inputs,outputs=x)\n",
    "    \n",
    "    # compile\n",
    "    opt = tfa.optimizers.RectifiedAdam(learning_rate=1e-03)\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=1e-02)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=loss, \n",
    "                  metrics=[tf.keras.metrics.AUC(name = 'auc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:09:29.021774Z",
     "iopub.status.busy": "2021-02-16T11:09:29.007139Z",
     "iopub.status.idle": "2021-02-16T11:09:29.025056Z",
     "shell.execute_reply": "2021-02-16T11:09:29.024444Z"
    },
    "papermill": {
     "duration": 0.064151,
     "end_time": "2021-02-16T11:09:29.025165",
     "exception": false,
     "start_time": "2021-02-16T11:09:28.961014",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_resnet(n_features, n_labels, encoder, label_smoothing = 0.0005):    \n",
    "    input_1 = tf.keras.layers.Input(shape = (n_features,))\n",
    "    input_2 = encoder(input_1)\n",
    "\n",
    "    head_1 = tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(512, activation=\"elu\"), \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(256, activation = \"elu\")\n",
    "        ],name='Head1') \n",
    "\n",
    "    input_3 = head_1(input_1)\n",
    "    input_3_concat = tf.keras.layers.Concatenate()([input_2, input_3])\n",
    "\n",
    "    head_2 = tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(512, \"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(512, \"elu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(256, \"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(256, \"elu\")\n",
    "        ],name='Head2')\n",
    "\n",
    "    input_4 = head_2(input_3_concat)\n",
    "    input_4_avg = tf.keras.layers.Average()([input_3, input_4]) \n",
    "\n",
    "    head_3 = tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(256, kernel_initializer='lecun_normal', activation='selu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(128, kernel_initializer='lecun_normal', activation='selu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1), name='l2_norm'),\n",
    "        tf.keras.layers.Dense(n_labels, activation=\"sigmoid\")\n",
    "        ],name='Head3')\n",
    "\n",
    "    output = head_3(input_4_avg)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [input_1, ], outputs = output)\n",
    "    opt = tfa.optimizers.RectifiedAdam(learning_rate=1e-03)\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing), \n",
    "                  metrics=['AUC'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:09:29.192814Z",
     "iopub.status.busy": "2021-02-16T11:09:29.191999Z",
     "iopub.status.idle": "2021-02-16T11:09:29.195372Z",
     "shell.execute_reply": "2021-02-16T11:09:29.195838Z"
    },
    "papermill": {
     "duration": 0.047893,
     "end_time": "2021-02-16T11:09:29.195972",
     "exception": false,
     "start_time": "2021-02-16T11:09:29.148079",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = features\n",
    "p.append('resp')\n",
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:09:29.456326Z",
     "iopub.status.busy": "2021-02-16T11:09:29.454958Z",
     "iopub.status.idle": "2021-02-16T11:10:25.496651Z",
     "shell.execute_reply": "2021-02-16T11:10:25.497413Z"
    },
    "papermill": {
     "duration": 56.264382,
     "end_time": "2021-02-16T11:10:25.497589",
     "exception": false,
     "start_time": "2021-02-16T11:09:29.233207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = train[p].corr()\n",
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:10:25.582394Z",
     "iopub.status.busy": "2021-02-16T11:10:25.581404Z",
     "iopub.status.idle": "2021-02-16T11:10:25.618348Z",
     "shell.execute_reply": "2021-02-16T11:10:25.619086Z"
    },
    "papermill": {
     "duration": 0.084053,
     "end_time": "2021-02-16T11:10:25.619230",
     "exception": false,
     "start_time": "2021-02-16T11:10:25.535177",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature_25', 'feature_35', 'feature_48', 'feature_61', 'feature_63', 'feature_66', 'feature_68', 'feature_101', 'feature_107', 'feature_108', 'feature_113', 'feature_114', 'feature_119', 'feature_122', 'feature_126', 'feature_127', 'feature_128', 'feature_129']\n"
     ]
    }
   ],
   "source": [
    "x = x.abs()\n",
    "upper = x.where(np.triu(np.ones(x.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "print(to_drop)\n",
    "del x, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:10:25.875719Z",
     "iopub.status.busy": "2021-02-16T11:10:25.873770Z",
     "iopub.status.idle": "2021-02-16T11:10:25.876405Z",
     "shell.execute_reply": "2021-02-16T11:10:25.876865Z"
    },
    "papermill": {
     "duration": 0.217041,
     "end_time": "2021-02-16T11:10:25.877010",
     "exception": false,
     "start_time": "2021-02-16T11:10:25.659969",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.drop(to_drop, 1, inplace=True)\n",
    "del to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:10:26.113447Z",
     "iopub.status.busy": "2021-02-16T11:10:26.111881Z",
     "iopub.status.idle": "2021-02-16T11:10:28.518840Z",
     "shell.execute_reply": "2021-02-16T11:10:28.518286Z"
    },
    "papermill": {
     "duration": 2.604441,
     "end_time": "2021-02-16T11:10:28.518964",
     "exception": false,
     "start_time": "2021-02-16T11:10:25.914523",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if 'feature' in c]\n",
    "\n",
    "X = train[features].values\n",
    "y = train['action']\n",
    "\n",
    "f_mean = np.mean(train[features[1:]].values,axis=0)\n",
    "\n",
    "# Next, we hold out part of the training data to form the hold-out validation set\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.2)\n",
    "del valid_x, valid_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:10:28.945475Z",
     "iopub.status.busy": "2021-02-16T11:10:28.944769Z",
     "iopub.status.idle": "2021-02-16T11:10:29.211492Z",
     "shell.execute_reply": "2021-02-16T11:10:29.212373Z"
    },
    "papermill": {
     "duration": 0.312477,
     "end_time": "2021-02-16T11:10:29.212519",
     "exception": false,
     "start_time": "2021-02-16T11:10:28.900042",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import treelite\n",
    "import treelite_runtime\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:10:29.336344Z",
     "iopub.status.busy": "2021-02-16T11:10:29.335221Z",
     "iopub.status.idle": "2021-02-16T11:10:31.611771Z",
     "shell.execute_reply": "2021-02-16T11:10:31.610635Z"
    },
    "papermill": {
     "duration": 2.340711,
     "end_time": "2021-02-16T11:10:31.611931",
     "exception": false,
     "start_time": "2021-02-16T11:10:29.271220",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We create the XGboost-specific DMatrix data format from the numpy array. \n",
    "# This data structure is optimised for memory efficiency and training speed\n",
    "dtrain = xgb.DMatrix(train_x, label=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:10:31.701772Z",
     "iopub.status.busy": "2021-02-16T11:10:31.701014Z",
     "iopub.status.idle": "2021-02-16T11:14:32.284390Z",
     "shell.execute_reply": "2021-02-16T11:14:32.285138Z"
    },
    "papermill": {
     "duration": 240.632193,
     "end_time": "2021-02-16T11:14:32.285299",
     "exception": false,
     "start_time": "2021-02-16T11:10:31.653106",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.656437\n",
      "[1]\ttrain-logloss:0.623436\n",
      "[2]\ttrain-logloss:0.594489\n",
      "[3]\ttrain-logloss:0.568319\n",
      "[4]\ttrain-logloss:0.544322\n",
      "[5]\ttrain-logloss:0.521805\n",
      "[6]\ttrain-logloss:0.501208\n",
      "[7]\ttrain-logloss:0.481793\n",
      "[8]\ttrain-logloss:0.46456\n",
      "[9]\ttrain-logloss:0.448322\n",
      "[10]\ttrain-logloss:0.43222\n",
      "[11]\ttrain-logloss:0.417025\n",
      "[12]\ttrain-logloss:0.403278\n",
      "[13]\ttrain-logloss:0.39055\n",
      "[14]\ttrain-logloss:0.378693\n",
      "[15]\ttrain-logloss:0.366939\n",
      "[16]\ttrain-logloss:0.355893\n",
      "[17]\ttrain-logloss:0.345916\n",
      "[18]\ttrain-logloss:0.336233\n",
      "[19]\ttrain-logloss:0.326694\n",
      "[20]\ttrain-logloss:0.318711\n",
      "[21]\ttrain-logloss:0.310871\n",
      "[22]\ttrain-logloss:0.303688\n",
      "[23]\ttrain-logloss:0.297223\n",
      "[24]\ttrain-logloss:0.291542\n",
      "[25]\ttrain-logloss:0.285331\n",
      "[26]\ttrain-logloss:0.279164\n",
      "[27]\ttrain-logloss:0.274718\n",
      "[28]\ttrain-logloss:0.269806\n",
      "[29]\ttrain-logloss:0.264769\n",
      "[30]\ttrain-logloss:0.260779\n",
      "[31]\ttrain-logloss:0.25494\n",
      "[32]\ttrain-logloss:0.250608\n",
      "[33]\ttrain-logloss:0.246\n",
      "[34]\ttrain-logloss:0.24322\n",
      "[35]\ttrain-logloss:0.24013\n",
      "[36]\ttrain-logloss:0.237209\n",
      "[37]\ttrain-logloss:0.234486\n",
      "[38]\ttrain-logloss:0.229876\n",
      "[39]\ttrain-logloss:0.227823\n",
      "[40]\ttrain-logloss:0.223379\n",
      "[41]\ttrain-logloss:0.220224\n",
      "[42]\ttrain-logloss:0.217969\n",
      "[43]\ttrain-logloss:0.216165\n",
      "[44]\ttrain-logloss:0.212685\n",
      "[45]\ttrain-logloss:0.208957\n",
      "[46]\ttrain-logloss:0.205888\n",
      "[47]\ttrain-logloss:0.203138\n",
      "[48]\ttrain-logloss:0.198701\n",
      "[49]\ttrain-logloss:0.196062\n",
      "[50]\ttrain-logloss:0.194125\n",
      "[51]\ttrain-logloss:0.191093\n",
      "[52]\ttrain-logloss:0.189289\n",
      "[53]\ttrain-logloss:0.187131\n",
      "[54]\ttrain-logloss:0.184262\n",
      "[55]\ttrain-logloss:0.182128\n",
      "[56]\ttrain-logloss:0.18136\n",
      "[57]\ttrain-logloss:0.178586\n",
      "[58]\ttrain-logloss:0.17674\n",
      "[59]\ttrain-logloss:0.173518\n",
      "[60]\ttrain-logloss:0.171425\n",
      "[61]\ttrain-logloss:0.16873\n",
      "[62]\ttrain-logloss:0.166364\n",
      "[63]\ttrain-logloss:0.164161\n",
      "[64]\ttrain-logloss:0.161579\n",
      "[65]\ttrain-logloss:0.159761\n",
      "[66]\ttrain-logloss:0.1575\n",
      "[67]\ttrain-logloss:0.154674\n",
      "[68]\ttrain-logloss:0.153475\n",
      "[69]\ttrain-logloss:0.150231\n",
      "[70]\ttrain-logloss:0.148976\n",
      "[71]\ttrain-logloss:0.146045\n",
      "[72]\ttrain-logloss:0.143835\n",
      "[73]\ttrain-logloss:0.143133\n",
      "[74]\ttrain-logloss:0.140784\n",
      "[75]\ttrain-logloss:0.139067\n",
      "[76]\ttrain-logloss:0.137616\n",
      "[77]\ttrain-logloss:0.135535\n",
      "[78]\ttrain-logloss:0.132953\n",
      "[79]\ttrain-logloss:0.131142\n",
      "[80]\ttrain-logloss:0.128834\n",
      "[81]\ttrain-logloss:0.127686\n",
      "[82]\ttrain-logloss:0.126347\n",
      "[83]\ttrain-logloss:0.124976\n",
      "[84]\ttrain-logloss:0.123811\n",
      "[85]\ttrain-logloss:0.12295\n",
      "[86]\ttrain-logloss:0.121728\n",
      "[87]\ttrain-logloss:0.119486\n",
      "[88]\ttrain-logloss:0.117343\n",
      "[89]\ttrain-logloss:0.115745\n",
      "[90]\ttrain-logloss:0.11437\n",
      "[91]\ttrain-logloss:0.113254\n",
      "[92]\ttrain-logloss:0.111881\n",
      "[93]\ttrain-logloss:0.11001\n",
      "[94]\ttrain-logloss:0.108955\n",
      "[95]\ttrain-logloss:0.107334\n",
      "[96]\ttrain-logloss:0.106546\n",
      "[97]\ttrain-logloss:0.105771\n",
      "[98]\ttrain-logloss:0.104721\n",
      "[99]\ttrain-logloss:0.103262\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'n_estimators': 435,\n",
    "        'max_depth': 24,\n",
    "        'learning_rate': 0.09905592273886195,\n",
    "        'subsample': 0.8704369112806065,\n",
    "        'colsample_bytree': 0.9932309296458037,\n",
    "        'objective': 'binary:logistic',\n",
    "        'gamma': 7,\n",
    "        \"eval_metric\" : 'logloss',\n",
    "        'seed': 2021,\n",
    "        'tree_method': 'gpu_hist'\n",
    "        }\n",
    "bst = xgb.train(params, dtrain, 100, [(dtrain, 'train')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:14:32.459475Z",
     "iopub.status.busy": "2021-02-16T11:14:32.457791Z",
     "iopub.status.idle": "2021-02-16T11:14:33.003361Z",
     "shell.execute_reply": "2021-02-16T11:14:33.002692Z"
    },
    "papermill": {
     "duration": 0.636224,
     "end_time": "2021-02-16T11:14:33.003487",
     "exception": false,
     "start_time": "2021-02-16T11:14:32.367263",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pass to treelite\n",
    "model1 = treelite.Model.from_xgboost(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:14:33.221179Z",
     "iopub.status.busy": "2021-02-16T11:14:33.220266Z",
     "iopub.status.idle": "2021-02-16T11:16:06.426882Z",
     "shell.execute_reply": "2021-02-16T11:16:06.427380Z"
    },
    "papermill": {
     "duration": 93.345238,
     "end_time": "2021-02-16T11:16:06.427532",
     "exception": false,
     "start_time": "2021-02-16T11:14:33.082294",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:14:33] ../src/compiler/failsafe.cc:245: Using FailSafeCompiler\n",
      "[11:14:33] ../src/compiler/failsafe.cc:256: Warning: 'parallel_comp' parameter is not applicable for FailSafeCompiler\n",
      "[11:14:41] ../src/c_api/c_api.cc:286: Code generation finished. Writing code to files...\n",
      "[11:14:41] ../src/c_api/c_api.cc:291: Writing file recipe.json...\n",
      "[11:14:41] ../src/c_api/c_api.cc:291: Writing file header.h...\n",
      "[11:14:41] ../src/c_api/c_api.cc:291: Writing file main.c...\n",
      "[11:14:41] ../src/c_api/c_api.cc:291: Writing file arrays.c...\n",
      "[11:14:42] /opt/conda/lib/python3.7/site-packages/treelite/contrib/__init__.py:263: \u001b[1;31mWARNING: some of the source files are long. Expect long compilation time.\u001b[0m You may want to adjust the parameter \u001b[33mparallel_comp\u001b[0m.\n",
      "\n",
      "[11:14:42] /opt/conda/lib/python3.7/site-packages/treelite/contrib/util.py:104: Compiling sources files in directory ./tmp_8r3cr9z into object files (*.o)...\n",
      "[11:16:05] /opt/conda/lib/python3.7/site-packages/treelite/contrib/util.py:133: Generating dynamic shared library ./tmp_8r3cr9z/predictor.so...\n",
      "[11:16:06] /opt/conda/lib/python3.7/site-packages/treelite/contrib/__init__.py:278: Generated shared library in 84.30 seconds\n"
     ]
    }
   ],
   "source": [
    "# generate shared library\n",
    "toolchain = 'gcc'\n",
    "model1.export_lib(toolchain=toolchain, libpath='./mymodel.so',compiler='failsafe',\n",
    "                     params={'parallel_comp': 32}, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:16:06.587095Z",
     "iopub.status.busy": "2021-02-16T11:16:06.585874Z",
     "iopub.status.idle": "2021-02-16T11:16:06.592196Z",
     "shell.execute_reply": "2021-02-16T11:16:06.593339Z"
    },
    "papermill": {
     "duration": 0.089239,
     "end_time": "2021-02-16T11:16:06.593534",
     "exception": false,
     "start_time": "2021-02-16T11:16:06.504295",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[11:16:06] ../src/predictor/predictor.cc:262: Dynamic shared library `/kaggle/working/mymodel.so' does not contain valid get_pred_transform() function\n",
      "[11:16:06] ../src/predictor/predictor.cc:276: Dynamic shared library `/kaggle/working/mymodel.so' does not contain valid get_sigmoid_alpha() function\n",
      "[11:16:06] ../src/predictor/predictor.cc:288: Dynamic shared library `/kaggle/working/mymodel.so' does not contain valid get_global_bias() function\n",
      "[11:16:06] /opt/conda/lib/python3.7/site-packages/treelite_runtime/predictor.py:311: Dynamic shared library /kaggle/working/mymodel.so has been successfully loaded into memory\n"
     ]
    }
   ],
   "source": [
    "# predictor from treelite\n",
    "predictor = treelite_runtime.Predictor('./mymodel.so', verbose=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.12234,
     "end_time": "2021-02-16T11:16:06.844511",
     "exception": false,
     "start_time": "2021-02-16T11:16:06.722171",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Fit Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:16:07.015291Z",
     "iopub.status.busy": "2021-02-16T11:16:07.014419Z",
     "iopub.status.idle": "2021-02-16T11:16:07.367174Z",
     "shell.execute_reply": "2021-02-16T11:16:07.366609Z"
    },
    "papermill": {
     "duration": 0.43722,
     "end_time": "2021-02-16T11:16:07.367285",
     "exception": false,
     "start_time": "2021-02-16T11:16:06.930065",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del y, train_x, train_y\n",
    "y = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T #Multitarget\n",
    "f_mean = np.mean(train[features[1:]].values,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:16:07.529010Z",
     "iopub.status.busy": "2021-02-16T11:16:07.528360Z",
     "iopub.status.idle": "2021-02-16T11:18:16.936521Z",
     "shell.execute_reply": "2021-02-16T11:18:16.935997Z"
    },
    "papermill": {
     "duration": 129.493546,
     "end_time": "2021-02-16T11:18:16.936645",
     "exception": false,
     "start_time": "2021-02-16T11:16:07.443099",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "691/691 [==============================] - 6s 8ms/step - loss: 2.4355 - decoded_loss: 1.7259 - label_output_loss: 0.7096 - val_loss: 1.2797 - val_decoded_loss: 0.5889 - val_label_output_loss: 0.6908\n",
      "Epoch 2/1000\n",
      "691/691 [==============================] - 7s 10ms/step - loss: 1.8524 - decoded_loss: 1.1605 - label_output_loss: 0.6919 - val_loss: 1.1884 - val_decoded_loss: 0.4985 - val_label_output_loss: 0.6899\n",
      "Epoch 3/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.8006 - decoded_loss: 1.1096 - label_output_loss: 0.6910 - val_loss: 1.1570 - val_decoded_loss: 0.4676 - val_label_output_loss: 0.6894\n",
      "Epoch 4/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7756 - decoded_loss: 1.0847 - label_output_loss: 0.6909 - val_loss: 1.1315 - val_decoded_loss: 0.4420 - val_label_output_loss: 0.6895\n",
      "Epoch 5/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7599 - decoded_loss: 1.0692 - label_output_loss: 0.6908 - val_loss: 1.1167 - val_decoded_loss: 0.4273 - val_label_output_loss: 0.6895\n",
      "Epoch 6/1000\n",
      "691/691 [==============================] - 4s 7ms/step - loss: 1.7428 - decoded_loss: 1.0521 - label_output_loss: 0.6906 - val_loss: 1.1076 - val_decoded_loss: 0.4182 - val_label_output_loss: 0.6894\n",
      "Epoch 7/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7403 - decoded_loss: 1.0497 - label_output_loss: 0.6906 - val_loss: 1.0851 - val_decoded_loss: 0.3957 - val_label_output_loss: 0.6894\n",
      "Epoch 8/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7294 - decoded_loss: 1.0389 - label_output_loss: 0.6905 - val_loss: 1.0844 - val_decoded_loss: 0.3954 - val_label_output_loss: 0.6890\n",
      "Epoch 9/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7150 - decoded_loss: 1.0246 - label_output_loss: 0.6904 - val_loss: 1.0780 - val_decoded_loss: 0.3889 - val_label_output_loss: 0.6891\n",
      "Epoch 10/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7116 - decoded_loss: 1.0212 - label_output_loss: 0.6904 - val_loss: 1.0648 - val_decoded_loss: 0.3758 - val_label_output_loss: 0.6891\n",
      "Epoch 11/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7072 - decoded_loss: 1.0169 - label_output_loss: 0.6903 - val_loss: 1.0664 - val_decoded_loss: 0.3776 - val_label_output_loss: 0.6888\n",
      "Epoch 12/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7001 - decoded_loss: 1.0098 - label_output_loss: 0.6902 - val_loss: 1.0673 - val_decoded_loss: 0.3785 - val_label_output_loss: 0.6888\n",
      "Epoch 13/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6970 - decoded_loss: 1.0067 - label_output_loss: 0.6903 - val_loss: 1.0624 - val_decoded_loss: 0.3737 - val_label_output_loss: 0.6887\n",
      "Epoch 14/1000\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 1.7031 - decoded_loss: 1.0128 - label_output_loss: 0.6902 - val_loss: 1.0518 - val_decoded_loss: 0.3629 - val_label_output_loss: 0.6888\n",
      "Epoch 15/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6919 - decoded_loss: 1.0017 - label_output_loss: 0.6902 - val_loss: 1.0489 - val_decoded_loss: 0.3602 - val_label_output_loss: 0.6887\n",
      "Epoch 16/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6897 - decoded_loss: 0.9995 - label_output_loss: 0.6902 - val_loss: 1.0556 - val_decoded_loss: 0.3670 - val_label_output_loss: 0.6887\n",
      "Epoch 17/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6912 - decoded_loss: 1.0011 - label_output_loss: 0.6901 - val_loss: 1.0488 - val_decoded_loss: 0.3599 - val_label_output_loss: 0.6889\n",
      "Epoch 18/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6884 - decoded_loss: 0.9983 - label_output_loss: 0.6902 - val_loss: 1.0474 - val_decoded_loss: 0.3587 - val_label_output_loss: 0.6887\n",
      "Epoch 19/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6867 - decoded_loss: 0.9966 - label_output_loss: 0.6901 - val_loss: 1.0503 - val_decoded_loss: 0.3614 - val_label_output_loss: 0.6889\n",
      "Epoch 20/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6784 - decoded_loss: 0.9883 - label_output_loss: 0.6901 - val_loss: 1.0559 - val_decoded_loss: 0.3671 - val_label_output_loss: 0.6888\n",
      "Epoch 21/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6772 - decoded_loss: 0.9872 - label_output_loss: 0.6900 - val_loss: 1.0660 - val_decoded_loss: 0.3773 - val_label_output_loss: 0.6887\n",
      "Epoch 22/1000\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 1.6793 - decoded_loss: 0.9892 - label_output_loss: 0.6901 - val_loss: 1.0538 - val_decoded_loss: 0.3653 - val_label_output_loss: 0.6886\n",
      "Epoch 23/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6799 - decoded_loss: 0.9898 - label_output_loss: 0.6901 - val_loss: 1.0547 - val_decoded_loss: 0.3660 - val_label_output_loss: 0.6887\n",
      "Epoch 24/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6608 - decoded_loss: 0.9707 - label_output_loss: 0.6900 - val_loss: 1.0614 - val_decoded_loss: 0.3727 - val_label_output_loss: 0.6887\n",
      "Epoch 25/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6657 - decoded_loss: 0.9757 - label_output_loss: 0.6900 - val_loss: 1.0665 - val_decoded_loss: 0.3779 - val_label_output_loss: 0.6886\n",
      "Epoch 26/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6590 - decoded_loss: 0.9690 - label_output_loss: 0.6900 - val_loss: 1.0545 - val_decoded_loss: 0.3658 - val_label_output_loss: 0.6886\n",
      "Epoch 27/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6678 - decoded_loss: 0.9778 - label_output_loss: 0.6900 - val_loss: 1.0607 - val_decoded_loss: 0.3720 - val_label_output_loss: 0.6886\n",
      "Epoch 28/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6547 - decoded_loss: 0.9647 - label_output_loss: 0.6899 - val_loss: 1.0651 - val_decoded_loss: 0.3763 - val_label_output_loss: 0.6888\n"
     ]
    }
   ],
   "source": [
    "autoencoder, encoder = create_autoencoder(X.shape[-1],y.shape[-1],noise=0.1)\n",
    "autoencoder.fit(X,(X,y),\n",
    "                epochs=1000,\n",
    "                batch_size=2048, \n",
    "                validation_split=0.1,\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping('val_loss',patience=10,restore_best_weights=True)])\n",
    "encoder.save_weights('./encoder.hdf5')\n",
    "encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:18:18.546286Z",
     "iopub.status.busy": "2021-02-16T11:18:18.545193Z",
     "iopub.status.idle": "2021-02-16T11:18:18.547854Z",
     "shell.execute_reply": "2021-02-16T11:18:18.547274Z"
    },
    "papermill": {
     "duration": 0.817577,
     "end_time": "2021-02-16T11:18:18.547980",
     "exception": false,
     "start_time": "2021-02-16T11:18:17.730403",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del dtrain"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:18:20.165958Z",
     "iopub.status.busy": "2021-02-16T11:18:20.164947Z",
     "iopub.status.idle": "2021-02-16T11:29:59.796750Z",
     "shell.execute_reply": "2021-02-16T11:29:59.797290Z"
    },
    "papermill": {
     "duration": 700.449858,
     "end_time": "2021-02-16T11:29:59.797440",
     "exception": false,
     "start_time": "2021-02-16T11:18:19.347582",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "615/615 [==============================] - 13s 22ms/step - loss: 0.7260 - auc: 0.5229 - val_loss: 0.6916 - val_auc: 0.5394\n",
      "Epoch 2/192\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.6942 - auc: 0.5492 - val_loss: 0.6966 - val_auc: 0.5454\n",
      "Epoch 3/192\n",
      "615/615 [==============================] - 10s 17ms/step - loss: 0.6909 - auc: 0.5570 - val_loss: 0.6916 - val_auc: 0.5463\n",
      "Epoch 4/192\n",
      "615/615 [==============================] - 11s 18ms/step - loss: 0.6879 - auc: 0.5637 - val_loss: 0.6910 - val_auc: 0.5453\n",
      "Epoch 5/192\n",
      "615/615 [==============================] - 10s 17ms/step - loss: 0.6848 - auc: 0.5704 - val_loss: 0.6943 - val_auc: 0.5443\n",
      "Epoch 6/192\n",
      "615/615 [==============================] - 10s 17ms/step - loss: 0.6815 - auc: 0.5775 - val_loss: 0.6944 - val_auc: 0.5476\n",
      "Epoch 7/192\n",
      "615/615 [==============================] - 11s 18ms/step - loss: 0.6779 - auc: 0.5850 - val_loss: 0.6975 - val_auc: 0.5436\n",
      "Epoch 8/192\n",
      "615/615 [==============================] - 10s 16ms/step - loss: 0.6740 - auc: 0.5932 - val_loss: 0.6999 - val_auc: 0.5441\n",
      "Epoch 9/192\n",
      "615/615 [==============================] - 10s 17ms/step - loss: 0.6699 - auc: 0.6024 - val_loss: 0.7046 - val_auc: 0.5427\n",
      "Epoch 10/192\n",
      "615/615 [==============================] - 11s 18ms/step - loss: 0.6656 - auc: 0.6118 - val_loss: 0.7111 - val_auc: 0.5416\n",
      "Epoch 11/192\n",
      "615/615 [==============================] - 10s 17ms/step - loss: 0.6610 - auc: 0.6213 - val_loss: 0.7158 - val_auc: 0.5393\n",
      "Epoch 12/192\n",
      "615/615 [==============================] - ETA: 0s - loss: 0.6562 - auc: 0.6310\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "615/615 [==============================] - 10s 16ms/step - loss: 0.6562 - auc: 0.6310 - val_loss: 0.7260 - val_auc: 0.5365\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [02:36, 156.10s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "614/614 [==============================] - 12s 19ms/step - loss: 0.7274 - auc: 0.5218 - val_loss: 0.6900 - val_auc: 0.5407\n",
      "Epoch 2/192\n",
      "614/614 [==============================] - 14s 23ms/step - loss: 0.6933 - auc: 0.5488 - val_loss: 0.6898 - val_auc: 0.5457\n",
      "Epoch 3/192\n",
      "614/614 [==============================] - 11s 17ms/step - loss: 0.6896 - auc: 0.5584 - val_loss: 0.6902 - val_auc: 0.5462\n",
      "Epoch 4/192\n",
      "614/614 [==============================] - 10s 17ms/step - loss: 0.6876 - auc: 0.5626 - val_loss: 0.6903 - val_auc: 0.5455\n",
      "Epoch 5/192\n",
      "614/614 [==============================] - 11s 18ms/step - loss: 0.6845 - auc: 0.5705 - val_loss: 0.6928 - val_auc: 0.5438\n",
      "Epoch 6/192\n",
      "614/614 [==============================] - 11s 18ms/step - loss: 0.6817 - auc: 0.5760 - val_loss: 0.6935 - val_auc: 0.5442\n",
      "Epoch 7/192\n",
      "614/614 [==============================] - 10s 16ms/step - loss: 0.6784 - auc: 0.5834 - val_loss: 0.6997 - val_auc: 0.5431\n",
      "Epoch 8/192\n",
      "614/614 [==============================] - 10s 17ms/step - loss: 0.6749 - auc: 0.5922 - val_loss: 0.7001 - val_auc: 0.5447\n",
      "Epoch 9/192\n",
      "614/614 [==============================] - 12s 19ms/step - loss: 0.6712 - auc: 0.6004 - val_loss: 0.7040 - val_auc: 0.5427\n",
      "Epoch 10/192\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6669 - auc: 0.6101\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "614/614 [==============================] - 10s 17ms/step - loss: 0.6669 - auc: 0.6101 - val_loss: 0.7090 - val_auc: 0.5412\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [04:39, 146.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "614/614 [==============================] - 13s 21ms/step - loss: 0.7230 - auc: 0.5227 - val_loss: 0.6929 - val_auc: 0.5426\n",
      "Epoch 2/192\n",
      "614/614 [==============================] - 14s 23ms/step - loss: 0.6934 - auc: 0.5494 - val_loss: 0.6910 - val_auc: 0.5454\n",
      "Epoch 3/192\n",
      "614/614 [==============================] - 11s 18ms/step - loss: 0.6902 - auc: 0.5570 - val_loss: 0.6909 - val_auc: 0.5442\n",
      "Epoch 4/192\n",
      "614/614 [==============================] - 10s 17ms/step - loss: 0.6885 - auc: 0.5604 - val_loss: 0.6907 - val_auc: 0.5460\n",
      "Epoch 5/192\n",
      "614/614 [==============================] - 10s 17ms/step - loss: 0.6853 - auc: 0.5679 - val_loss: 0.6917 - val_auc: 0.5450\n",
      "Epoch 6/192\n",
      "614/614 [==============================] - 11s 18ms/step - loss: 0.6819 - auc: 0.5759 - val_loss: 0.6963 - val_auc: 0.5436\n",
      "Epoch 7/192\n",
      "614/614 [==============================] - 10s 17ms/step - loss: 0.6787 - auc: 0.5829 - val_loss: 0.6992 - val_auc: 0.5434\n",
      "Epoch 8/192\n",
      "614/614 [==============================] - 11s 17ms/step - loss: 0.6744 - auc: 0.5923 - val_loss: 0.7009 - val_auc: 0.5416\n",
      "Epoch 9/192\n",
      "614/614 [==============================] - 11s 17ms/step - loss: 0.6705 - auc: 0.6006 - val_loss: 0.7018 - val_auc: 0.5424\n",
      "Epoch 10/192\n",
      "614/614 [==============================] - 11s 18ms/step - loss: 0.6664 - auc: 0.6097 - val_loss: 0.7083 - val_auc: 0.5391\n",
      "Epoch 11/192\n",
      "614/614 [==============================] - 10s 17ms/step - loss: 0.6617 - auc: 0.6195 - val_loss: 0.7131 - val_auc: 0.5391\n",
      "Epoch 12/192\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6571 - auc: 0.6291\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "614/614 [==============================] - 11s 17ms/step - loss: 0.6571 - auc: 0.6291 - val_loss: 0.7181 - val_auc: 0.5366\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [07:04, 145.88s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "615/615 [==============================] - 12s 19ms/step - loss: 0.7268 - auc: 0.5223 - val_loss: 0.6904 - val_auc: 0.5394\n",
      "Epoch 2/192\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.6942 - auc: 0.5490 - val_loss: 0.6896 - val_auc: 0.5446\n",
      "Epoch 3/192\n",
      "615/615 [==============================] - 11s 18ms/step - loss: 0.6901 - auc: 0.5591 - val_loss: 0.6899 - val_auc: 0.5445\n",
      "Epoch 4/192\n",
      "615/615 [==============================] - 11s 17ms/step - loss: 0.6869 - auc: 0.5656 - val_loss: 0.6906 - val_auc: 0.5445\n",
      "Epoch 5/192\n",
      "615/615 [==============================] - 10s 17ms/step - loss: 0.6839 - auc: 0.5724 - val_loss: 0.6921 - val_auc: 0.5457\n",
      "Epoch 6/192\n",
      "615/615 [==============================] - 12s 19ms/step - loss: 0.6806 - auc: 0.5798 - val_loss: 0.6956 - val_auc: 0.5424\n",
      "Epoch 7/192\n",
      "615/615 [==============================] - 10s 17ms/step - loss: 0.6769 - auc: 0.5879 - val_loss: 0.6955 - val_auc: 0.5438\n",
      "Epoch 8/192\n",
      "615/615 [==============================] - 10s 16ms/step - loss: 0.6730 - auc: 0.5961 - val_loss: 0.6981 - val_auc: 0.5447\n",
      "Epoch 9/192\n",
      "615/615 [==============================] - 12s 19ms/step - loss: 0.6689 - auc: 0.6053 - val_loss: 0.7040 - val_auc: 0.5414\n",
      "Epoch 10/192\n",
      "615/615 [==============================] - ETA: 0s - loss: 0.6645 - auc: 0.6147\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "615/615 [==============================] - 11s 17ms/step - loss: 0.6645 - auc: 0.6147 - val_loss: 0.7083 - val_auc: 0.5388\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [09:11, 140.32s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "614/614 [==============================] - 13s 22ms/step - loss: 0.7249 - auc: 0.5224 - val_loss: 0.6912 - val_auc: 0.5356\n",
      "Epoch 2/192\n",
      "614/614 [==============================] - 15s 24ms/step - loss: 0.6937 - auc: 0.5492 - val_loss: 0.6936 - val_auc: 0.5415\n",
      "Epoch 3/192\n",
      "614/614 [==============================] - 10s 17ms/step - loss: 0.6903 - auc: 0.5582 - val_loss: 0.6913 - val_auc: 0.5442\n",
      "Epoch 4/192\n",
      "614/614 [==============================] - 12s 20ms/step - loss: 0.6876 - auc: 0.5649 - val_loss: 0.6907 - val_auc: 0.5429\n",
      "Epoch 5/192\n",
      "614/614 [==============================] - 10s 16ms/step - loss: 0.6846 - auc: 0.5715 - val_loss: 0.6939 - val_auc: 0.5433\n",
      "Epoch 6/192\n",
      "614/614 [==============================] - 10s 17ms/step - loss: 0.6812 - auc: 0.5787 - val_loss: 0.6958 - val_auc: 0.5422\n",
      "Epoch 7/192\n",
      "614/614 [==============================] - 12s 20ms/step - loss: 0.6776 - auc: 0.5859 - val_loss: 0.6989 - val_auc: 0.5420\n",
      "Epoch 8/192\n",
      "614/614 [==============================] - 10s 17ms/step - loss: 0.6739 - auc: 0.5942 - val_loss: 0.7042 - val_auc: 0.5409\n",
      "Epoch 9/192\n",
      "614/614 [==============================] - 10s 16ms/step - loss: 0.6701 - auc: 0.6026 - val_loss: 0.7084 - val_auc: 0.5423\n",
      "Epoch 10/192\n",
      "614/614 [==============================] - 12s 19ms/step - loss: 0.6659 - auc: 0.6119 - val_loss: 0.7153 - val_auc: 0.5409\n",
      "Epoch 11/192\n",
      "614/614 [==============================] - 11s 18ms/step - loss: 0.6612 - auc: 0.6217 - val_loss: 0.7198 - val_auc: 0.5371\n",
      "Epoch 12/192\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6565 - auc: 0.6312\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "614/614 [==============================] - 11s 17ms/step - loss: 0.6565 - auc: 0.6312 - val_loss: 0.7263 - val_auc: 0.5373\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [11:39, 139.92s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 8min 53s, sys: 40.4 s, total: 9min 33s\n",
      "Wall time: 11min 39s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "if CV_STRATEGY == 'PurgedGroupTimeSeriesSplit':\n",
    "    gkf = PurgedGroupTimeSeriesSplit(n_splits=FOLDS, group_gap=20)\n",
    "    splits = list(gkf.split(y, groups=train['date'].values))    \n",
    "    \n",
    "elif CV_STRATEGY == \"GroupKFold\":\n",
    "    cv = GroupKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "    splits = cv.split(train, train['resp'].values.astype(int), 'date')\n",
    "\n",
    "elif CV_STRATEGY ==  \"StratifiedGroupKFold\":\n",
    "    cv = StratifiedGroupKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "    splits = cv.split(train, train['resp'].values.astype(int), 'date')\n",
    "\n",
    "models = []\n",
    "for fold, (train_indices, test_indices) in tqdm(enumerate(splits)):\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "    # model\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = create_1dcnn(X.shape[-1], y.shape[-1], encoder)\n",
    "    \n",
    "    # callbacks\n",
    "    er = tf.keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True, monitor='val_loss')\n",
    "    ReduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, verbose=1, mode='min')\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f'./model_{SEED}_{fold}.hdf5', save_weights_only=True, verbose=0, monitor='val_loss', save_best_only=True)\n",
    "    nn_callbacks = [er, ReduceLR, model_checkpoint_callback]\n",
    "    \n",
    "    # fit\n",
    "    model.fit(X_train, y_train, validation_data=(X_test,y_test), \n",
    "              epochs=192, batch_size=2048, callbacks=nn_callbacks)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:30:08.494917Z",
     "iopub.status.busy": "2021-02-16T11:30:08.493921Z",
     "iopub.status.idle": "2021-02-16T11:30:08.499176Z",
     "shell.execute_reply": "2021-02-16T11:30:08.498597Z"
    },
    "papermill": {
     "duration": 4.623324,
     "end_time": "2021-02-16T11:30:08.499284",
     "exception": false,
     "start_time": "2021-02-16T11:30:03.875960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/encoder.hdf5\n",
      "/kaggle/working/mymodel.so\n",
      "/kaggle/working/model_2021_2.hdf5\n",
      "/kaggle/working/model_2021_0.hdf5\n",
      "/kaggle/working/__notebook__.ipynb\n",
      "/kaggle/working/model_2021_1.hdf5\n",
      "/kaggle/working/model_2021_4.hdf5\n",
      "/kaggle/working/model_2021_3.hdf5\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/working'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:30:16.847920Z",
     "iopub.status.busy": "2021-02-16T11:30:16.846882Z",
     "iopub.status.idle": "2021-02-16T11:30:16.849955Z",
     "shell.execute_reply": "2021-02-16T11:30:16.849475Z"
    },
    "papermill": {
     "duration": 4.246402,
     "end_time": "2021-02-16T11:30:16.850063",
     "exception": false,
     "start_time": "2021-02-16T11:30:12.603661",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "NN_NAME = 'mlp' # 1dcnn, resnet, mlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:30:25.529391Z",
     "iopub.status.busy": "2021-02-16T11:30:25.527228Z",
     "iopub.status.idle": "2021-02-16T11:30:25.588407Z",
     "shell.execute_reply": "2021-02-16T11:30:25.587252Z"
    },
    "papermill": {
     "duration": 4.456834,
     "end_time": "2021-02-16T11:30:25.588528",
     "exception": false,
     "start_time": "2021-02-16T11:30:21.131694",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train.loc[:, train.columns.str.contains('feature')]\n",
    "y_train = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:30:34.346747Z",
     "iopub.status.busy": "2021-02-16T11:30:34.345989Z",
     "iopub.status.idle": "2021-02-16T11:42:30.143261Z",
     "shell.execute_reply": "2021-02-16T11:42:30.142706Z"
    },
    "papermill": {
     "duration": 720.138955,
     "end_time": "2021-02-16T11:42:30.143383",
     "exception": false,
     "start_time": "2021-02-16T11:30:30.004428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "384/384 - 4s - loss: 0.7172 - AUC: 0.5121\n",
      "Epoch 2/200\n",
      "384/384 - 6s - loss: 0.6946 - AUC: 0.5272\n",
      "Epoch 3/200\n",
      "384/384 - 3s - loss: 0.6914 - AUC: 0.5343\n",
      "Epoch 4/200\n",
      "384/384 - 3s - loss: 0.6904 - AUC: 0.5380\n",
      "Epoch 5/200\n",
      "384/384 - 3s - loss: 0.6900 - AUC: 0.5409\n",
      "Epoch 6/200\n",
      "384/384 - 5s - loss: 0.6897 - AUC: 0.5427\n",
      "Epoch 7/200\n",
      "384/384 - 5s - loss: 0.6894 - AUC: 0.5445\n",
      "Epoch 8/200\n",
      "384/384 - 3s - loss: 0.6892 - AUC: 0.5457\n",
      "Epoch 9/200\n",
      "384/384 - 4s - loss: 0.6890 - AUC: 0.5467\n",
      "Epoch 10/200\n",
      "384/384 - 4s - loss: 0.6889 - AUC: 0.5476\n",
      "Epoch 11/200\n",
      "384/384 - 3s - loss: 0.6887 - AUC: 0.5484\n",
      "Epoch 12/200\n",
      "384/384 - 3s - loss: 0.6886 - AUC: 0.5492\n",
      "Epoch 13/200\n",
      "384/384 - 3s - loss: 0.6884 - AUC: 0.5501\n",
      "Epoch 14/200\n",
      "384/384 - 3s - loss: 0.6883 - AUC: 0.5505\n",
      "Epoch 15/200\n",
      "384/384 - 3s - loss: 0.6881 - AUC: 0.5509\n",
      "Epoch 16/200\n",
      "384/384 - 4s - loss: 0.6880 - AUC: 0.5515\n",
      "Epoch 17/200\n",
      "384/384 - 5s - loss: 0.6879 - AUC: 0.5519\n",
      "Epoch 18/200\n",
      "384/384 - 4s - loss: 0.6878 - AUC: 0.5525\n",
      "Epoch 19/200\n",
      "384/384 - 3s - loss: 0.6876 - AUC: 0.5534\n",
      "Epoch 20/200\n",
      "384/384 - 3s - loss: 0.6876 - AUC: 0.5536\n",
      "Epoch 21/200\n",
      "384/384 - 3s - loss: 0.6875 - AUC: 0.5538\n",
      "Epoch 22/200\n",
      "384/384 - 3s - loss: 0.6873 - AUC: 0.5545\n",
      "Epoch 23/200\n",
      "384/384 - 3s - loss: 0.6872 - AUC: 0.5547\n",
      "Epoch 24/200\n",
      "384/384 - 3s - loss: 0.6871 - AUC: 0.5553\n",
      "Epoch 25/200\n",
      "384/384 - 4s - loss: 0.6871 - AUC: 0.5554\n",
      "Epoch 26/200\n",
      "384/384 - 3s - loss: 0.6870 - AUC: 0.5557\n",
      "Epoch 27/200\n",
      "384/384 - 3s - loss: 0.6869 - AUC: 0.5563\n",
      "Epoch 28/200\n",
      "384/384 - 5s - loss: 0.6867 - AUC: 0.5568\n",
      "Epoch 29/200\n",
      "384/384 - 4s - loss: 0.6866 - AUC: 0.5567\n",
      "Epoch 30/200\n",
      "384/384 - 3s - loss: 0.6867 - AUC: 0.5568\n",
      "Epoch 31/200\n",
      "384/384 - 3s - loss: 0.6866 - AUC: 0.5571\n",
      "Epoch 32/200\n",
      "384/384 - 3s - loss: 0.6864 - AUC: 0.5576\n",
      "Epoch 33/200\n",
      "384/384 - 3s - loss: 0.6863 - AUC: 0.5577\n",
      "Epoch 34/200\n",
      "384/384 - 3s - loss: 0.6863 - AUC: 0.5584\n",
      "Epoch 35/200\n",
      "384/384 - 4s - loss: 0.6862 - AUC: 0.5583\n",
      "Epoch 36/200\n",
      "384/384 - 3s - loss: 0.6862 - AUC: 0.5583\n",
      "Epoch 37/200\n",
      "384/384 - 3s - loss: 0.6860 - AUC: 0.5590\n",
      "Epoch 38/200\n",
      "384/384 - 3s - loss: 0.6861 - AUC: 0.5586\n",
      "Epoch 39/200\n",
      "384/384 - 5s - loss: 0.6860 - AUC: 0.5590\n",
      "Epoch 40/200\n",
      "384/384 - 4s - loss: 0.6859 - AUC: 0.5591\n",
      "Epoch 41/200\n",
      "384/384 - 3s - loss: 0.6859 - AUC: 0.5593\n",
      "Epoch 42/200\n",
      "384/384 - 3s - loss: 0.6858 - AUC: 0.5593\n",
      "Epoch 43/200\n",
      "384/384 - 3s - loss: 0.6857 - AUC: 0.5599\n",
      "Epoch 44/200\n",
      "384/384 - 4s - loss: 0.6857 - AUC: 0.5596\n",
      "Epoch 45/200\n",
      "384/384 - 3s - loss: 0.6856 - AUC: 0.5599\n",
      "Epoch 46/200\n",
      "384/384 - 3s - loss: 0.6856 - AUC: 0.5599\n",
      "Epoch 47/200\n",
      "384/384 - 4s - loss: 0.6855 - AUC: 0.5600\n",
      "Epoch 48/200\n",
      "384/384 - 3s - loss: 0.6855 - AUC: 0.5604\n",
      "Epoch 49/200\n",
      "384/384 - 3s - loss: 0.6854 - AUC: 0.5608\n",
      "Epoch 50/200\n",
      "384/384 - 5s - loss: 0.6854 - AUC: 0.5606\n",
      "Epoch 51/200\n",
      "384/384 - 4s - loss: 0.6854 - AUC: 0.5608\n",
      "Epoch 52/200\n",
      "384/384 - 3s - loss: 0.6853 - AUC: 0.5610\n",
      "Epoch 53/200\n",
      "384/384 - 4s - loss: 0.6853 - AUC: 0.5610\n",
      "Epoch 54/200\n",
      "384/384 - 3s - loss: 0.6852 - AUC: 0.5613\n",
      "Epoch 55/200\n",
      "384/384 - 3s - loss: 0.6852 - AUC: 0.5615\n",
      "Epoch 56/200\n",
      "384/384 - 3s - loss: 0.6851 - AUC: 0.5617\n",
      "Epoch 57/200\n",
      "384/384 - 3s - loss: 0.6851 - AUC: 0.5616\n",
      "Epoch 58/200\n",
      "384/384 - 3s - loss: 0.6851 - AUC: 0.5615\n",
      "Epoch 59/200\n",
      "384/384 - 3s - loss: 0.6851 - AUC: 0.5613\n",
      "Epoch 60/200\n",
      "384/384 - 4s - loss: 0.6850 - AUC: 0.5620\n",
      "Epoch 61/200\n",
      "384/384 - 5s - loss: 0.6849 - AUC: 0.5622\n",
      "Epoch 62/200\n",
      "384/384 - 4s - loss: 0.6848 - AUC: 0.5624\n",
      "Epoch 63/200\n",
      "384/384 - 3s - loss: 0.6849 - AUC: 0.5624\n",
      "Epoch 64/200\n",
      "384/384 - 3s - loss: 0.6848 - AUC: 0.5626\n",
      "Epoch 65/200\n",
      "384/384 - 3s - loss: 0.6848 - AUC: 0.5623\n",
      "Epoch 66/200\n",
      "384/384 - 3s - loss: 0.6848 - AUC: 0.5623\n",
      "Epoch 67/200\n",
      "384/384 - 3s - loss: 0.6847 - AUC: 0.5631\n",
      "Epoch 68/200\n",
      "384/384 - 3s - loss: 0.6847 - AUC: 0.5630\n",
      "Epoch 69/200\n",
      "384/384 - 3s - loss: 0.6846 - AUC: 0.5628\n",
      "Epoch 70/200\n",
      "384/384 - 3s - loss: 0.6846 - AUC: 0.5630\n",
      "Epoch 71/200\n",
      "384/384 - 3s - loss: 0.6846 - AUC: 0.5631\n",
      "Epoch 72/200\n",
      "384/384 - 6s - loss: 0.6845 - AUC: 0.5634\n",
      "Epoch 73/200\n",
      "384/384 - 4s - loss: 0.6845 - AUC: 0.5632\n",
      "Epoch 74/200\n",
      "384/384 - 3s - loss: 0.6845 - AUC: 0.5633\n",
      "Epoch 75/200\n",
      "384/384 - 4s - loss: 0.6845 - AUC: 0.5637\n",
      "Epoch 76/200\n",
      "384/384 - 3s - loss: 0.6844 - AUC: 0.5637\n",
      "Epoch 77/200\n",
      "384/384 - 3s - loss: 0.6844 - AUC: 0.5635\n",
      "Epoch 78/200\n",
      "384/384 - 3s - loss: 0.6845 - AUC: 0.5633\n",
      "Epoch 79/200\n",
      "384/384 - 3s - loss: 0.6843 - AUC: 0.5640\n",
      "Epoch 80/200\n",
      "384/384 - 3s - loss: 0.6844 - AUC: 0.5637\n",
      "Epoch 81/200\n",
      "384/384 - 3s - loss: 0.6844 - AUC: 0.5640\n",
      "Epoch 82/200\n",
      "384/384 - 4s - loss: 0.6843 - AUC: 0.5640\n",
      "Epoch 83/200\n",
      "384/384 - 5s - loss: 0.6843 - AUC: 0.5640\n",
      "Epoch 84/200\n",
      "384/384 - 4s - loss: 0.6843 - AUC: 0.5639\n",
      "Epoch 85/200\n",
      "384/384 - 3s - loss: 0.6842 - AUC: 0.5643\n",
      "Epoch 86/200\n",
      "384/384 - 3s - loss: 0.6842 - AUC: 0.5642\n",
      "Epoch 87/200\n",
      "384/384 - 3s - loss: 0.6842 - AUC: 0.5644\n",
      "Epoch 88/200\n",
      "384/384 - 4s - loss: 0.6842 - AUC: 0.5644\n",
      "Epoch 89/200\n",
      "384/384 - 3s - loss: 0.6841 - AUC: 0.5646\n",
      "Epoch 90/200\n",
      "384/384 - 3s - loss: 0.6841 - AUC: 0.5645\n",
      "Epoch 91/200\n",
      "384/384 - 4s - loss: 0.6841 - AUC: 0.5643\n",
      "Epoch 92/200\n",
      "384/384 - 3s - loss: 0.6840 - AUC: 0.5648\n",
      "Epoch 93/200\n",
      "384/384 - 3s - loss: 0.6840 - AUC: 0.5648\n",
      "Epoch 94/200\n",
      "384/384 - 5s - loss: 0.6840 - AUC: 0.5648\n",
      "Epoch 95/200\n",
      "384/384 - 4s - loss: 0.6841 - AUC: 0.5644\n",
      "Epoch 96/200\n",
      "384/384 - 3s - loss: 0.6839 - AUC: 0.5650\n",
      "Epoch 97/200\n",
      "384/384 - 3s - loss: 0.6839 - AUC: 0.5649\n",
      "Epoch 98/200\n",
      "384/384 - 3s - loss: 0.6840 - AUC: 0.5649\n",
      "Epoch 99/200\n",
      "384/384 - 3s - loss: 0.6839 - AUC: 0.5653\n",
      "Epoch 100/200\n",
      "384/384 - 3s - loss: 0.6840 - AUC: 0.5648\n",
      "Epoch 101/200\n",
      "384/384 - 4s - loss: 0.6838 - AUC: 0.5654\n",
      "Epoch 102/200\n",
      "384/384 - 3s - loss: 0.6839 - AUC: 0.5652\n",
      "Epoch 103/200\n",
      "384/384 - 3s - loss: 0.6838 - AUC: 0.5653\n",
      "Epoch 104/200\n",
      "384/384 - 3s - loss: 0.6838 - AUC: 0.5654\n",
      "Epoch 105/200\n",
      "384/384 - 5s - loss: 0.6839 - AUC: 0.5650\n",
      "Epoch 106/200\n",
      "384/384 - 4s - loss: 0.6837 - AUC: 0.5655\n",
      "Epoch 107/200\n",
      "384/384 - 3s - loss: 0.6837 - AUC: 0.5655\n",
      "Epoch 108/200\n",
      "384/384 - 3s - loss: 0.6837 - AUC: 0.5658\n",
      "Epoch 109/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5656\n",
      "Epoch 110/200\n",
      "384/384 - 4s - loss: 0.6837 - AUC: 0.5655\n",
      "Epoch 111/200\n",
      "384/384 - 3s - loss: 0.6837 - AUC: 0.5658\n",
      "Epoch 112/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5660\n",
      "Epoch 113/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5659\n",
      "Epoch 114/200\n",
      "384/384 - 3s - loss: 0.6837 - AUC: 0.5658\n",
      "Epoch 115/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5661\n",
      "Epoch 116/200\n",
      "384/384 - 5s - loss: 0.6836 - AUC: 0.5658\n",
      "Epoch 117/200\n",
      "384/384 - 4s - loss: 0.6837 - AUC: 0.5658\n",
      "Epoch 118/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5659\n",
      "Epoch 119/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5657\n",
      "Epoch 120/200\n",
      "384/384 - 4s - loss: 0.6836 - AUC: 0.5660\n",
      "Epoch 121/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5662\n",
      "Epoch 122/200\n",
      "384/384 - 3s - loss: 0.6835 - AUC: 0.5660\n",
      "Epoch 123/200\n",
      "384/384 - 3s - loss: 0.6835 - AUC: 0.5665\n",
      "Epoch 124/200\n",
      "384/384 - 3s - loss: 0.6835 - AUC: 0.5664\n",
      "Epoch 125/200\n",
      "384/384 - 3s - loss: 0.6835 - AUC: 0.5663\n",
      "Epoch 126/200\n",
      "384/384 - 3s - loss: 0.6835 - AUC: 0.5662\n",
      "Epoch 127/200\n",
      "384/384 - 5s - loss: 0.6834 - AUC: 0.5665\n",
      "Epoch 128/200\n",
      "384/384 - 4s - loss: 0.6835 - AUC: 0.5660\n",
      "Epoch 129/200\n",
      "384/384 - 4s - loss: 0.6834 - AUC: 0.5666\n",
      "Epoch 130/200\n",
      "384/384 - 3s - loss: 0.6834 - AUC: 0.5667\n",
      "Epoch 131/200\n",
      "384/384 - 3s - loss: 0.6834 - AUC: 0.5663\n",
      "Epoch 132/200\n",
      "384/384 - 3s - loss: 0.6834 - AUC: 0.5664\n",
      "Epoch 133/200\n",
      "384/384 - 3s - loss: 0.6833 - AUC: 0.5665\n",
      "Epoch 134/200\n",
      "384/384 - 3s - loss: 0.6834 - AUC: 0.5664\n",
      "Epoch 135/200\n",
      "384/384 - 3s - loss: 0.6833 - AUC: 0.5669\n",
      "Epoch 136/200\n",
      "384/384 - 3s - loss: 0.6833 - AUC: 0.5672\n",
      "Epoch 137/200\n",
      "384/384 - 3s - loss: 0.6833 - AUC: 0.5666\n",
      "Epoch 138/200\n",
      "384/384 - 6s - loss: 0.6833 - AUC: 0.5670\n",
      "Epoch 139/200\n",
      "384/384 - 4s - loss: 0.6833 - AUC: 0.5664\n",
      "Epoch 140/200\n",
      "384/384 - 3s - loss: 0.6832 - AUC: 0.5670\n",
      "Epoch 141/200\n",
      "384/384 - 3s - loss: 0.6833 - AUC: 0.5669\n",
      "Epoch 142/200\n",
      "384/384 - 3s - loss: 0.6832 - AUC: 0.5669\n",
      "Epoch 143/200\n",
      "384/384 - 3s - loss: 0.6832 - AUC: 0.5674\n",
      "Epoch 144/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5674\n",
      "Epoch 145/200\n",
      "384/384 - 3s - loss: 0.6832 - AUC: 0.5672\n",
      "Epoch 146/200\n",
      "384/384 - 3s - loss: 0.6832 - AUC: 0.5671\n",
      "Epoch 147/200\n",
      "384/384 - 3s - loss: 0.6830 - AUC: 0.5676\n",
      "Epoch 148/200\n",
      "384/384 - 4s - loss: 0.6831 - AUC: 0.5669\n",
      "Epoch 149/200\n",
      "384/384 - 5s - loss: 0.6832 - AUC: 0.5670\n",
      "Epoch 150/200\n",
      "384/384 - 4s - loss: 0.6831 - AUC: 0.5675\n",
      "Epoch 151/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5674\n",
      "Epoch 152/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5675\n",
      "Epoch 153/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5675\n",
      "Epoch 154/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5676\n",
      "Epoch 155/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5675\n",
      "Epoch 156/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5674\n",
      "Epoch 157/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5673\n",
      "Epoch 158/200\n",
      "384/384 - 4s - loss: 0.6830 - AUC: 0.5677\n",
      "Epoch 159/200\n",
      "384/384 - 3s - loss: 0.6830 - AUC: 0.5675\n",
      "Epoch 160/200\n",
      "384/384 - 5s - loss: 0.6830 - AUC: 0.5673\n",
      "Epoch 161/200\n",
      "384/384 - 4s - loss: 0.6830 - AUC: 0.5676\n",
      "Epoch 162/200\n",
      "384/384 - 3s - loss: 0.6830 - AUC: 0.5675\n",
      "Epoch 163/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5680\n",
      "Epoch 164/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5680\n",
      "Epoch 165/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5675\n",
      "Epoch 166/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5675\n",
      "Epoch 167/200\n",
      "384/384 - 4s - loss: 0.6829 - AUC: 0.5678\n",
      "Epoch 168/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5678\n",
      "Epoch 169/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5680\n",
      "Epoch 170/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5680\n",
      "Epoch 171/200\n",
      "384/384 - 5s - loss: 0.6828 - AUC: 0.5684\n",
      "Epoch 172/200\n",
      "384/384 - 4s - loss: 0.6828 - AUC: 0.5683\n",
      "Epoch 173/200\n",
      "384/384 - 4s - loss: 0.6829 - AUC: 0.5679\n",
      "Epoch 174/200\n",
      "384/384 - 3s - loss: 0.6828 - AUC: 0.5684\n",
      "Epoch 175/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5679\n",
      "Epoch 176/200\n",
      "384/384 - 4s - loss: 0.6828 - AUC: 0.5679\n",
      "Epoch 177/200\n",
      "384/384 - 3s - loss: 0.6828 - AUC: 0.5682\n",
      "Epoch 178/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5685\n",
      "Epoch 179/200\n",
      "384/384 - 3s - loss: 0.6828 - AUC: 0.5685\n",
      "Epoch 180/200\n",
      "384/384 - 3s - loss: 0.6828 - AUC: 0.5681\n",
      "Epoch 181/200\n",
      "384/384 - 3s - loss: 0.6828 - AUC: 0.5683\n",
      "Epoch 182/200\n",
      "384/384 - 5s - loss: 0.6828 - AUC: 0.5681\n",
      "Epoch 183/200\n",
      "384/384 - 4s - loss: 0.6827 - AUC: 0.5685\n",
      "Epoch 184/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5685\n",
      "Epoch 185/200\n",
      "384/384 - 4s - loss: 0.6827 - AUC: 0.5685\n",
      "Epoch 186/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5678\n",
      "Epoch 187/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5687\n",
      "Epoch 188/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5687\n",
      "Epoch 189/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5683\n",
      "Epoch 190/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5682\n",
      "Epoch 191/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5688\n",
      "Epoch 192/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5688\n",
      "Epoch 193/200\n",
      "384/384 - 5s - loss: 0.6827 - AUC: 0.5687\n",
      "Epoch 194/200\n",
      "384/384 - 4s - loss: 0.6825 - AUC: 0.5690\n",
      "Epoch 195/200\n",
      "384/384 - 4s - loss: 0.6826 - AUC: 0.5686\n",
      "Epoch 196/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5687\n",
      "Epoch 197/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5685\n",
      "Epoch 198/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5688\n",
      "Epoch 199/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5688\n",
      "Epoch 200/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5689\n"
     ]
    }
   ],
   "source": [
    "def create_mlp(\n",
    "    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n",
    "    for i in range(len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(num_labels)(x)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tfa.optimizers.RectifiedAdam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "    )\n",
    "\n",
    "    return model\n",
    "\n",
    "epochs = 200\n",
    "batch_size = 4096\n",
    "hidden_units = [160, 160, 160]\n",
    "dropout_rates = [0.2, 0.2, 0.2, 0.2]\n",
    "label_smoothing = 1e-2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(SEED)\n",
    "clf = create_mlp(\n",
    "    len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "    )\n",
    "\n",
    "clf.fit(X_train, y_train, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "# save model\n",
    "clf.save(f'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:42:38.676338Z",
     "iopub.status.busy": "2021-02-16T11:42:38.675642Z",
     "iopub.status.idle": "2021-02-16T11:42:38.680034Z",
     "shell.execute_reply": "2021-02-16T11:42:38.679405Z"
    },
    "papermill": {
     "duration": 4.249316,
     "end_time": "2021-02-16T11:42:38.680136",
     "exception": false,
     "start_time": "2021-02-16T11:42:34.430820",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del X_train, y_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:42:47.547809Z",
     "iopub.status.busy": "2021-02-16T11:42:47.546817Z",
     "iopub.status.idle": "2021-02-16T11:42:47.553601Z",
     "shell.execute_reply": "2021-02-16T11:42:47.553072Z"
    },
    "papermill": {
     "duration": 4.387726,
     "end_time": "2021-02-16T11:42:47.553703",
     "exception": false,
     "start_time": "2021-02-16T11:42:43.165977",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/kaggle/working/encoder.hdf5\n",
      "/kaggle/working/mymodel.so\n",
      "/kaggle/working/model_2021_2.hdf5\n",
      "/kaggle/working/model.h5\n",
      "/kaggle/working/model_2021_0.hdf5\n",
      "/kaggle/working/__notebook__.ipynb\n",
      "/kaggle/working/model_2021_1.hdf5\n",
      "/kaggle/working/model_2021_4.hdf5\n",
      "/kaggle/working/model_2021_3.hdf5\n"
     ]
    }
   ],
   "source": [
    "for dirname, _, filenames in os.walk('/kaggle/working'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:42:55.821928Z",
     "iopub.status.busy": "2021-02-16T11:42:55.821174Z",
     "iopub.status.idle": "2021-02-16T11:42:55.826994Z",
     "shell.execute_reply": "2021-02-16T11:42:55.827466Z"
    },
    "papermill": {
     "duration": 4.156733,
     "end_time": "2021-02-16T11:42:55.827617",
     "exception": false,
     "start_time": "2021-02-16T11:42:51.670884",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 s, sys: 0 ns, total: 4 s\n",
      "Wall time: 9.3 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if NN_NAME == '1dcnn':\n",
    "    models = []\n",
    "\n",
    "    for fold in range(FOLDS):\n",
    "        # 1dcnn\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = create_1dcnn(X.shape[-1], y.shape[-1], encoder)\n",
    "        model.load_weights(pathlib.Path(f'/kaggle/working/model_{SEED}_{fold}.hdf5'))\n",
    "        models.append(model)\n",
    "        \n",
    "    models = [models[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:43:04.599828Z",
     "iopub.status.busy": "2021-02-16T11:43:04.599104Z",
     "iopub.status.idle": "2021-02-16T11:43:04.602220Z",
     "shell.execute_reply": "2021-02-16T11:43:04.602767Z"
    },
    "papermill": {
     "duration": 4.198057,
     "end_time": "2021-02-16T11:43:04.602925",
     "exception": false,
     "start_time": "2021-02-16T11:43:00.404868",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 s, sys: 0 ns, total: 4 s\n",
      "Wall time: 7.87 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if NN_NAME == 'resnet':\n",
    "    models = []\n",
    "\n",
    "    for fold in range(FOLDS):\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = create_resnet(X.shape[-1], y.shape[-1], encoder)\n",
    "        model.load_weights(pathlib.Path(f'/kaggle/working/model_{SEED}_{fold}.hdf5'))\n",
    "        models.append(model)\n",
    "        \n",
    "    models = [models[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:43:13.159428Z",
     "iopub.status.busy": "2021-02-16T11:43:13.158498Z",
     "iopub.status.idle": "2021-02-16T11:43:13.422954Z",
     "shell.execute_reply": "2021-02-16T11:43:13.423446Z"
    },
    "papermill": {
     "duration": 4.47698,
     "end_time": "2021-02-16T11:43:13.423578",
     "exception": false,
     "start_time": "2021-02-16T11:43:08.946598",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 262 ms, sys: 6.01 ms, total: 268 ms\n",
      "Wall time: 268 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if NN_NAME == 'mlp':\n",
    "    model = tf.keras.models.load_model('./model.h5')\n",
    "    models = [model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-16T11:43:22.214122Z",
     "iopub.status.busy": "2021-02-16T11:43:22.213386Z",
     "iopub.status.idle": "2021-02-16T11:47:43.934794Z",
     "shell.execute_reply": "2021-02-16T11:47:43.935298Z"
    },
    "papermill": {
     "duration": 266.033292,
     "end_time": "2021-02-16T11:47:43.935822",
     "exception": false,
     "start_time": "2021-02-16T11:43:17.902530",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15219it [04:21, 58.16it/s]\n"
     ]
    }
   ],
   "source": [
    "f = np.median\n",
    "th = 0.500\n",
    "\n",
    "import janestreet\n",
    "env = janestreet.make_env()\n",
    "for (test_df, pred_df) in tqdm(env.iter_test()):\n",
    "    if test_df['weight'].item() > 0:\n",
    "        x_tt = test_df.loc[:, features].values\n",
    "        \n",
    "        # GBDT inference with treelite\n",
    "        batch = treelite_runtime.Batch.from_npy2d(x_tt)\n",
    "        xgb_pred = predictor.predict(batch)\n",
    "    \n",
    "        # NN inference\n",
    "        if np.isnan(x_tt[:, 1:].sum()):\n",
    "            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n",
    "        \n",
    "        pred = np.mean([model(x_tt, training = False).numpy() for model in models],axis=0)\n",
    "        pred = f(pred)\n",
    "        \n",
    "        # ensemble\n",
    "        pred_df.action = np.where(0.9*pred + 0.1*xgb_pred >= th, 1, 0).astype(int)\n",
    "    else:\n",
    "        pred_df.action = 0\n",
    "    env.predict(pred_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  },
  "papermill": {
   "duration": 2515.151188,
   "end_time": "2021-02-16T11:47:51.146198",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-16T11:05:55.995010",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
