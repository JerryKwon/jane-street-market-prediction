{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-18T13:03:17.252654Z",
     "iopub.status.busy": "2021-02-18T13:03:17.251911Z",
     "iopub.status.idle": "2021-02-18T13:03:24.272182Z",
     "shell.execute_reply": "2021-02-18T13:03:24.271472Z"
    },
    "papermill": {
     "duration": 7.046542,
     "end_time": "2021-02-18T13:03:24.272326",
     "exception": false,
     "start_time": "2021-02-18T13:03:17.225784",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from random import choices\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:03:24.311310Z",
     "iopub.status.busy": "2021-02-18T13:03:24.310364Z",
     "iopub.status.idle": "2021-02-18T13:03:24.314803Z",
     "shell.execute_reply": "2021-02-18T13:03:24.315524Z"
    },
    "papermill": {
     "duration": 0.028458,
     "end_time": "2021-02-18T13:03:24.315734",
     "exception": false,
     "start_time": "2021-02-18T13:03:24.287276",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.3.1\n",
      "Accelerated Linear Algebra enabled\n"
     ]
    }
   ],
   "source": [
    "# tf setup\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "MIXED_PRECISION = False\n",
    "XLA_ACCELERATE = True\n",
    "\n",
    "if MIXED_PRECISION:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "    if tpu: policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
    "    else: policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "    mixed_precision.set_policy(policy)\n",
    "    print('Mixed precision enabled')\n",
    "\n",
    "if XLA_ACCELERATE:\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    print('Accelerated Linear Algebra enabled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014729,
     "end_time": "2021-02-18T13:03:24.346757",
     "exception": false,
     "start_time": "2021-02-18T13:03:24.332028",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:03:24.381401Z",
     "iopub.status.busy": "2021-02-18T13:03:24.380613Z",
     "iopub.status.idle": "2021-02-18T13:03:24.384487Z",
     "shell.execute_reply": "2021-02-18T13:03:24.383922Z"
    },
    "papermill": {
     "duration": 0.023472,
     "end_time": "2021-02-18T13:03:24.384589",
     "exception": false,
     "start_time": "2021-02-18T13:03:24.361117",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CV_STRATEGY = 'StratifiedGroupKFold' # 'StratifiedGroupKFold' # GroupKFold, PurgedGroupTimeSeriesSplit\n",
    "SEED = 2021\n",
    "START_DATE = 86\n",
    "FOLDS = 5\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014199,
     "end_time": "2021-02-18T13:03:24.413200",
     "exception": false,
     "start_time": "2021-02-18T13:03:24.399001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV Strategy\n",
    "\n",
    "## PurgedGroupTimeSeriesSplit\n",
    "Click the code button to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-18T13:03:24.471442Z",
     "iopub.status.busy": "2021-02-18T13:03:24.469713Z",
     "iopub.status.idle": "2021-02-18T13:03:24.472326Z",
     "shell.execute_reply": "2021-02-18T13:03:24.472828Z"
    },
    "papermill": {
     "duration": 0.045113,
     "end_time": "2021-02-18T13:03:24.472967",
     "exception": false,
     "start_time": "2021-02-18T13:03:24.427854",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.014643,
     "end_time": "2021-02-18T13:03:24.502132",
     "exception": false,
     "start_time": "2021-02-18T13:03:24.487489",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## GroupKFold, StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:03:24.563552Z",
     "iopub.status.busy": "2021-02-18T13:03:24.556521Z",
     "iopub.status.idle": "2021-02-18T13:03:24.566302Z",
     "shell.execute_reply": "2021-02-18T13:03:24.565680Z"
    },
    "papermill": {
     "duration": 0.049381,
     "end_time": "2021-02-18T13:03:24.566412",
     "exception": false,
     "start_time": "2021-02-18T13:03:24.517031",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- GroupKFold ----\n",
    "class GroupKFold(object):\n",
    "    \"\"\"\n",
    "    GroupKFold with random shuffle with a sklearn-like structure\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=4, shuffle=True, random_state=42):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, group=None):\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y, group):\n",
    "        kf = model_selection.KFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state)\n",
    "        unique_ids = X[group].unique()\n",
    "        for fold, (tr_group_idx, va_group_idx) in enumerate(kf.split(unique_ids)):\n",
    "            # split group\n",
    "            tr_group, va_group = unique_ids[tr_group_idx], unique_ids[va_group_idx]\n",
    "            train_idx = np.where(X[group].isin(tr_group))[0]\n",
    "            val_idx = np.where(X[group].isin(va_group))[0]\n",
    "            yield train_idx, val_idx\n",
    "\n",
    "# ---- StratifiedGroupKFold ----\n",
    "class StratifiedGroupKFold(object):\n",
    "    \"\"\"\n",
    "    StratifiedGroupKFold with random shuffle with a sklearn-like structure\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=4, shuffle=True, random_state=42):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, group=None):\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y, group):\n",
    "        labels_num = np.max(y) + 1\n",
    "        y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "        y_distr = Counter()\n",
    "        groups = X[group].values\n",
    "        for label, g in zip(y, groups):\n",
    "            y_counts_per_group[g][label] += 1\n",
    "            y_distr[label] += 1\n",
    "\n",
    "        y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "        groups_per_fold = defaultdict(set)\n",
    "\n",
    "        def eval_y_counts_per_fold(y_counts, fold):\n",
    "            y_counts_per_fold[fold] += y_counts\n",
    "            std_per_label = []\n",
    "            for label in range(labels_num):\n",
    "                label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(self.n_splits)])\n",
    "                std_per_label.append(label_std)\n",
    "            y_counts_per_fold[fold] -= y_counts\n",
    "            return np.mean(std_per_label)\n",
    "        \n",
    "        groups_and_y_counts = list(y_counts_per_group.items())\n",
    "        random.Random(self.random_state).shuffle(groups_and_y_counts)\n",
    "\n",
    "        for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "            best_fold = None\n",
    "            min_eval = None\n",
    "            for i in range(self.n_splits):\n",
    "                fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "                if min_eval is None or fold_eval < min_eval:\n",
    "                    min_eval = fold_eval\n",
    "                    best_fold = i\n",
    "            y_counts_per_fold[best_fold] += y_counts\n",
    "            groups_per_fold[best_fold].add(g)\n",
    "\n",
    "        all_groups = set(groups)\n",
    "        for i in range(self.n_splits):\n",
    "            train_groups = all_groups - groups_per_fold[i]\n",
    "            test_groups = groups_per_fold[i]\n",
    "\n",
    "            train_idx = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "            test_idx = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "            yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.01519,
     "end_time": "2021-02-18T13:03:24.597143",
     "exception": false,
     "start_time": "2021-02-18T13:03:24.581953",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:03:24.639061Z",
     "iopub.status.busy": "2021-02-18T13:03:24.638008Z",
     "iopub.status.idle": "2021-02-18T13:03:36.668350Z",
     "shell.execute_reply": "2021-02-18T13:03:36.667226Z"
    },
    "papermill": {
     "duration": 12.05609,
     "end_time": "2021-02-18T13:03:36.668481",
     "exception": false,
     "start_time": "2021-02-18T13:03:24.612391",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_feather('../input/jane-street-save-as-feather/train.feather') # faster data load\n",
    "train = train.query(f'date >= {START_DATE}').reset_index(drop = True) \n",
    "train = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns}) #limit memory use\n",
    "train.fillna(train.mean(),inplace=True)\n",
    "train = train.query('weight > 0').reset_index(drop = True)\n",
    "#train = train.query('weight != 0').reset_index(drop = True)\n",
    "#train['action'] = (train['resp'] > 0).astype('int')\n",
    "train['action'] =  (  (train['resp_1'] > 0 ) & (train['resp_2'] > 0 ) & (train['resp_3'] > 0 ) & (train['resp_4'] > 0 ) &  (train['resp'] > 0 )   ).astype('int')\n",
    "features = [c for c in train.columns if 'feature' in c]\n",
    "resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:03:36.963929Z",
     "iopub.status.busy": "2021-02-18T13:03:36.962430Z",
     "iopub.status.idle": "2021-02-18T13:03:37.638282Z",
     "shell.execute_reply": "2021-02-18T13:03:37.636947Z"
    },
    "papermill": {
     "duration": 0.953307,
     "end_time": "2021-02-18T13:03:37.638418",
     "exception": false,
     "start_time": "2021-02-18T13:03:36.685111",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    train = train.sample(10000, random_state=SEED)\n",
    "\n",
    "X = train[features].values\n",
    "y = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T #Multitarget\n",
    "\n",
    "f_mean = np.mean(train[features[1:]].values,axis=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.016092,
     "end_time": "2021-02-18T13:03:37.671093",
     "exception": false,
     "start_time": "2021-02-18T13:03:37.655001",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Creating Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:03:37.719320Z",
     "iopub.status.busy": "2021-02-18T13:03:37.717338Z",
     "iopub.status.idle": "2021-02-18T13:03:37.720017Z",
     "shell.execute_reply": "2021-02-18T13:03:37.720513Z"
    },
    "papermill": {
     "duration": 0.032754,
     "end_time": "2021-02-18T13:03:37.720654",
     "exception": false,
     "start_time": "2021-02-18T13:03:37.687900",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_autoencoder(input_dim,output_dim,noise=0.05):\n",
    "    i = tf.keras.layers.Input(input_dim)\n",
    "    encoded = tf.keras.layers.BatchNormalization()(i)\n",
    "    encoded = tf.keras.layers.GaussianNoise(noise)(encoded)\n",
    "    encoded = tf.keras.layers.Dense(64,activation='relu')(encoded)\n",
    "    decoded = tf.keras.layers.Dropout(0.2)(encoded)\n",
    "    decoded = tf.keras.layers.Dense(input_dim,name='decoded')(decoded)\n",
    "    x = tf.keras.layers.Dense(32,activation='relu')(decoded)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(output_dim,activation='sigmoid',name='label_output')(x)\n",
    "    \n",
    "    encoder = tf.keras.models.Model(inputs=i,outputs=encoded)\n",
    "    autoencoder = tf.keras.models.Model(inputs=i,outputs=[decoded,x])\n",
    "    \n",
    "    autoencoder.compile(optimizer=tf.keras.optimizers.Adam(0.001), \n",
    "                        loss={'decoded':'mse','label_output':'binary_crossentropy'})\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:03:37.776641Z",
     "iopub.status.busy": "2021-02-18T13:03:37.774645Z",
     "iopub.status.idle": "2021-02-18T13:03:37.777395Z",
     "shell.execute_reply": "2021-02-18T13:03:37.777888Z"
    },
    "papermill": {
     "duration": 0.042261,
     "end_time": "2021-02-18T13:03:37.778016",
     "exception": false,
     "start_time": "2021-02-18T13:03:37.735755",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_resnet(n_features, n_labels, encoder, label_smoothing = 0.0005):    \n",
    "    input_1 = tf.keras.layers.Input(shape = (n_features,))\n",
    "    input_2 = encoder(input_1)\n",
    "\n",
    "    head_1 = tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(512, activation=\"elu\"), \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(256, activation = \"elu\")\n",
    "        ],name='Head1') \n",
    "\n",
    "    input_3 = head_1(input_1)\n",
    "    input_3_concat = tf.keras.layers.Concatenate()([input_2, input_3])\n",
    "\n",
    "    head_2 = tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(512, \"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(512, \"elu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(256, \"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(256, \"elu\")\n",
    "        ],name='Head2')\n",
    "\n",
    "    input_4 = head_2(input_3_concat)\n",
    "    input_4_avg = tf.keras.layers.Average()([input_3, input_4]) \n",
    "\n",
    "    head_3 = tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(256, kernel_initializer='lecun_normal', activation='selu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(128, kernel_initializer='lecun_normal', activation='selu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1), name='l2_norm'),\n",
    "        tf.keras.layers.Dense(n_labels, activation=\"sigmoid\")\n",
    "        ],name='Head3')\n",
    "\n",
    "    output = head_3(input_4_avg)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [input_1, ], outputs = output)\n",
    "    opt = tfa.optimizers.RectifiedAdam(learning_rate=1e-03)\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing), \n",
    "                  metrics=['AUC'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:03:37.818412Z",
     "iopub.status.busy": "2021-02-18T13:03:37.817544Z",
     "iopub.status.idle": "2021-02-18T13:06:19.622735Z",
     "shell.execute_reply": "2021-02-18T13:06:19.621919Z"
    },
    "papermill": {
     "duration": 161.828537,
     "end_time": "2021-02-18T13:06:19.622877",
     "exception": false,
     "start_time": "2021-02-18T13:03:37.794340",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "691/691 [==============================] - 6s 9ms/step - loss: 2.3766 - decoded_loss: 1.6684 - label_output_loss: 0.7082 - val_loss: 1.2757 - val_decoded_loss: 0.5855 - val_label_output_loss: 0.6902\n",
      "Epoch 2/1000\n",
      "691/691 [==============================] - 7s 10ms/step - loss: 1.8116 - decoded_loss: 1.1200 - label_output_loss: 0.6916 - val_loss: 1.1763 - val_decoded_loss: 0.4865 - val_label_output_loss: 0.6897\n",
      "Epoch 3/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7645 - decoded_loss: 1.0735 - label_output_loss: 0.6910 - val_loss: 1.1288 - val_decoded_loss: 0.4394 - val_label_output_loss: 0.6895\n",
      "Epoch 4/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7415 - decoded_loss: 1.0507 - label_output_loss: 0.6908 - val_loss: 1.1068 - val_decoded_loss: 0.4175 - val_label_output_loss: 0.6893\n",
      "Epoch 5/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7252 - decoded_loss: 1.0346 - label_output_loss: 0.6906 - val_loss: 1.0979 - val_decoded_loss: 0.4087 - val_label_output_loss: 0.6892\n",
      "Epoch 6/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7176 - decoded_loss: 1.0270 - label_output_loss: 0.6906 - val_loss: 1.0875 - val_decoded_loss: 0.3985 - val_label_output_loss: 0.6891\n",
      "Epoch 7/1000\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 1.7083 - decoded_loss: 1.0178 - label_output_loss: 0.6906 - val_loss: 1.0836 - val_decoded_loss: 0.3943 - val_label_output_loss: 0.6893\n",
      "Epoch 8/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6947 - decoded_loss: 1.0043 - label_output_loss: 0.6904 - val_loss: 1.0730 - val_decoded_loss: 0.3838 - val_label_output_loss: 0.6892\n",
      "Epoch 9/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6936 - decoded_loss: 1.0032 - label_output_loss: 0.6904 - val_loss: 1.0716 - val_decoded_loss: 0.3826 - val_label_output_loss: 0.6890\n",
      "Epoch 10/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6865 - decoded_loss: 0.9961 - label_output_loss: 0.6903 - val_loss: 1.0672 - val_decoded_loss: 0.3782 - val_label_output_loss: 0.6890\n",
      "Epoch 11/1000\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 1.6761 - decoded_loss: 0.9858 - label_output_loss: 0.6903 - val_loss: 1.0562 - val_decoded_loss: 0.3671 - val_label_output_loss: 0.6890\n",
      "Epoch 12/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6771 - decoded_loss: 0.9869 - label_output_loss: 0.6902 - val_loss: 1.0574 - val_decoded_loss: 0.3685 - val_label_output_loss: 0.6890\n",
      "Epoch 13/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6727 - decoded_loss: 0.9824 - label_output_loss: 0.6903 - val_loss: 1.0534 - val_decoded_loss: 0.3646 - val_label_output_loss: 0.6888\n",
      "Epoch 14/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6796 - decoded_loss: 0.9894 - label_output_loss: 0.6902 - val_loss: 1.0550 - val_decoded_loss: 0.3661 - val_label_output_loss: 0.6889\n",
      "Epoch 15/1000\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 1.6684 - decoded_loss: 0.9782 - label_output_loss: 0.6902 - val_loss: 1.0453 - val_decoded_loss: 0.3565 - val_label_output_loss: 0.6888\n",
      "Epoch 16/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6662 - decoded_loss: 0.9760 - label_output_loss: 0.6902 - val_loss: 1.0536 - val_decoded_loss: 0.3647 - val_label_output_loss: 0.6889\n",
      "Epoch 17/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6651 - decoded_loss: 0.9748 - label_output_loss: 0.6902 - val_loss: 1.0554 - val_decoded_loss: 0.3667 - val_label_output_loss: 0.6888\n",
      "Epoch 18/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6626 - decoded_loss: 0.9725 - label_output_loss: 0.6901 - val_loss: 1.0617 - val_decoded_loss: 0.3728 - val_label_output_loss: 0.6888\n",
      "Epoch 19/1000\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 1.6596 - decoded_loss: 0.9694 - label_output_loss: 0.6902 - val_loss: 1.0531 - val_decoded_loss: 0.3642 - val_label_output_loss: 0.6889\n",
      "Epoch 20/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6510 - decoded_loss: 0.9609 - label_output_loss: 0.6901 - val_loss: 1.0561 - val_decoded_loss: 0.3673 - val_label_output_loss: 0.6889\n",
      "Epoch 21/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6474 - decoded_loss: 0.9574 - label_output_loss: 0.6900 - val_loss: 1.0604 - val_decoded_loss: 0.3716 - val_label_output_loss: 0.6888\n",
      "Epoch 22/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6533 - decoded_loss: 0.9633 - label_output_loss: 0.6901 - val_loss: 1.0640 - val_decoded_loss: 0.3753 - val_label_output_loss: 0.6887\n",
      "Epoch 23/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6464 - decoded_loss: 0.9564 - label_output_loss: 0.6901 - val_loss: 1.0581 - val_decoded_loss: 0.3693 - val_label_output_loss: 0.6888\n",
      "Epoch 24/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6502 - decoded_loss: 0.9601 - label_output_loss: 0.6900 - val_loss: 1.0435 - val_decoded_loss: 0.3548 - val_label_output_loss: 0.6887\n",
      "Epoch 25/1000\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 1.6461 - decoded_loss: 0.9560 - label_output_loss: 0.6900 - val_loss: 1.0517 - val_decoded_loss: 0.3629 - val_label_output_loss: 0.6888\n",
      "Epoch 26/1000\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 1.6418 - decoded_loss: 0.9517 - label_output_loss: 0.6900 - val_loss: 1.0491 - val_decoded_loss: 0.3605 - val_label_output_loss: 0.6887\n",
      "Epoch 27/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6446 - decoded_loss: 0.9546 - label_output_loss: 0.6900 - val_loss: 1.0523 - val_decoded_loss: 0.3638 - val_label_output_loss: 0.6886\n",
      "Epoch 28/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6379 - decoded_loss: 0.9479 - label_output_loss: 0.6899 - val_loss: 1.0674 - val_decoded_loss: 0.3787 - val_label_output_loss: 0.6887\n",
      "Epoch 29/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6343 - decoded_loss: 0.9443 - label_output_loss: 0.6900 - val_loss: 1.0741 - val_decoded_loss: 0.3855 - val_label_output_loss: 0.6885\n",
      "Epoch 30/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6339 - decoded_loss: 0.9439 - label_output_loss: 0.6900 - val_loss: 1.0853 - val_decoded_loss: 0.3967 - val_label_output_loss: 0.6885\n",
      "Epoch 31/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6334 - decoded_loss: 0.9434 - label_output_loss: 0.6900 - val_loss: 1.0821 - val_decoded_loss: 0.3935 - val_label_output_loss: 0.6886\n",
      "Epoch 32/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6313 - decoded_loss: 0.9414 - label_output_loss: 0.6899 - val_loss: 1.0783 - val_decoded_loss: 0.3896 - val_label_output_loss: 0.6887\n",
      "Epoch 33/1000\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 1.6288 - decoded_loss: 0.9389 - label_output_loss: 0.6899 - val_loss: 1.0773 - val_decoded_loss: 0.3886 - val_label_output_loss: 0.6887\n",
      "Epoch 34/1000\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 1.6310 - decoded_loss: 0.9411 - label_output_loss: 0.6899 - val_loss: 1.0891 - val_decoded_loss: 0.4006 - val_label_output_loss: 0.6885\n"
     ]
    }
   ],
   "source": [
    "autoencoder, encoder = create_autoencoder(X.shape[-1],y.shape[-1],noise=0.1)\n",
    "autoencoder.fit(X,(X,y),\n",
    "                epochs=1000,\n",
    "                batch_size=2048, \n",
    "                validation_split=0.1,\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping('val_loss',patience=10,restore_best_weights=True)])\n",
    "encoder.save_weights('./encoder.hdf5')\n",
    "encoder.trainable = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:06:21.691321Z",
     "iopub.status.busy": "2021-02-18T13:06:21.690218Z",
     "iopub.status.idle": "2021-02-18T13:06:22.389598Z",
     "shell.execute_reply": "2021-02-18T13:06:22.389014Z"
    },
    "papermill": {
     "duration": 1.727877,
     "end_time": "2021-02-18T13:06:22.389760",
     "exception": false,
     "start_time": "2021-02-18T13:06:20.661883",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"functional_5\"\n",
      "__________________________________________________________________________________________________\n",
      "Layer (type)                    Output Shape         Param #     Connected to                     \n",
      "==================================================================================================\n",
      "input_2 (InputLayer)            [(None, 130)]        0                                            \n",
      "__________________________________________________________________________________________________\n",
      "Head1 (Sequential)              (None, 256)          200968      input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "functional_1 (Functional)       (None, 64)           8904        input_2[0][0]                    \n",
      "__________________________________________________________________________________________________\n",
      "concatenate (Concatenate)       (None, 320)          0           functional_1[0][0]               \n",
      "                                                                 Head1[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Head2 (Sequential)              (None, 256)          630528      concatenate[0][0]                \n",
      "__________________________________________________________________________________________________\n",
      "average (Average)               (None, 256)          0           Head1[0][0]                      \n",
      "                                                                 Head2[0][0]                      \n",
      "__________________________________________________________________________________________________\n",
      "Head3 (Sequential)              (None, 5)            101893      average[0][0]                    \n",
      "==================================================================================================\n",
      "Total params: 942,293\n",
      "Trainable params: 927,625\n",
      "Non-trainable params: 14,668\n",
      "__________________________________________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model = create_resnet(130, 5, encoder)\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:06:24.433387Z",
     "iopub.status.busy": "2021-02-18T13:06:24.432265Z",
     "iopub.status.idle": "2021-02-18T13:06:25.026748Z",
     "shell.execute_reply": "2021-02-18T13:06:25.026198Z"
    },
    "papermill": {
     "duration": 1.622885,
     "end_time": "2021-02-18T13:06:25.026873",
     "exception": false,
     "start_time": "2021-02-18T13:06:23.403988",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.utils.plot_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:06:27.126633Z",
     "iopub.status.busy": "2021-02-18T13:06:27.125354Z",
     "iopub.status.idle": "2021-02-18T13:25:10.804403Z",
     "shell.execute_reply": "2021-02-18T13:25:10.805229Z"
    },
    "papermill": {
     "duration": 1124.754273,
     "end_time": "2021-02-18T13:25:10.805433",
     "exception": false,
     "start_time": "2021-02-18T13:06:26.051160",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "615/615 [==============================] - 18s 30ms/step - loss: 0.6911 - auc: 0.5344 - val_loss: 0.6904 - val_auc: 0.5407\n",
      "Epoch 2/192\n",
      "615/615 [==============================] - 20s 33ms/step - loss: 0.6894 - auc: 0.5453 - val_loss: 0.6889 - val_auc: 0.5465\n",
      "Epoch 3/192\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.6887 - auc: 0.5491 - val_loss: 0.6889 - val_auc: 0.5472\n",
      "Epoch 4/192\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.6881 - auc: 0.5517 - val_loss: 0.6889 - val_auc: 0.5476\n",
      "Epoch 5/192\n",
      "615/615 [==============================] - 16s 26ms/step - loss: 0.6877 - auc: 0.5539 - val_loss: 0.6890 - val_auc: 0.5491\n",
      "Epoch 6/192\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.6871 - auc: 0.5565 - val_loss: 0.6888 - val_auc: 0.5496\n",
      "Epoch 7/192\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.6865 - auc: 0.5590 - val_loss: 0.6886 - val_auc: 0.5502\n",
      "Epoch 8/192\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.6859 - auc: 0.5613 - val_loss: 0.6899 - val_auc: 0.5488\n",
      "Epoch 9/192\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.6851 - auc: 0.5639 - val_loss: 0.6903 - val_auc: 0.5484\n",
      "Epoch 10/192\n",
      "615/615 [==============================] - 14s 24ms/step - loss: 0.6842 - auc: 0.5668 - val_loss: 0.6905 - val_auc: 0.5500\n",
      "Epoch 11/192\n",
      "615/615 [==============================] - 16s 25ms/step - loss: 0.6833 - auc: 0.5701 - val_loss: 0.6914 - val_auc: 0.5492\n",
      "Epoch 12/192\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.6824 - auc: 0.5726 - val_loss: 0.6917 - val_auc: 0.5469\n",
      "Epoch 13/192\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.6813 - auc: 0.5754 - val_loss: 0.6925 - val_auc: 0.5478\n",
      "Epoch 14/192\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.6802 - auc: 0.5781 - val_loss: 0.6936 - val_auc: 0.5474\n",
      "Epoch 15/192\n",
      "615/615 [==============================] - ETA: 0s - loss: 0.6791 - auc: 0.5806\n",
      "Epoch 00015: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.6791 - auc: 0.5806 - val_loss: 0.6939 - val_auc: 0.5462\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [04:24, 264.65s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "614/614 [==============================] - 18s 30ms/step - loss: 0.6910 - auc: 0.5346 - val_loss: 0.6901 - val_auc: 0.5424\n",
      "Epoch 2/192\n",
      "614/614 [==============================] - 20s 32ms/step - loss: 0.6893 - auc: 0.5459 - val_loss: 0.6899 - val_auc: 0.5420\n",
      "Epoch 3/192\n",
      "614/614 [==============================] - 17s 28ms/step - loss: 0.6886 - auc: 0.5495 - val_loss: 0.6893 - val_auc: 0.5457\n",
      "Epoch 4/192\n",
      "614/614 [==============================] - 14s 23ms/step - loss: 0.6881 - auc: 0.5522 - val_loss: 0.6896 - val_auc: 0.5446\n",
      "Epoch 5/192\n",
      "614/614 [==============================] - 16s 26ms/step - loss: 0.6875 - auc: 0.5549 - val_loss: 0.6901 - val_auc: 0.5441\n",
      "Epoch 6/192\n",
      "614/614 [==============================] - 15s 25ms/step - loss: 0.6870 - auc: 0.5572 - val_loss: 0.6900 - val_auc: 0.5457\n",
      "Epoch 7/192\n",
      "614/614 [==============================] - 14s 23ms/step - loss: 0.6865 - auc: 0.5593 - val_loss: 0.6898 - val_auc: 0.5474\n",
      "Epoch 8/192\n",
      "614/614 [==============================] - 17s 28ms/step - loss: 0.6860 - auc: 0.5614 - val_loss: 0.6898 - val_auc: 0.5478\n",
      "Epoch 9/192\n",
      "614/614 [==============================] - 14s 23ms/step - loss: 0.6853 - auc: 0.5638 - val_loss: 0.6905 - val_auc: 0.5463\n",
      "Epoch 10/192\n",
      "614/614 [==============================] - 18s 29ms/step - loss: 0.6845 - auc: 0.5665 - val_loss: 0.6916 - val_auc: 0.5473\n",
      "Epoch 11/192\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.6837 - auc: 0.5692\n",
      "Epoch 00011: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "614/614 [==============================] - 14s 23ms/step - loss: 0.6837 - auc: 0.5692 - val_loss: 0.6910 - val_auc: 0.5500\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [07:48, 246.39s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "614/614 [==============================] - 19s 31ms/step - loss: 0.6911 - auc: 0.5342 - val_loss: 0.6894 - val_auc: 0.5463\n",
      "Epoch 2/192\n",
      "614/614 [==============================] - 21s 34ms/step - loss: 0.6894 - auc: 0.5451 - val_loss: 0.6893 - val_auc: 0.5476\n",
      "Epoch 3/192\n",
      "614/614 [==============================] - 16s 26ms/step - loss: 0.6886 - auc: 0.5493 - val_loss: 0.6902 - val_auc: 0.5436\n",
      "Epoch 4/192\n",
      "614/614 [==============================] - 15s 24ms/step - loss: 0.6880 - auc: 0.5521 - val_loss: 0.6888 - val_auc: 0.5487\n",
      "Epoch 5/192\n",
      "614/614 [==============================] - 17s 28ms/step - loss: 0.6874 - auc: 0.5547 - val_loss: 0.6897 - val_auc: 0.5458\n",
      "Epoch 6/192\n",
      "614/614 [==============================] - 15s 24ms/step - loss: 0.6869 - auc: 0.5569 - val_loss: 0.6897 - val_auc: 0.5472\n",
      "Epoch 7/192\n",
      "614/614 [==============================] - 18s 29ms/step - loss: 0.6862 - auc: 0.5599 - val_loss: 0.6904 - val_auc: 0.5473\n",
      "Epoch 8/192\n",
      "614/614 [==============================] - 14s 23ms/step - loss: 0.6855 - auc: 0.5622 - val_loss: 0.6901 - val_auc: 0.5487\n",
      "Epoch 9/192\n",
      "614/614 [==============================] - 16s 27ms/step - loss: 0.6848 - auc: 0.5649 - val_loss: 0.6910 - val_auc: 0.5486\n",
      "Epoch 10/192\n",
      "614/614 [==============================] - 16s 26ms/step - loss: 0.6840 - auc: 0.5675 - val_loss: 0.6907 - val_auc: 0.5482\n",
      "Epoch 11/192\n",
      "614/614 [==============================] - 14s 24ms/step - loss: 0.6830 - auc: 0.5704 - val_loss: 0.6920 - val_auc: 0.5475\n",
      "Epoch 12/192\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6820 - auc: 0.5731\n",
      "Epoch 00012: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "614/614 [==============================] - 15s 24ms/step - loss: 0.6820 - auc: 0.5731 - val_loss: 0.6930 - val_auc: 0.5460\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [11:28, 238.43s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "615/615 [==============================] - 20s 32ms/step - loss: 0.6910 - auc: 0.5348 - val_loss: 0.6897 - val_auc: 0.5447\n",
      "Epoch 2/192\n",
      "615/615 [==============================] - 21s 34ms/step - loss: 0.6893 - auc: 0.5462 - val_loss: 0.6891 - val_auc: 0.5457\n",
      "Epoch 3/192\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.6885 - auc: 0.5501 - val_loss: 0.6890 - val_auc: 0.5469\n",
      "Epoch 4/192\n",
      "615/615 [==============================] - 15s 25ms/step - loss: 0.6879 - auc: 0.5534 - val_loss: 0.6894 - val_auc: 0.5467\n",
      "Epoch 5/192\n",
      "615/615 [==============================] - 17s 28ms/step - loss: 0.6874 - auc: 0.5555 - val_loss: 0.6896 - val_auc: 0.5426\n",
      "Epoch 6/192\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.6868 - auc: 0.5579 - val_loss: 0.6892 - val_auc: 0.5467\n",
      "Epoch 7/192\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.6862 - auc: 0.5603 - val_loss: 0.6899 - val_auc: 0.5464\n",
      "Epoch 8/192\n",
      "615/615 [==============================] - 15s 24ms/step - loss: 0.6855 - auc: 0.5630 - val_loss: 0.6899 - val_auc: 0.5472\n",
      "Epoch 9/192\n",
      "615/615 [==============================] - 18s 29ms/step - loss: 0.6847 - auc: 0.5657 - val_loss: 0.6905 - val_auc: 0.5461\n",
      "Epoch 10/192\n",
      "614/615 [============================>.] - ETA: 0s - loss: 0.6838 - auc: 0.5689\n",
      "Epoch 00010: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "615/615 [==============================] - 14s 24ms/step - loss: 0.6838 - auc: 0.5689 - val_loss: 0.6910 - val_auc: 0.5468\n",
      "Epoch 11/192\n",
      "615/615 [==============================] - 14s 23ms/step - loss: 0.6818 - auc: 0.5753 - val_loss: 0.6912 - val_auc: 0.5483\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [14:50, 227.49s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "614/614 [==============================] - 21s 34ms/step - loss: 0.6909 - auc: 0.5353 - val_loss: 0.6904 - val_auc: 0.5407\n",
      "Epoch 2/192\n",
      "614/614 [==============================] - 21s 34ms/step - loss: 0.6891 - auc: 0.5466 - val_loss: 0.6898 - val_auc: 0.5437\n",
      "Epoch 3/192\n",
      "614/614 [==============================] - 14s 23ms/step - loss: 0.6884 - auc: 0.5502 - val_loss: 0.6897 - val_auc: 0.5440\n",
      "Epoch 4/192\n",
      "614/614 [==============================] - 15s 25ms/step - loss: 0.6879 - auc: 0.5530 - val_loss: 0.6902 - val_auc: 0.5439\n",
      "Epoch 5/192\n",
      "614/614 [==============================] - 19s 31ms/step - loss: 0.6873 - auc: 0.5556 - val_loss: 0.6894 - val_auc: 0.5466\n",
      "Epoch 6/192\n",
      "614/614 [==============================] - 15s 24ms/step - loss: 0.6867 - auc: 0.5580 - val_loss: 0.6900 - val_auc: 0.5451\n",
      "Epoch 7/192\n",
      "614/614 [==============================] - 14s 23ms/step - loss: 0.6861 - auc: 0.5602 - val_loss: 0.6896 - val_auc: 0.5478\n",
      "Epoch 8/192\n",
      "614/614 [==============================] - 15s 24ms/step - loss: 0.6853 - auc: 0.5633 - val_loss: 0.6905 - val_auc: 0.5461\n",
      "Epoch 9/192\n",
      "614/614 [==============================] - 16s 26ms/step - loss: 0.6845 - auc: 0.5658 - val_loss: 0.6922 - val_auc: 0.5432\n",
      "Epoch 10/192\n",
      "614/614 [==============================] - 18s 29ms/step - loss: 0.6835 - auc: 0.5690 - val_loss: 0.6930 - val_auc: 0.5440\n",
      "Epoch 11/192\n",
      "614/614 [==============================] - 14s 23ms/step - loss: 0.6826 - auc: 0.5719 - val_loss: 0.6944 - val_auc: 0.5433\n",
      "Epoch 12/192\n",
      "614/614 [==============================] - 15s 24ms/step - loss: 0.6815 - auc: 0.5747 - val_loss: 0.6954 - val_auc: 0.5423\n",
      "Epoch 13/192\n",
      "613/614 [============================>.] - ETA: 0s - loss: 0.6804 - auc: 0.5778\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "614/614 [==============================] - 14s 23ms/step - loss: 0.6804 - auc: 0.5778 - val_loss: 0.6971 - val_auc: 0.5428\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [18:43, 224.73s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 21min 5s, sys: 1min 41s, total: 22min 46s\n",
      "Wall time: 18min 43s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "if CV_STRATEGY == 'PurgedGroupTimeSeriesSplit':\n",
    "    gkf = PurgedGroupTimeSeriesSplit(n_splits=FOLDS, group_gap=20)\n",
    "    splits = list(gkf.split(y, groups=train['date'].values))    \n",
    "    \n",
    "elif CV_STRATEGY == \"GroupKFold\":\n",
    "    cv = GroupKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "    splits = cv.split(train, train['resp'].values.astype(int), 'date')\n",
    "\n",
    "elif CV_STRATEGY ==  \"StratifiedGroupKFold\":\n",
    "    cv = StratifiedGroupKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "    splits = cv.split(train, train['resp'].values.astype(int), 'date')\n",
    "\n",
    "models = []\n",
    "for fold, (train_indices, test_indices) in tqdm(enumerate(splits)):\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "    # model\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = create_resnet(X.shape[-1], y.shape[-1], encoder)\n",
    "    \n",
    "    # callbacks\n",
    "    er = tf.keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True, monitor='val_loss')\n",
    "    ReduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, verbose=1, mode='min')\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f'./model_{SEED}_{fold}.hdf5', save_weights_only=True, verbose=0, monitor='val_loss', save_best_only=True)\n",
    "    nn_callbacks = [er, ReduceLR, model_checkpoint_callback]\n",
    "    \n",
    "    # fit\n",
    "    model.fit(X_train, y_train, validation_data=(X_test,y_test), \n",
    "              epochs=192, batch_size=2048, callbacks=nn_callbacks)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T13:25:24.385060Z",
     "iopub.status.busy": "2021-02-18T13:25:24.383877Z",
     "iopub.status.idle": "2021-02-18T13:25:24.388035Z",
     "shell.execute_reply": "2021-02-18T13:25:24.388539Z"
    },
    "papermill": {
     "duration": 7.179275,
     "end_time": "2021-02-18T13:25:24.388689",
     "exception": false,
     "start_time": "2021-02-18T13:25:17.209414",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"f = np.median\\nth = 0.500\\n\\nimport janestreet\\nenv = janestreet.make_env()\\nfor (test_df, pred_df) in tqdm(env.iter_test()):\\n    if test_df['weight'].item() > 0:\\n        x_tt = test_df.loc[:, features].values\\n        \\n        # GBDT inference with treelite\\n        batch = treelite_runtime.Batch.from_npy2d(x_tt)\\n        xgb_pred = predictor.predict(batch)\\n    \\n        # NN inference\\n        if np.isnan(x_tt[:, 1:].sum()):\\n            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\\n        \\n        pred = np.mean([model(x_tt, training = False).numpy() for model in models],axis=0)\\n        pred = f(pred)\\n        \\n        # ensemble\\n        pred_df.action = np.where(0.9*pred + 0.1*xgb_pred >= th, 1, 0).astype(int)\\n    else:\\n        pred_df.action = 0\\n    env.predict(pred_df)\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"f = np.median\n",
    "th = 0.500\n",
    "\n",
    "import janestreet\n",
    "env = janestreet.make_env()\n",
    "for (test_df, pred_df) in tqdm(env.iter_test()):\n",
    "    if test_df['weight'].item() > 0:\n",
    "        x_tt = test_df.loc[:, features].values\n",
    "        \n",
    "        # GBDT inference with treelite\n",
    "        batch = treelite_runtime.Batch.from_npy2d(x_tt)\n",
    "        xgb_pred = predictor.predict(batch)\n",
    "    \n",
    "        # NN inference\n",
    "        if np.isnan(x_tt[:, 1:].sum()):\n",
    "            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n",
    "        \n",
    "        pred = np.mean([model(x_tt, training = False).numpy() for model in models],axis=0)\n",
    "        pred = f(pred)\n",
    "        \n",
    "        # ensemble\n",
    "        pred_df.action = np.where(0.9*pred + 0.1*xgb_pred >= th, 1, 0).astype(int)\n",
    "    else:\n",
    "        pred_df.action = 0\n",
    "    env.predict(pred_df)\"\"\""
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 1340.54591,
   "end_time": "2021-02-18T13:25:32.969876",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-18T13:03:12.423966",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
