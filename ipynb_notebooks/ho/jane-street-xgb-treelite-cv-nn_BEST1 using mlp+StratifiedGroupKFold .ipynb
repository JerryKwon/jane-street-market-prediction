{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "_cell_guid": "b1076dfc-b9ad-4769-8c92-a6c4dae69d19",
    "_uuid": "8f2839f25d086af736a60e9eeb907d3b93b6e0e5",
    "execution": {
     "iopub.execute_input": "2021-02-18T04:20:22.059896Z",
     "iopub.status.busy": "2021-02-18T04:20:22.059206Z",
     "iopub.status.idle": "2021-02-18T04:20:29.412439Z",
     "shell.execute_reply": "2021-02-18T04:20:29.411078Z"
    },
    "papermill": {
     "duration": 7.395162,
     "end_time": "2021-02-18T04:20:29.412578",
     "exception": false,
     "start_time": "2021-02-18T04:20:22.017416",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "import sys\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_addons as tfa\n",
    "\n",
    "import operator\n",
    "import seaborn as sns\n",
    "\n",
    "import sklearn\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import GroupKFold\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.model_selection._split import _BaseKFold, indexable, _num_samples\n",
    "from sklearn.utils.validation import _deprecate_positional_args\n",
    "\n",
    "from tqdm import tqdm\n",
    "import random\n",
    "from random import choices\n",
    "\n",
    "from collections import Counter, defaultdict\n",
    "\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:20:29.487316Z",
     "iopub.status.busy": "2021-02-18T04:20:29.486345Z",
     "iopub.status.idle": "2021-02-18T04:20:29.490579Z",
     "shell.execute_reply": "2021-02-18T04:20:29.491348Z"
    },
    "papermill": {
     "duration": 0.045859,
     "end_time": "2021-02-18T04:20:29.491526",
     "exception": false,
     "start_time": "2021-02-18T04:20:29.445667",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Tensorflow version 2.3.1\n",
      "Accelerated Linear Algebra enabled\n"
     ]
    }
   ],
   "source": [
    "# tf setup\n",
    "print(\"Tensorflow version \" + tf.__version__)\n",
    "AUTO = tf.data.experimental.AUTOTUNE\n",
    "\n",
    "MIXED_PRECISION = False\n",
    "XLA_ACCELERATE = True\n",
    "\n",
    "if MIXED_PRECISION:\n",
    "    from tensorflow.keras.mixed_precision import experimental as mixed_precision\n",
    "    if tpu: policy = tf.keras.mixed_precision.experimental.Policy('mixed_bfloat16')\n",
    "    else: policy = tf.keras.mixed_precision.experimental.Policy('mixed_float16')\n",
    "    mixed_precision.set_policy(policy)\n",
    "    print('Mixed precision enabled')\n",
    "\n",
    "if XLA_ACCELERATE:\n",
    "    tf.config.optimizer.set_jit(True)\n",
    "    print('Accelerated Linear Algebra enabled')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.030852,
     "end_time": "2021-02-18T04:20:29.554397",
     "exception": false,
     "start_time": "2021-02-18T04:20:29.523545",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:20:29.623076Z",
     "iopub.status.busy": "2021-02-18T04:20:29.622296Z",
     "iopub.status.idle": "2021-02-18T04:20:29.625420Z",
     "shell.execute_reply": "2021-02-18T04:20:29.624918Z"
    },
    "papermill": {
     "duration": 0.039312,
     "end_time": "2021-02-18T04:20:29.625519",
     "exception": false,
     "start_time": "2021-02-18T04:20:29.586207",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "SEED = 2021\n",
    "START_DATE = 86\n",
    "FOLDS = 5\n",
    "DEBUG = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032454,
     "end_time": "2021-02-18T04:20:29.689694",
     "exception": false,
     "start_time": "2021-02-18T04:20:29.657240",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# CV Strategy\n",
    "\n",
    "## PurgedGroupTimeSeriesSplit\n",
    "Click the code button to see. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "_kg_hide-input": true,
    "_kg_hide-output": true,
    "execution": {
     "iopub.execute_input": "2021-02-18T04:20:29.815022Z",
     "iopub.status.busy": "2021-02-18T04:20:29.802523Z",
     "iopub.status.idle": "2021-02-18T04:20:29.818056Z",
     "shell.execute_reply": "2021-02-18T04:20:29.817498Z"
    },
    "papermill": {
     "duration": 0.096411,
     "end_time": "2021-02-18T04:20:29.818168",
     "exception": false,
     "start_time": "2021-02-18T04:20:29.721757",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# modified code for group gaps; source\n",
    "# https://github.com/getgaurav2/scikit-learn/blob/d4a3af5cc9da3a76f0266932644b884c99724c57/sklearn/model_selection/_split.py#L2243\n",
    "class PurgedGroupTimeSeriesSplit(_BaseKFold):\n",
    "    \"\"\"Time Series cross-validator variant with non-overlapping groups.\n",
    "    Allows for a gap in groups to avoid potentially leaking info from\n",
    "    train into test if the model has windowed or lag features.\n",
    "    Provides train/test indices to split time series data samples\n",
    "    that are observed at fixed time intervals according to a\n",
    "    third-party provided group.\n",
    "    In each split, test indices must be higher than before, and thus shuffling\n",
    "    in cross validator is inappropriate.\n",
    "    This cross-validation object is a variation of :class:`KFold`.\n",
    "    In the kth split, it returns first k folds as train set and the\n",
    "    (k+1)th fold as test set.\n",
    "    The same group will not appear in two different folds (the number of\n",
    "    distinct groups has to be at least equal to the number of folds).\n",
    "    Note that unlike standard cross-validation methods, successive\n",
    "    training sets are supersets of those that come before them.\n",
    "    Read more in the :ref:`User Guide <cross_validation>`.\n",
    "    Parameters\n",
    "    ----------\n",
    "    n_splits : int, default=5\n",
    "        Number of splits. Must be at least 2.\n",
    "    max_train_group_size : int, default=Inf\n",
    "        Maximum group size for a single training set.\n",
    "    group_gap : int, default=None\n",
    "        Gap between train and test\n",
    "    max_test_group_size : int, default=Inf\n",
    "        We discard this number of groups from the end of each train split\n",
    "    \"\"\"\n",
    "\n",
    "    @_deprecate_positional_args\n",
    "    def __init__(self,\n",
    "                 n_splits=5,\n",
    "                 *,\n",
    "                 max_train_group_size=np.inf,\n",
    "                 max_test_group_size=np.inf,\n",
    "                 group_gap=None,\n",
    "                 verbose=False\n",
    "                 ):\n",
    "        super().__init__(n_splits, shuffle=False, random_state=None)\n",
    "        self.max_train_group_size = max_train_group_size\n",
    "        self.group_gap = group_gap\n",
    "        self.max_test_group_size = max_test_group_size\n",
    "        self.verbose = verbose\n",
    "\n",
    "    def split(self, X, y=None, groups=None):\n",
    "        \"\"\"Generate indices to split data into training and test set.\n",
    "        Parameters\n",
    "        ----------\n",
    "        X : array-like of shape (n_samples, n_features)\n",
    "            Training data, where n_samples is the number of samples\n",
    "            and n_features is the number of features.\n",
    "        y : array-like of shape (n_samples,)\n",
    "            Always ignored, exists for compatibility.\n",
    "        groups : array-like of shape (n_samples,)\n",
    "            Group labels for the samples used while splitting the dataset into\n",
    "            train/test set.\n",
    "        Yields\n",
    "        ------\n",
    "        train : ndarray\n",
    "            The training set indices for that split.\n",
    "        test : ndarray\n",
    "            The testing set indices for that split.\n",
    "        \"\"\"\n",
    "        if groups is None:\n",
    "            raise ValueError(\n",
    "                \"The 'groups' parameter should not be None\")\n",
    "        X, y, groups = indexable(X, y, groups)\n",
    "        n_samples = _num_samples(X)\n",
    "        n_splits = self.n_splits\n",
    "        group_gap = self.group_gap\n",
    "        max_test_group_size = self.max_test_group_size\n",
    "        max_train_group_size = self.max_train_group_size\n",
    "        n_folds = n_splits + 1\n",
    "        group_dict = {}\n",
    "        u, ind = np.unique(groups, return_index=True)\n",
    "        unique_groups = u[np.argsort(ind)]\n",
    "        n_samples = _num_samples(X)\n",
    "        n_groups = _num_samples(unique_groups)\n",
    "        for idx in np.arange(n_samples):\n",
    "            if (groups[idx] in group_dict):\n",
    "                group_dict[groups[idx]].append(idx)\n",
    "            else:\n",
    "                group_dict[groups[idx]] = [idx]\n",
    "        if n_folds > n_groups:\n",
    "            raise ValueError(\n",
    "                (\"Cannot have number of folds={0} greater than\"\n",
    "                 \" the number of groups={1}\").format(n_folds,\n",
    "                                                     n_groups))\n",
    "\n",
    "        group_test_size = min(n_groups // n_folds, max_test_group_size)\n",
    "        group_test_starts = range(n_groups - n_splits * group_test_size,\n",
    "                                  n_groups, group_test_size)\n",
    "        for group_test_start in group_test_starts:\n",
    "            train_array = []\n",
    "            test_array = []\n",
    "\n",
    "            group_st = max(0, group_test_start - group_gap - max_train_group_size)\n",
    "            for train_group_idx in unique_groups[group_st:(group_test_start - group_gap)]:\n",
    "                train_array_tmp = group_dict[train_group_idx]\n",
    "                \n",
    "                train_array = np.sort(np.unique(\n",
    "                                      np.concatenate((train_array,\n",
    "                                                      train_array_tmp)),\n",
    "                                      axis=None), axis=None)\n",
    "\n",
    "            train_end = train_array.size\n",
    " \n",
    "            for test_group_idx in unique_groups[group_test_start:\n",
    "                                                group_test_start +\n",
    "                                                group_test_size]:\n",
    "                test_array_tmp = group_dict[test_group_idx]\n",
    "                test_array = np.sort(np.unique(\n",
    "                                              np.concatenate((test_array,\n",
    "                                                              test_array_tmp)),\n",
    "                                     axis=None), axis=None)\n",
    "\n",
    "            test_array  = test_array[group_gap:]\n",
    "            \n",
    "            \n",
    "            if self.verbose > 0:\n",
    "                    pass\n",
    "                    \n",
    "            yield [int(i) for i in train_array], [int(i) for i in test_array]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.031455,
     "end_time": "2021-02-18T04:20:29.880716",
     "exception": false,
     "start_time": "2021-02-18T04:20:29.849261",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## GroupKFold, StratifiedGroupKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:20:29.968622Z",
     "iopub.status.busy": "2021-02-18T04:20:29.963251Z",
     "iopub.status.idle": "2021-02-18T04:20:29.976580Z",
     "shell.execute_reply": "2021-02-18T04:20:29.976089Z"
    },
    "papermill": {
     "duration": 0.063715,
     "end_time": "2021-02-18T04:20:29.976680",
     "exception": false,
     "start_time": "2021-02-18T04:20:29.912965",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# ---- GroupKFold ----\n",
    "class GroupKFold(object):\n",
    "    \"\"\"\n",
    "    GroupKFold with random shuffle with a sklearn-like structure\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=4, shuffle=True, random_state=42):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, group=None):\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y, group):\n",
    "        kf = model_selection.KFold(n_splits=self.n_splits, shuffle=self.shuffle, random_state=self.random_state)\n",
    "        unique_ids = X[group].unique()\n",
    "        for fold, (tr_group_idx, va_group_idx) in enumerate(kf.split(unique_ids)):\n",
    "            # split group\n",
    "            tr_group, va_group = unique_ids[tr_group_idx], unique_ids[va_group_idx]\n",
    "            train_idx = np.where(X[group].isin(tr_group))[0]\n",
    "            val_idx = np.where(X[group].isin(va_group))[0]\n",
    "            yield train_idx, val_idx\n",
    "\n",
    "# ---- StratifiedGroupKFold ----\n",
    "class StratifiedGroupKFold(object):\n",
    "    \"\"\"\n",
    "    StratifiedGroupKFold with random shuffle with a sklearn-like structure\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, n_splits=4, shuffle=True, random_state=42):\n",
    "        self.n_splits = n_splits\n",
    "        self.shuffle = shuffle\n",
    "        self.random_state = random_state\n",
    "\n",
    "    def get_n_splits(self, X=None, y=None, group=None):\n",
    "        return self.n_splits\n",
    "\n",
    "    def split(self, X, y, group):\n",
    "        labels_num = np.max(y) + 1\n",
    "        y_counts_per_group = defaultdict(lambda: np.zeros(labels_num))\n",
    "        y_distr = Counter()\n",
    "        groups = X[group].values\n",
    "        for label, g in zip(y, groups):\n",
    "            y_counts_per_group[g][label] += 1\n",
    "            y_distr[label] += 1\n",
    "\n",
    "        y_counts_per_fold = defaultdict(lambda: np.zeros(labels_num))\n",
    "        groups_per_fold = defaultdict(set)\n",
    "\n",
    "        def eval_y_counts_per_fold(y_counts, fold):\n",
    "            y_counts_per_fold[fold] += y_counts\n",
    "            std_per_label = []\n",
    "            for label in range(labels_num):\n",
    "                label_std = np.std([y_counts_per_fold[i][label] / y_distr[label] for i in range(self.n_splits)])\n",
    "                std_per_label.append(label_std)\n",
    "            y_counts_per_fold[fold] -= y_counts\n",
    "            return np.mean(std_per_label)\n",
    "        \n",
    "        groups_and_y_counts = list(y_counts_per_group.items())\n",
    "        random.Random(self.random_state).shuffle(groups_and_y_counts)\n",
    "\n",
    "        for g, y_counts in sorted(groups_and_y_counts, key=lambda x: -np.std(x[1])):\n",
    "            best_fold = None\n",
    "            min_eval = None\n",
    "            for i in range(self.n_splits):\n",
    "                fold_eval = eval_y_counts_per_fold(y_counts, i)\n",
    "                if min_eval is None or fold_eval < min_eval:\n",
    "                    min_eval = fold_eval\n",
    "                    best_fold = i\n",
    "            y_counts_per_fold[best_fold] += y_counts\n",
    "            groups_per_fold[best_fold].add(g)\n",
    "\n",
    "        all_groups = set(groups)\n",
    "        for i in range(self.n_splits):\n",
    "            train_groups = all_groups - groups_per_fold[i]\n",
    "            test_groups = groups_per_fold[i]\n",
    "\n",
    "            train_idx = [i for i, g in enumerate(groups) if g in train_groups]\n",
    "            test_idx = [i for i, g in enumerate(groups) if g in test_groups]\n",
    "\n",
    "            yield train_idx, test_idx"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032371,
     "end_time": "2021-02-18T04:20:30.040759",
     "exception": false,
     "start_time": "2021-02-18T04:20:30.008388",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Loading the training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:20:30.111761Z",
     "iopub.status.busy": "2021-02-18T04:20:30.111002Z",
     "iopub.status.idle": "2021-02-18T04:23:03.026782Z",
     "shell.execute_reply": "2021-02-18T04:23:03.025762Z"
    },
    "papermill": {
     "duration": 152.954419,
     "end_time": "2021-02-18T04:23:03.026914",
     "exception": false,
     "start_time": "2021-02-18T04:20:30.072495",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train = pd.read_csv('../input/jane-street-market-prediction/train.csv') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:23:03.111209Z",
     "iopub.status.busy": "2021-02-18T04:23:03.109369Z",
     "iopub.status.idle": "2021-02-18T04:23:03.111979Z",
     "shell.execute_reply": "2021-02-18T04:23:03.112539Z"
    },
    "papermill": {
     "duration": 0.053051,
     "end_time": "2021-02-18T04:23:03.112674",
     "exception": false,
     "start_time": "2021-02-18T04:23:03.059623",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def reduce_memory_usage(df):\n",
    "    \n",
    "    start_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe is {start_memory} MB\")\n",
    "    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtype\n",
    "        \n",
    "        if col_type != 'object':\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            \n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)\n",
    "            \n",
    "            else:\n",
    "                \"\"\"if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\"\"\"\n",
    "                if c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    pass\n",
    "        else:\n",
    "            df[col] = df[col].astype('category')\n",
    "    \n",
    "    end_memory = df.memory_usage().sum() / 1024**2\n",
    "    print(f\"Memory usage of dataframe after reduction {end_memory} MB\")\n",
    "    print(f\"Reduced by {100 * (start_memory - end_memory) / start_memory} % \")\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:23:03.197148Z",
     "iopub.status.busy": "2021-02-18T04:23:03.195430Z",
     "iopub.status.idle": "2021-02-18T04:23:55.994218Z",
     "shell.execute_reply": "2021-02-18T04:23:55.994890Z"
    },
    "papermill": {
     "duration": 52.850778,
     "end_time": "2021-02-18T04:23:55.995050",
     "exception": false,
     "start_time": "2021-02-18T04:23:03.144272",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Memory usage of dataframe is 2516.843978881836 MB\n",
      "Memory usage of dataframe after reduction 1247.0233011245728 MB\n",
      "Reduced by 50.45289610369131 % \n"
     ]
    }
   ],
   "source": [
    "train = reduce_memory_usage(train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:23:56.104771Z",
     "iopub.status.busy": "2021-02-18T04:23:56.103764Z",
     "iopub.status.idle": "2021-02-18T04:23:59.801486Z",
     "shell.execute_reply": "2021-02-18T04:23:59.800883Z"
    },
    "papermill": {
     "duration": 3.764122,
     "end_time": "2021-02-18T04:23:59.801599",
     "exception": false,
     "start_time": "2021-02-18T04:23:56.037477",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "#train = pd.read_feather('../input/janestreet-save-as-feather/train.feather') # faster data load\n",
    "train = train.query(f'date >= {START_DATE}').reset_index(drop = True) \n",
    "train = train.astype({c: np.float32 for c in train.select_dtypes(include='float64').columns}) #limit memory use\n",
    "train.fillna(train.mean(),inplace=True)\n",
    "train = train.query('weight > 0').reset_index(drop = True)\n",
    "# train = train.query('weight != 0').reset_index(drop = True)\n",
    "#train['action'] = (train['resp'] > 0).astype('int')\n",
    "train['action'] =  (  (train['resp_1'] > 0 ) & (train['resp_2'] > 0 ) & (train['resp_3'] > 0 ) & (train['resp_4'] > 0 ) &  (train['resp'] > 0 )   ).astype('int')\n",
    "features = [c for c in train.columns if 'feature' in c]\n",
    "\n",
    "resp_cols = ['resp_1', 'resp_2', 'resp_3', 'resp', 'resp_4']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:23:59.873201Z",
     "iopub.status.busy": "2021-02-18T04:23:59.872604Z",
     "iopub.status.idle": "2021-02-18T04:23:59.876381Z",
     "shell.execute_reply": "2021-02-18T04:23:59.876827Z"
    },
    "papermill": {
     "duration": 0.042726,
     "end_time": "2021-02-18T04:23:59.876949",
     "exception": false,
     "start_time": "2021-02-18T04:23:59.834223",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "if DEBUG:\n",
    "    train = train.sample(10000, random_state=SEED)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.03297,
     "end_time": "2021-02-18T04:23:59.943161",
     "exception": false,
     "start_time": "2021-02-18T04:23:59.910191",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Creating Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:24:00.023746Z",
     "iopub.status.busy": "2021-02-18T04:24:00.021907Z",
     "iopub.status.idle": "2021-02-18T04:24:00.024506Z",
     "shell.execute_reply": "2021-02-18T04:24:00.025014Z"
    },
    "papermill": {
     "duration": 0.049382,
     "end_time": "2021-02-18T04:24:00.025140",
     "exception": false,
     "start_time": "2021-02-18T04:23:59.975758",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_autoencoder(input_dim,output_dim,noise=0.05):\n",
    "    i = tf.keras.layers.Input(input_dim)\n",
    "    encoded = tf.keras.layers.BatchNormalization()(i)\n",
    "    encoded = tf.keras.layers.GaussianNoise(noise)(encoded)\n",
    "    encoded = tf.keras.layers.Dense(64,activation='relu')(encoded)\n",
    "    decoded = tf.keras.layers.Dropout(0.2)(encoded)\n",
    "    decoded = tf.keras.layers.Dense(input_dim,name='decoded')(decoded)\n",
    "    x = tf.keras.layers.Dense(32,activation='relu')(decoded)\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(output_dim,activation='sigmoid',name='label_output')(x)\n",
    "    \n",
    "    encoder = tf.keras.models.Model(inputs=i,outputs=encoded)\n",
    "    autoencoder = tf.keras.models.Model(inputs=i,outputs=[decoded,x])\n",
    "    \n",
    "    autoencoder.compile(optimizer=tf.keras.optimizers.Adam(0.001), \n",
    "                        loss={'decoded':'mse','label_output':'binary_crossentropy'})\n",
    "    return autoencoder, encoder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.032223,
     "end_time": "2021-02-18T04:24:00.090315",
     "exception": false,
     "start_time": "2021-02-18T04:24:00.058092",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:24:00.165164Z",
     "iopub.status.busy": "2021-02-18T04:24:00.164488Z",
     "iopub.status.idle": "2021-02-18T04:24:00.167799Z",
     "shell.execute_reply": "2021-02-18T04:24:00.168397Z"
    },
    "papermill": {
     "duration": 0.044816,
     "end_time": "2021-02-18T04:24:00.168517",
     "exception": false,
     "start_time": "2021-02-18T04:24:00.123701",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "131"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "p = features\n",
    "p.append('resp')\n",
    "len(p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:24:00.482043Z",
     "iopub.status.busy": "2021-02-18T04:24:00.480790Z",
     "iopub.status.idle": "2021-02-18T04:24:54.637703Z",
     "shell.execute_reply": "2021-02-18T04:24:54.637072Z"
    },
    "papermill": {
     "duration": 54.43645,
     "end_time": "2021-02-18T04:24:54.637840",
     "exception": false,
     "start_time": "2021-02-18T04:24:00.201390",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "x = train[p].corr()\n",
    "del p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:24:54.713473Z",
     "iopub.status.busy": "2021-02-18T04:24:54.712316Z",
     "iopub.status.idle": "2021-02-18T04:24:54.751308Z",
     "shell.execute_reply": "2021-02-18T04:24:54.750749Z"
    },
    "papermill": {
     "duration": 0.078891,
     "end_time": "2021-02-18T04:24:54.751431",
     "exception": false,
     "start_time": "2021-02-18T04:24:54.672540",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['feature_25', 'feature_35', 'feature_48', 'feature_61', 'feature_63', 'feature_66', 'feature_68', 'feature_101', 'feature_107', 'feature_108', 'feature_113', 'feature_114', 'feature_119', 'feature_122', 'feature_126', 'feature_127', 'feature_128', 'feature_129']\n"
     ]
    }
   ],
   "source": [
    "x = x.abs()\n",
    "upper = x.where(np.triu(np.ones(x.shape), k=1).astype(np.bool))\n",
    "to_drop = [column for column in upper.columns if any(upper[column] > 0.95)]\n",
    "print(to_drop)\n",
    "del x, upper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:24:55.007062Z",
     "iopub.status.busy": "2021-02-18T04:24:55.005135Z",
     "iopub.status.idle": "2021-02-18T04:24:55.007767Z",
     "shell.execute_reply": "2021-02-18T04:24:55.008296Z"
    },
    "papermill": {
     "duration": 0.219272,
     "end_time": "2021-02-18T04:24:55.008451",
     "exception": false,
     "start_time": "2021-02-18T04:24:54.789179",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "train.drop(to_drop, 1, inplace=True)\n",
    "del to_drop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:24:55.299395Z",
     "iopub.status.busy": "2021-02-18T04:24:55.297887Z",
     "iopub.status.idle": "2021-02-18T04:24:57.752026Z",
     "shell.execute_reply": "2021-02-18T04:24:57.750672Z"
    },
    "papermill": {
     "duration": 2.708216,
     "end_time": "2021-02-18T04:24:57.752151",
     "exception": false,
     "start_time": "2021-02-18T04:24:55.043935",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "features = [c for c in train.columns if 'feature' in c]\n",
    "\n",
    "X = train[features].values\n",
    "y = train['action']\n",
    "\n",
    "f_mean = np.mean(train[features[1:]].values,axis=0)\n",
    "\n",
    "# Next, we hold out part of the training data to form the hold-out validation set\n",
    "train_x, valid_x, train_y, valid_y = train_test_split(X, y, test_size=0.2)\n",
    "del valid_x, valid_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.033875,
     "end_time": "2021-02-18T04:24:57.820674",
     "exception": false,
     "start_time": "2021-02-18T04:24:57.786799",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "## Make a predictor with XGBoost using treelite"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:24:57.894391Z",
     "iopub.status.busy": "2021-02-18T04:24:57.893702Z",
     "iopub.status.idle": "2021-02-18T04:24:58.140443Z",
     "shell.execute_reply": "2021-02-18T04:24:58.138955Z"
    },
    "papermill": {
     "duration": 0.284955,
     "end_time": "2021-02-18T04:24:58.140565",
     "exception": false,
     "start_time": "2021-02-18T04:24:57.855610",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<style type='text/css'>\n",
       ".datatable table.frame { margin-bottom: 0; }\n",
       ".datatable table.frame thead { border-bottom: none; }\n",
       ".datatable table.frame tr.coltypes td {  color: #FFFFFF;  line-height: 6px;  padding: 0 0.5em;}\n",
       ".datatable .bool    { background: #DDDD99; }\n",
       ".datatable .object  { background: #565656; }\n",
       ".datatable .int     { background: #5D9E5D; }\n",
       ".datatable .float   { background: #4040CC; }\n",
       ".datatable .str     { background: #CC4040; }\n",
       ".datatable .row_index {  background: var(--jp-border-color3);  border-right: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  font-size: 9px;}\n",
       ".datatable .frame tr.coltypes .row_index {  background: var(--jp-border-color0);}\n",
       ".datatable th:nth-child(2) { padding-left: 12px; }\n",
       ".datatable .hellipsis {  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .vellipsis {  background: var(--jp-layout-color0);  color: var(--jp-cell-editor-border-color);}\n",
       ".datatable .na {  color: var(--jp-cell-editor-border-color);  font-size: 80%;}\n",
       ".datatable .footer { font-size: 9px; }\n",
       ".datatable .frame_dimensions {  background: var(--jp-border-color3);  border-top: 1px solid var(--jp-border-color0);  color: var(--jp-ui-font-color3);  display: inline-block;  opacity: 0.6;  padding: 1px 10px 1px 5px;}\n",
       "</style>\n"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import treelite\n",
    "import treelite_runtime\n",
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:24:58.218194Z",
     "iopub.status.busy": "2021-02-18T04:24:58.217368Z",
     "iopub.status.idle": "2021-02-18T04:25:00.261348Z",
     "shell.execute_reply": "2021-02-18T04:25:00.260764Z"
    },
    "papermill": {
     "duration": 2.084389,
     "end_time": "2021-02-18T04:25:00.261467",
     "exception": false,
     "start_time": "2021-02-18T04:24:58.177078",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# We create the XGboost-specific DMatrix data format from the numpy array. \n",
    "# This data structure is optimised for memory efficiency and training speed\n",
    "dtrain = xgb.DMatrix(train_x, label=train_y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:25:00.339021Z",
     "iopub.status.busy": "2021-02-18T04:25:00.338280Z",
     "iopub.status.idle": "2021-02-18T04:28:59.665711Z",
     "shell.execute_reply": "2021-02-18T04:28:59.666527Z"
    },
    "papermill": {
     "duration": 239.369259,
     "end_time": "2021-02-18T04:28:59.666746",
     "exception": false,
     "start_time": "2021-02-18T04:25:00.297487",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\ttrain-logloss:0.655629\n",
      "[1]\ttrain-logloss:0.623005\n",
      "[2]\ttrain-logloss:0.594485\n",
      "[3]\ttrain-logloss:0.567377\n",
      "[4]\ttrain-logloss:0.543478\n",
      "[5]\ttrain-logloss:0.521352\n",
      "[6]\ttrain-logloss:0.500838\n",
      "[7]\ttrain-logloss:0.482105\n",
      "[8]\ttrain-logloss:0.464513\n",
      "[9]\ttrain-logloss:0.448376\n",
      "[10]\ttrain-logloss:0.433093\n",
      "[11]\ttrain-logloss:0.418456\n",
      "[12]\ttrain-logloss:0.405401\n",
      "[13]\ttrain-logloss:0.391796\n",
      "[14]\ttrain-logloss:0.378452\n",
      "[15]\ttrain-logloss:0.366547\n",
      "[16]\ttrain-logloss:0.356094\n",
      "[17]\ttrain-logloss:0.345561\n",
      "[18]\ttrain-logloss:0.336285\n",
      "[19]\ttrain-logloss:0.327395\n",
      "[20]\ttrain-logloss:0.319892\n",
      "[21]\ttrain-logloss:0.312036\n",
      "[22]\ttrain-logloss:0.304651\n",
      "[23]\ttrain-logloss:0.298485\n",
      "[24]\ttrain-logloss:0.291532\n",
      "[25]\ttrain-logloss:0.285631\n",
      "[26]\ttrain-logloss:0.279113\n",
      "[27]\ttrain-logloss:0.274815\n",
      "[28]\ttrain-logloss:0.268346\n",
      "[29]\ttrain-logloss:0.263694\n",
      "[30]\ttrain-logloss:0.259645\n",
      "[31]\ttrain-logloss:0.254514\n",
      "[32]\ttrain-logloss:0.24937\n",
      "[33]\ttrain-logloss:0.245505\n",
      "[34]\ttrain-logloss:0.241948\n",
      "[35]\ttrain-logloss:0.237897\n",
      "[36]\ttrain-logloss:0.23468\n",
      "[37]\ttrain-logloss:0.232599\n",
      "[38]\ttrain-logloss:0.229003\n",
      "[39]\ttrain-logloss:0.227166\n",
      "[40]\ttrain-logloss:0.224998\n",
      "[41]\ttrain-logloss:0.221042\n",
      "[42]\ttrain-logloss:0.216748\n",
      "[43]\ttrain-logloss:0.214361\n",
      "[44]\ttrain-logloss:0.211514\n",
      "[45]\ttrain-logloss:0.208979\n",
      "[46]\ttrain-logloss:0.206701\n",
      "[47]\ttrain-logloss:0.203296\n",
      "[48]\ttrain-logloss:0.199034\n",
      "[49]\ttrain-logloss:0.197283\n",
      "[50]\ttrain-logloss:0.193636\n",
      "[51]\ttrain-logloss:0.190757\n",
      "[52]\ttrain-logloss:0.188991\n",
      "[53]\ttrain-logloss:0.187708\n",
      "[54]\ttrain-logloss:0.185046\n",
      "[55]\ttrain-logloss:0.181978\n",
      "[56]\ttrain-logloss:0.180689\n",
      "[57]\ttrain-logloss:0.179179\n",
      "[58]\ttrain-logloss:0.175491\n",
      "[59]\ttrain-logloss:0.172729\n",
      "[60]\ttrain-logloss:0.170085\n",
      "[61]\ttrain-logloss:0.169006\n",
      "[62]\ttrain-logloss:0.16708\n",
      "[63]\ttrain-logloss:0.164879\n",
      "[64]\ttrain-logloss:0.162304\n",
      "[65]\ttrain-logloss:0.159224\n",
      "[66]\ttrain-logloss:0.157446\n",
      "[67]\ttrain-logloss:0.155474\n",
      "[68]\ttrain-logloss:0.15354\n",
      "[69]\ttrain-logloss:0.151709\n",
      "[70]\ttrain-logloss:0.14952\n",
      "[71]\ttrain-logloss:0.148633\n",
      "[72]\ttrain-logloss:0.146256\n",
      "[73]\ttrain-logloss:0.14477\n",
      "[74]\ttrain-logloss:0.142238\n",
      "[75]\ttrain-logloss:0.139999\n",
      "[76]\ttrain-logloss:0.137748\n",
      "[77]\ttrain-logloss:0.135507\n",
      "[78]\ttrain-logloss:0.133292\n",
      "[79]\ttrain-logloss:0.131075\n",
      "[80]\ttrain-logloss:0.129293\n",
      "[81]\ttrain-logloss:0.127323\n",
      "[82]\ttrain-logloss:0.125845\n",
      "[83]\ttrain-logloss:0.124426\n",
      "[84]\ttrain-logloss:0.122406\n",
      "[85]\ttrain-logloss:0.121408\n",
      "[86]\ttrain-logloss:0.119677\n",
      "[87]\ttrain-logloss:0.118692\n",
      "[88]\ttrain-logloss:0.117714\n",
      "[89]\ttrain-logloss:0.116483\n",
      "[90]\ttrain-logloss:0.114858\n",
      "[91]\ttrain-logloss:0.113525\n",
      "[92]\ttrain-logloss:0.112541\n",
      "[93]\ttrain-logloss:0.111231\n",
      "[94]\ttrain-logloss:0.109857\n",
      "[95]\ttrain-logloss:0.108604\n",
      "[96]\ttrain-logloss:0.107656\n",
      "[97]\ttrain-logloss:0.106183\n",
      "[98]\ttrain-logloss:0.10497\n",
      "[99]\ttrain-logloss:0.103471\n"
     ]
    }
   ],
   "source": [
    "params = {\n",
    "        'n_estimators': 435,\n",
    "        'max_depth': 24,\n",
    "        'learning_rate': 0.09905592273886195,\n",
    "        'subsample': 0.8704369112806065,\n",
    "        'colsample_bytree': 0.9932309296458037,\n",
    "        'objective': 'binary:logistic',\n",
    "        'gamma': 7,\n",
    "        \"eval_metric\" : 'logloss',\n",
    "        'seed': 2021,\n",
    "        'tree_method': 'gpu_hist'\n",
    "        }\n",
    "bst = xgb.train(params, dtrain, 100, [(dtrain, 'train')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:28:59.810283Z",
     "iopub.status.busy": "2021-02-18T04:28:59.808864Z",
     "iopub.status.idle": "2021-02-18T04:29:00.332494Z",
     "shell.execute_reply": "2021-02-18T04:29:00.331895Z"
    },
    "papermill": {
     "duration": 0.596998,
     "end_time": "2021-02-18T04:29:00.332603",
     "exception": false,
     "start_time": "2021-02-18T04:28:59.735605",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# pass to treelite\n",
    "model1 = treelite.Model.from_xgboost(bst)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:29:00.513473Z",
     "iopub.status.busy": "2021-02-18T04:29:00.512633Z",
     "iopub.status.idle": "2021-02-18T04:30:30.562833Z",
     "shell.execute_reply": "2021-02-18T04:30:30.564032Z"
    },
    "papermill": {
     "duration": 90.163259,
     "end_time": "2021-02-18T04:30:30.564239",
     "exception": false,
     "start_time": "2021-02-18T04:29:00.400980",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:29:00] ../src/compiler/failsafe.cc:245: Using FailSafeCompiler\n",
      "[04:29:00] ../src/compiler/failsafe.cc:256: Warning: 'parallel_comp' parameter is not applicable for FailSafeCompiler\n",
      "[04:29:08] ../src/c_api/c_api.cc:286: Code generation finished. Writing code to files...\n",
      "[04:29:08] ../src/c_api/c_api.cc:291: Writing file recipe.json...\n",
      "[04:29:08] ../src/c_api/c_api.cc:291: Writing file header.h...\n",
      "[04:29:08] ../src/c_api/c_api.cc:291: Writing file main.c...\n",
      "[04:29:08] ../src/c_api/c_api.cc:291: Writing file arrays.c...\n",
      "[04:29:08] /opt/conda/lib/python3.7/site-packages/treelite/contrib/__init__.py:263: \u001b[1;31mWARNING: some of the source files are long. Expect long compilation time.\u001b[0m You may want to adjust the parameter \u001b[33mparallel_comp\u001b[0m.\n",
      "\n",
      "[04:29:09] /opt/conda/lib/python3.7/site-packages/treelite/contrib/util.py:104: Compiling sources files in directory ./tmp4fhicd97 into object files (*.o)...\n",
      "[04:30:29] /opt/conda/lib/python3.7/site-packages/treelite/contrib/util.py:133: Generating dynamic shared library ./tmp4fhicd97/predictor.so...\n",
      "[04:30:30] /opt/conda/lib/python3.7/site-packages/treelite/contrib/__init__.py:278: Generated shared library in 81.53 seconds\n"
     ]
    }
   ],
   "source": [
    "# generate shared library\n",
    "toolchain = 'gcc'\n",
    "model1.export_lib(toolchain=toolchain, libpath='./mymodel.so',compiler='failsafe',\n",
    "                     params={'parallel_comp': 32}, verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:30:30.821885Z",
     "iopub.status.busy": "2021-02-18T04:30:30.820599Z",
     "iopub.status.idle": "2021-02-18T04:30:30.828286Z",
     "shell.execute_reply": "2021-02-18T04:30:30.829375Z"
    },
    "papermill": {
     "duration": 0.151754,
     "end_time": "2021-02-18T04:30:30.829685",
     "exception": false,
     "start_time": "2021-02-18T04:30:30.677931",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[04:30:30] ../src/predictor/predictor.cc:262: Dynamic shared library `/kaggle/working/mymodel.so' does not contain valid get_pred_transform() function\n",
      "[04:30:30] ../src/predictor/predictor.cc:276: Dynamic shared library `/kaggle/working/mymodel.so' does not contain valid get_sigmoid_alpha() function\n",
      "[04:30:30] ../src/predictor/predictor.cc:288: Dynamic shared library `/kaggle/working/mymodel.so' does not contain valid get_global_bias() function\n",
      "[04:30:30] /opt/conda/lib/python3.7/site-packages/treelite_runtime/predictor.py:311: Dynamic shared library /kaggle/working/mymodel.so has been successfully loaded into memory\n"
     ]
    }
   ],
   "source": [
    "# predictor from treelite\n",
    "predictor = treelite_runtime.Predictor('./mymodel.so', verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:30:31.244812Z",
     "iopub.status.busy": "2021-02-18T04:30:31.242084Z",
     "iopub.status.idle": "2021-02-18T04:30:31.248097Z",
     "shell.execute_reply": "2021-02-18T04:30:31.248897Z"
    },
    "papermill": {
     "duration": 0.171078,
     "end_time": "2021-02-18T04:30:31.249070",
     "exception": false,
     "start_time": "2021-02-18T04:30:31.077992",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del y, train_x, train_y, dtrain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 0.075056,
     "end_time": "2021-02-18T04:30:31.453845",
     "exception": false,
     "start_time": "2021-02-18T04:30:31.378789",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Fit Autoencoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:30:31.617715Z",
     "iopub.status.busy": "2021-02-18T04:30:31.616546Z",
     "iopub.status.idle": "2021-02-18T04:30:31.983942Z",
     "shell.execute_reply": "2021-02-18T04:30:31.983230Z"
    },
    "papermill": {
     "duration": 0.45393,
     "end_time": "2021-02-18T04:30:31.984067",
     "exception": false,
     "start_time": "2021-02-18T04:30:31.530137",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "y = np.stack([(train[c] > 0).astype('int') for c in resp_cols]).T #Multitarget\n",
    "f_mean = np.mean(train[features[1:]].values,axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:30:32.157282Z",
     "iopub.status.busy": "2021-02-18T04:30:32.156582Z",
     "iopub.status.idle": "2021-02-18T04:33:42.584427Z",
     "shell.execute_reply": "2021-02-18T04:33:42.583758Z"
    },
    "papermill": {
     "duration": 190.515605,
     "end_time": "2021-02-18T04:33:42.584544",
     "exception": false,
     "start_time": "2021-02-18T04:30:32.068939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "691/691 [==============================] - 6s 8ms/step - loss: 2.4359 - decoded_loss: 1.7289 - label_output_loss: 0.7071 - val_loss: 1.2741 - val_decoded_loss: 0.5834 - val_label_output_loss: 0.6907\n",
      "Epoch 2/1000\n",
      "691/691 [==============================] - 7s 10ms/step - loss: 1.8477 - decoded_loss: 1.1560 - label_output_loss: 0.6917 - val_loss: 1.1814 - val_decoded_loss: 0.4917 - val_label_output_loss: 0.6897\n",
      "Epoch 3/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7933 - decoded_loss: 1.1023 - label_output_loss: 0.6911 - val_loss: 1.1576 - val_decoded_loss: 0.4681 - val_label_output_loss: 0.6895\n",
      "Epoch 4/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7666 - decoded_loss: 1.0757 - label_output_loss: 0.6909 - val_loss: 1.1239 - val_decoded_loss: 0.4347 - val_label_output_loss: 0.6892\n",
      "Epoch 5/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7481 - decoded_loss: 1.0573 - label_output_loss: 0.6907 - val_loss: 1.1082 - val_decoded_loss: 0.4188 - val_label_output_loss: 0.6894\n",
      "Epoch 6/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7404 - decoded_loss: 1.0498 - label_output_loss: 0.6906 - val_loss: 1.0923 - val_decoded_loss: 0.4031 - val_label_output_loss: 0.6892\n",
      "Epoch 7/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7270 - decoded_loss: 1.0364 - label_output_loss: 0.6905 - val_loss: 1.0879 - val_decoded_loss: 0.3989 - val_label_output_loss: 0.6890\n",
      "Epoch 8/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7258 - decoded_loss: 1.0353 - label_output_loss: 0.6905 - val_loss: 1.0679 - val_decoded_loss: 0.3789 - val_label_output_loss: 0.6891\n",
      "Epoch 9/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7147 - decoded_loss: 1.0244 - label_output_loss: 0.6904 - val_loss: 1.0705 - val_decoded_loss: 0.3816 - val_label_output_loss: 0.6889\n",
      "Epoch 10/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7092 - decoded_loss: 1.0189 - label_output_loss: 0.6904 - val_loss: 1.0669 - val_decoded_loss: 0.3779 - val_label_output_loss: 0.6889\n",
      "Epoch 11/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7080 - decoded_loss: 1.0177 - label_output_loss: 0.6903 - val_loss: 1.0637 - val_decoded_loss: 0.3747 - val_label_output_loss: 0.6890\n",
      "Epoch 12/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7038 - decoded_loss: 1.0135 - label_output_loss: 0.6903 - val_loss: 1.0537 - val_decoded_loss: 0.3649 - val_label_output_loss: 0.6888\n",
      "Epoch 13/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.7026 - decoded_loss: 1.0123 - label_output_loss: 0.6903 - val_loss: 1.0563 - val_decoded_loss: 0.3673 - val_label_output_loss: 0.6889\n",
      "Epoch 14/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6981 - decoded_loss: 1.0078 - label_output_loss: 0.6902 - val_loss: 1.0563 - val_decoded_loss: 0.3676 - val_label_output_loss: 0.6886\n",
      "Epoch 15/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6958 - decoded_loss: 1.0056 - label_output_loss: 0.6902 - val_loss: 1.0520 - val_decoded_loss: 0.3633 - val_label_output_loss: 0.6887\n",
      "Epoch 16/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6928 - decoded_loss: 1.0026 - label_output_loss: 0.6902 - val_loss: 1.0438 - val_decoded_loss: 0.3550 - val_label_output_loss: 0.6888\n",
      "Epoch 17/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6914 - decoded_loss: 1.0013 - label_output_loss: 0.6901 - val_loss: 1.0546 - val_decoded_loss: 0.3659 - val_label_output_loss: 0.6886\n",
      "Epoch 18/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6946 - decoded_loss: 1.0046 - label_output_loss: 0.6901 - val_loss: 1.0539 - val_decoded_loss: 0.3651 - val_label_output_loss: 0.6888\n",
      "Epoch 19/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6895 - decoded_loss: 0.9994 - label_output_loss: 0.6901 - val_loss: 1.0491 - val_decoded_loss: 0.3605 - val_label_output_loss: 0.6886\n",
      "Epoch 20/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6885 - decoded_loss: 0.9984 - label_output_loss: 0.6901 - val_loss: 1.0452 - val_decoded_loss: 0.3567 - val_label_output_loss: 0.6885\n",
      "Epoch 21/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6808 - decoded_loss: 0.9907 - label_output_loss: 0.6901 - val_loss: 1.0385 - val_decoded_loss: 0.3499 - val_label_output_loss: 0.6886\n",
      "Epoch 22/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6975 - decoded_loss: 1.0074 - label_output_loss: 0.6900 - val_loss: 1.0535 - val_decoded_loss: 0.3648 - val_label_output_loss: 0.6887\n",
      "Epoch 23/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6878 - decoded_loss: 0.9978 - label_output_loss: 0.6900 - val_loss: 1.0551 - val_decoded_loss: 0.3666 - val_label_output_loss: 0.6886\n",
      "Epoch 24/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6792 - decoded_loss: 0.9892 - label_output_loss: 0.6900 - val_loss: 1.0480 - val_decoded_loss: 0.3593 - val_label_output_loss: 0.6887\n",
      "Epoch 25/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6834 - decoded_loss: 0.9934 - label_output_loss: 0.6900 - val_loss: 1.0470 - val_decoded_loss: 0.3584 - val_label_output_loss: 0.6886\n",
      "Epoch 26/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6864 - decoded_loss: 0.9964 - label_output_loss: 0.6900 - val_loss: 1.0378 - val_decoded_loss: 0.3493 - val_label_output_loss: 0.6886\n",
      "Epoch 27/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6822 - decoded_loss: 0.9922 - label_output_loss: 0.6900 - val_loss: 1.0476 - val_decoded_loss: 0.3589 - val_label_output_loss: 0.6887\n",
      "Epoch 28/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6815 - decoded_loss: 0.9915 - label_output_loss: 0.6900 - val_loss: 1.0354 - val_decoded_loss: 0.3466 - val_label_output_loss: 0.6888\n",
      "Epoch 29/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6833 - decoded_loss: 0.9932 - label_output_loss: 0.6900 - val_loss: 1.0367 - val_decoded_loss: 0.3481 - val_label_output_loss: 0.6886\n",
      "Epoch 30/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6840 - decoded_loss: 0.9940 - label_output_loss: 0.6900 - val_loss: 1.0463 - val_decoded_loss: 0.3576 - val_label_output_loss: 0.6887\n",
      "Epoch 31/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6858 - decoded_loss: 0.9959 - label_output_loss: 0.6900 - val_loss: 1.0471 - val_decoded_loss: 0.3585 - val_label_output_loss: 0.6886\n",
      "Epoch 32/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6766 - decoded_loss: 0.9866 - label_output_loss: 0.6900 - val_loss: 1.0396 - val_decoded_loss: 0.3509 - val_label_output_loss: 0.6887\n",
      "Epoch 33/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6755 - decoded_loss: 0.9855 - label_output_loss: 0.6900 - val_loss: 1.0352 - val_decoded_loss: 0.3466 - val_label_output_loss: 0.6886\n",
      "Epoch 34/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6731 - decoded_loss: 0.9831 - label_output_loss: 0.6900 - val_loss: 1.0427 - val_decoded_loss: 0.3539 - val_label_output_loss: 0.6887\n",
      "Epoch 35/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6682 - decoded_loss: 0.9783 - label_output_loss: 0.6900 - val_loss: 1.0380 - val_decoded_loss: 0.3493 - val_label_output_loss: 0.6887\n",
      "Epoch 36/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6658 - decoded_loss: 0.9759 - label_output_loss: 0.6899 - val_loss: 1.0549 - val_decoded_loss: 0.3662 - val_label_output_loss: 0.6886\n",
      "Epoch 37/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6662 - decoded_loss: 0.9763 - label_output_loss: 0.6899 - val_loss: 1.0473 - val_decoded_loss: 0.3587 - val_label_output_loss: 0.6886\n",
      "Epoch 38/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6677 - decoded_loss: 0.9777 - label_output_loss: 0.6899 - val_loss: 1.0538 - val_decoded_loss: 0.3651 - val_label_output_loss: 0.6887\n",
      "Epoch 39/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6548 - decoded_loss: 0.9649 - label_output_loss: 0.6899 - val_loss: 1.0499 - val_decoded_loss: 0.3612 - val_label_output_loss: 0.6887\n",
      "Epoch 40/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6598 - decoded_loss: 0.9698 - label_output_loss: 0.6899 - val_loss: 1.0616 - val_decoded_loss: 0.3730 - val_label_output_loss: 0.6886\n",
      "Epoch 41/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6554 - decoded_loss: 0.9656 - label_output_loss: 0.6899 - val_loss: 1.0532 - val_decoded_loss: 0.3645 - val_label_output_loss: 0.6887\n",
      "Epoch 42/1000\n",
      "691/691 [==============================] - 5s 7ms/step - loss: 1.6629 - decoded_loss: 0.9730 - label_output_loss: 0.6899 - val_loss: 1.0813 - val_decoded_loss: 0.3927 - val_label_output_loss: 0.6886\n",
      "Epoch 43/1000\n",
      "691/691 [==============================] - 4s 6ms/step - loss: 1.6518 - decoded_loss: 0.9619 - label_output_loss: 0.6899 - val_loss: 1.0711 - val_decoded_loss: 0.3826 - val_label_output_loss: 0.6885\n"
     ]
    }
   ],
   "source": [
    "autoencoder, encoder = create_autoencoder(X.shape[-1],y.shape[-1],noise=0.1)\n",
    "autoencoder.fit(X,(X,y),\n",
    "                epochs=1000,\n",
    "                batch_size=2048, \n",
    "                validation_split=0.1,\n",
    "                callbacks=[tf.keras.callbacks.EarlyStopping('val_loss',patience=10,restore_best_weights=True)])\n",
    "encoder.save_weights('./encoder.hdf5')\n",
    "encoder.trainable = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.220591,
     "end_time": "2021-02-18T04:33:45.021934",
     "exception": false,
     "start_time": "2021-02-18T04:33:43.801343",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "_cell_guid": "79c7e3d0-c299-4dcb-8224-4455121ee9b0",
    "_uuid": "d629ff2d2480ee46fbb7e2d37f6b5fab8052498a",
    "execution": {
     "iopub.execute_input": "2021-02-18T04:33:47.402706Z",
     "iopub.status.busy": "2021-02-18T04:33:47.401799Z",
     "iopub.status.idle": "2021-02-18T04:33:47.416348Z",
     "shell.execute_reply": "2021-02-18T04:33:47.415854Z"
    },
    "papermill": {
     "duration": 1.205907,
     "end_time": "2021-02-18T04:33:47.416464",
     "exception": false,
     "start_time": "2021-02-18T04:33:46.210557",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_1dcnn(input_dim, output_dim, encoder):\n",
    "    # input\n",
    "    inputs = tf.keras.layers.Input(input_dim)\n",
    "    \n",
    "    x = encoder(inputs)\n",
    "    x = tf.keras.layers.Concatenate()([x,inputs]) #use both raw and encoded features\n",
    "    \n",
    "    # normalize\n",
    "    x = tf.keras.layers.BatchNormalization()(x)\n",
    "    \n",
    "    # 1dcnn\n",
    "    x = tf.keras.layers.Dense(4096, activation='relu')(x)\n",
    "    x = tf.keras.layers.Reshape((256, 16))(x)\n",
    "    x = tf.keras.layers.Conv1D(filters=16,\n",
    "                      kernel_size=7,\n",
    "                      strides=1,\n",
    "                      activation='relu')(x)\n",
    "    x = tf.keras.layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = tf.keras.layers.Flatten()(x)\n",
    "    \n",
    "    # ffn\n",
    "    for i in range(2):\n",
    "        x = tf.keras.layers.Dense(256 // (2 ** i), activation='relu')(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.GaussianNoise(0.01)(x)\n",
    "        x = tf.keras.layers.Dropout(0.2)(x)\n",
    "    x = tf.keras.layers.Dense(output_dim, activation='sigmoid')(x)\n",
    "    \n",
    "    model = tf.keras.models.Model(inputs=inputs,outputs=x)\n",
    "    \n",
    "    # compile\n",
    "    opt = tfa.optimizers.RectifiedAdam(learning_rate=1e-03)\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "    loss = tf.keras.losses.BinaryCrossentropy(label_smoothing=1e-02)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=loss, \n",
    "                  metrics=[tf.keras.metrics.AUC(name = 'auc')])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:33:50.027780Z",
     "iopub.status.busy": "2021-02-18T04:33:50.026960Z",
     "iopub.status.idle": "2021-02-18T04:33:50.029676Z",
     "shell.execute_reply": "2021-02-18T04:33:50.030254Z"
    },
    "papermill": {
     "duration": 1.356488,
     "end_time": "2021-02-18T04:33:50.030427",
     "exception": false,
     "start_time": "2021-02-18T04:33:48.673939",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_resnet(n_features, n_labels, encoder, label_smoothing = 0.0005):    \n",
    "    input_1 = tf.keras.layers.Input(shape = (n_features,))\n",
    "    input_2 = encoder(input_1)\n",
    "\n",
    "    head_1 = tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(512, activation=\"elu\"), \n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.4),\n",
    "        tf.keras.layers.Dense(256, activation = \"elu\")\n",
    "        ],name='Head1') \n",
    "\n",
    "    input_3 = head_1(input_1)\n",
    "    input_3_concat = tf.keras.layers.Concatenate()([input_2, input_3])\n",
    "\n",
    "    head_2 = tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(512, \"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(512, \"elu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(256, \"relu\"),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.3),\n",
    "        tf.keras.layers.Dense(256, \"elu\")\n",
    "        ],name='Head2')\n",
    "\n",
    "    input_4 = head_2(input_3_concat)\n",
    "    input_4_avg = tf.keras.layers.Average()([input_3, input_4]) \n",
    "\n",
    "    head_3 = tf.keras.Sequential([\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dense(256, kernel_initializer='lecun_normal', activation='selu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Dense(128, kernel_initializer='lecun_normal', activation='selu'),\n",
    "        tf.keras.layers.BatchNormalization(),\n",
    "        tf.keras.layers.Dropout(0.2),\n",
    "        tf.keras.layers.Lambda(lambda x: tf.math.l2_normalize(x, axis=1), name='l2_norm'),\n",
    "        tf.keras.layers.Dense(n_labels, activation=\"sigmoid\")\n",
    "        ],name='Head3')\n",
    "\n",
    "    output = head_3(input_4_avg)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs = [input_1, ], outputs = output)\n",
    "    opt = tfa.optimizers.RectifiedAdam(learning_rate=1e-03)\n",
    "    opt = tfa.optimizers.SWA(opt)\n",
    "    model.compile(optimizer=opt, \n",
    "                  loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing), \n",
    "                  metrics=['AUC'])\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:33:52.422606Z",
     "iopub.status.busy": "2021-02-18T04:33:52.421661Z",
     "iopub.status.idle": "2021-02-18T04:33:52.424177Z",
     "shell.execute_reply": "2021-02-18T04:33:52.424793Z"
    },
    "papermill": {
     "duration": 1.192223,
     "end_time": "2021-02-18T04:33:52.424919",
     "exception": false,
     "start_time": "2021-02-18T04:33:51.232696",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def create_mlp(\n",
    "    num_columns, num_labels, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "):\n",
    "\n",
    "    inp = tf.keras.layers.Input(shape=(num_columns,))\n",
    "    x = tf.keras.layers.BatchNormalization()(inp)\n",
    "    x = tf.keras.layers.Dropout(dropout_rates[0])(x)\n",
    "    for i in range(len(hidden_units)):\n",
    "        x = tf.keras.layers.Dense(hidden_units[i])(x)\n",
    "        x = tf.keras.layers.BatchNormalization()(x)\n",
    "        x = tf.keras.layers.Activation(tf.keras.activations.swish)(x)\n",
    "        x = tf.keras.layers.Dropout(dropout_rates[i + 1])(x)\n",
    "    \n",
    "    x = tf.keras.layers.Dense(num_labels)(x)\n",
    "    out = tf.keras.layers.Activation(\"sigmoid\")(x)\n",
    "\n",
    "    model = tf.keras.models.Model(inputs=inp, outputs=out)\n",
    "    model.compile(\n",
    "        optimizer=tfa.optimizers.RectifiedAdam(learning_rate=learning_rate),\n",
    "        loss=tf.keras.losses.BinaryCrossentropy(label_smoothing=label_smoothing),\n",
    "        metrics=tf.keras.metrics.AUC(name=\"AUC\"),\n",
    "    )\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:33:54.838989Z",
     "iopub.status.busy": "2021-02-18T04:33:54.838078Z",
     "iopub.status.idle": "2021-02-18T04:33:54.841122Z",
     "shell.execute_reply": "2021-02-18T04:33:54.840649Z"
    },
    "papermill": {
     "duration": 1.20552,
     "end_time": "2021-02-18T04:33:54.841224",
     "exception": false,
     "start_time": "2021-02-18T04:33:53.635704",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "CV_STRATEGY = 'StratifiedGroupKFold' # StratifiedGroupKFold, GroupKFold, PurgedGroupTimeSeriesSplit**\n",
    "NN_NAME = 'mlp' # 1dcnn, resnet, mlp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.192365,
     "end_time": "2021-02-18T04:33:57.220061",
     "exception": false,
     "start_time": "2021-02-18T04:33:56.027696",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "# NN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "papermill": {
     "duration": 1.292855,
     "end_time": "2021-02-18T04:33:59.716077",
     "exception": false,
     "start_time": "2021-02-18T04:33:58.423222",
     "status": "completed"
    },
    "tags": []
   },
   "source": [
    "### Creating 1dcnn, Resnet, MLP\n",
    "Just put 1dcnn before fead-forward network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:34:02.910339Z",
     "iopub.status.busy": "2021-02-18T04:34:02.908352Z",
     "iopub.status.idle": "2021-02-18T04:34:02.911130Z",
     "shell.execute_reply": "2021-02-18T04:34:02.911735Z"
    },
    "papermill": {
     "duration": 1.854099,
     "end_time": "2021-02-18T04:34:02.911872",
     "exception": false,
     "start_time": "2021-02-18T04:34:01.057773",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "X_train = train.loc[:, train.columns.str.contains('feature')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:34:05.310415Z",
     "iopub.status.busy": "2021-02-18T04:34:05.308143Z",
     "iopub.status.idle": "2021-02-18T04:44:39.616757Z",
     "shell.execute_reply": "2021-02-18T04:44:39.616162Z"
    },
    "papermill": {
     "duration": 635.514885,
     "end_time": "2021-02-18T04:44:39.616881",
     "exception": false,
     "start_time": "2021-02-18T04:34:04.101996",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/200\n",
      "384/384 - 3s - loss: 0.7172 - AUC: 0.5121\n",
      "Epoch 2/200\n",
      "384/384 - 5s - loss: 0.6946 - AUC: 0.5272\n",
      "Epoch 3/200\n",
      "384/384 - 3s - loss: 0.6914 - AUC: 0.5343\n",
      "Epoch 4/200\n",
      "384/384 - 3s - loss: 0.6904 - AUC: 0.5380\n",
      "Epoch 5/200\n",
      "384/384 - 3s - loss: 0.6900 - AUC: 0.5409\n",
      "Epoch 6/200\n",
      "384/384 - 3s - loss: 0.6897 - AUC: 0.5427\n",
      "Epoch 7/200\n",
      "384/384 - 4s - loss: 0.6894 - AUC: 0.5445\n",
      "Epoch 8/200\n",
      "384/384 - 3s - loss: 0.6892 - AUC: 0.5457\n",
      "Epoch 9/200\n",
      "384/384 - 3s - loss: 0.6890 - AUC: 0.5467\n",
      "Epoch 10/200\n",
      "384/384 - 3s - loss: 0.6889 - AUC: 0.5476\n",
      "Epoch 11/200\n",
      "384/384 - 3s - loss: 0.6887 - AUC: 0.5484\n",
      "Epoch 12/200\n",
      "384/384 - 3s - loss: 0.6886 - AUC: 0.5492\n",
      "Epoch 13/200\n",
      "384/384 - 3s - loss: 0.6884 - AUC: 0.5501\n",
      "Epoch 14/200\n",
      "384/384 - 3s - loss: 0.6883 - AUC: 0.5505\n",
      "Epoch 15/200\n",
      "384/384 - 3s - loss: 0.6881 - AUC: 0.5509\n",
      "Epoch 16/200\n",
      "384/384 - 4s - loss: 0.6880 - AUC: 0.5515\n",
      "Epoch 17/200\n",
      "384/384 - 3s - loss: 0.6879 - AUC: 0.5519\n",
      "Epoch 18/200\n",
      "384/384 - 4s - loss: 0.6878 - AUC: 0.5525\n",
      "Epoch 19/200\n",
      "384/384 - 3s - loss: 0.6876 - AUC: 0.5534\n",
      "Epoch 20/200\n",
      "384/384 - 3s - loss: 0.6876 - AUC: 0.5536\n",
      "Epoch 21/200\n",
      "384/384 - 3s - loss: 0.6875 - AUC: 0.5538\n",
      "Epoch 22/200\n",
      "384/384 - 3s - loss: 0.6873 - AUC: 0.5545\n",
      "Epoch 23/200\n",
      "384/384 - 3s - loss: 0.6872 - AUC: 0.5547\n",
      "Epoch 24/200\n",
      "384/384 - 3s - loss: 0.6871 - AUC: 0.5553\n",
      "Epoch 25/200\n",
      "384/384 - 3s - loss: 0.6871 - AUC: 0.5554\n",
      "Epoch 26/200\n",
      "384/384 - 3s - loss: 0.6870 - AUC: 0.5557\n",
      "Epoch 27/200\n",
      "384/384 - 3s - loss: 0.6869 - AUC: 0.5563\n",
      "Epoch 28/200\n",
      "384/384 - 4s - loss: 0.6867 - AUC: 0.5568\n",
      "Epoch 29/200\n",
      "384/384 - 3s - loss: 0.6866 - AUC: 0.5567\n",
      "Epoch 30/200\n",
      "384/384 - 3s - loss: 0.6867 - AUC: 0.5568\n",
      "Epoch 31/200\n",
      "384/384 - 3s - loss: 0.6866 - AUC: 0.5571\n",
      "Epoch 32/200\n",
      "384/384 - 3s - loss: 0.6864 - AUC: 0.5576\n",
      "Epoch 33/200\n",
      "384/384 - 3s - loss: 0.6863 - AUC: 0.5577\n",
      "Epoch 34/200\n",
      "384/384 - 3s - loss: 0.6863 - AUC: 0.5584\n",
      "Epoch 35/200\n",
      "384/384 - 3s - loss: 0.6862 - AUC: 0.5583\n",
      "Epoch 36/200\n",
      "384/384 - 3s - loss: 0.6862 - AUC: 0.5583\n",
      "Epoch 37/200\n",
      "384/384 - 3s - loss: 0.6860 - AUC: 0.5590\n",
      "Epoch 38/200\n",
      "384/384 - 3s - loss: 0.6861 - AUC: 0.5586\n",
      "Epoch 39/200\n",
      "384/384 - 4s - loss: 0.6860 - AUC: 0.5590\n",
      "Epoch 40/200\n",
      "384/384 - 3s - loss: 0.6859 - AUC: 0.5591\n",
      "Epoch 41/200\n",
      "384/384 - 3s - loss: 0.6859 - AUC: 0.5593\n",
      "Epoch 42/200\n",
      "384/384 - 3s - loss: 0.6858 - AUC: 0.5593\n",
      "Epoch 43/200\n",
      "384/384 - 3s - loss: 0.6857 - AUC: 0.5599\n",
      "Epoch 44/200\n",
      "384/384 - 3s - loss: 0.6857 - AUC: 0.5596\n",
      "Epoch 45/200\n",
      "384/384 - 3s - loss: 0.6856 - AUC: 0.5599\n",
      "Epoch 46/200\n",
      "384/384 - 3s - loss: 0.6856 - AUC: 0.5599\n",
      "Epoch 47/200\n",
      "384/384 - 3s - loss: 0.6855 - AUC: 0.5600\n",
      "Epoch 48/200\n",
      "384/384 - 3s - loss: 0.6855 - AUC: 0.5604\n",
      "Epoch 49/200\n",
      "384/384 - 3s - loss: 0.6854 - AUC: 0.5608\n",
      "Epoch 50/200\n",
      "384/384 - 4s - loss: 0.6854 - AUC: 0.5606\n",
      "Epoch 51/200\n",
      "384/384 - 3s - loss: 0.6854 - AUC: 0.5608\n",
      "Epoch 52/200\n",
      "384/384 - 3s - loss: 0.6853 - AUC: 0.5610\n",
      "Epoch 53/200\n",
      "384/384 - 3s - loss: 0.6853 - AUC: 0.5610\n",
      "Epoch 54/200\n",
      "384/384 - 3s - loss: 0.6852 - AUC: 0.5613\n",
      "Epoch 55/200\n",
      "384/384 - 3s - loss: 0.6852 - AUC: 0.5615\n",
      "Epoch 56/200\n",
      "384/384 - 3s - loss: 0.6851 - AUC: 0.5617\n",
      "Epoch 57/200\n",
      "384/384 - 3s - loss: 0.6851 - AUC: 0.5616\n",
      "Epoch 58/200\n",
      "384/384 - 3s - loss: 0.6851 - AUC: 0.5615\n",
      "Epoch 59/200\n",
      "384/384 - 3s - loss: 0.6851 - AUC: 0.5613\n",
      "Epoch 60/200\n",
      "384/384 - 3s - loss: 0.6850 - AUC: 0.5620\n",
      "Epoch 61/200\n",
      "384/384 - 4s - loss: 0.6849 - AUC: 0.5622\n",
      "Epoch 62/200\n",
      "384/384 - 3s - loss: 0.6848 - AUC: 0.5624\n",
      "Epoch 63/200\n",
      "384/384 - 3s - loss: 0.6849 - AUC: 0.5624\n",
      "Epoch 64/200\n",
      "384/384 - 3s - loss: 0.6848 - AUC: 0.5626\n",
      "Epoch 65/200\n",
      "384/384 - 3s - loss: 0.6848 - AUC: 0.5623\n",
      "Epoch 66/200\n",
      "384/384 - 3s - loss: 0.6848 - AUC: 0.5623\n",
      "Epoch 67/200\n",
      "384/384 - 3s - loss: 0.6847 - AUC: 0.5631\n",
      "Epoch 68/200\n",
      "384/384 - 3s - loss: 0.6847 - AUC: 0.5630\n",
      "Epoch 69/200\n",
      "384/384 - 3s - loss: 0.6846 - AUC: 0.5628\n",
      "Epoch 70/200\n",
      "384/384 - 3s - loss: 0.6846 - AUC: 0.5630\n",
      "Epoch 71/200\n",
      "384/384 - 3s - loss: 0.6846 - AUC: 0.5631\n",
      "Epoch 72/200\n",
      "384/384 - 4s - loss: 0.6845 - AUC: 0.5634\n",
      "Epoch 73/200\n",
      "384/384 - 3s - loss: 0.6845 - AUC: 0.5632\n",
      "Epoch 74/200\n",
      "384/384 - 3s - loss: 0.6845 - AUC: 0.5633\n",
      "Epoch 75/200\n",
      "384/384 - 3s - loss: 0.6845 - AUC: 0.5637\n",
      "Epoch 76/200\n",
      "384/384 - 3s - loss: 0.6844 - AUC: 0.5637\n",
      "Epoch 77/200\n",
      "384/384 - 3s - loss: 0.6844 - AUC: 0.5635\n",
      "Epoch 78/200\n",
      "384/384 - 3s - loss: 0.6845 - AUC: 0.5633\n",
      "Epoch 79/200\n",
      "384/384 - 4s - loss: 0.6843 - AUC: 0.5640\n",
      "Epoch 80/200\n",
      "384/384 - 3s - loss: 0.6844 - AUC: 0.5637\n",
      "Epoch 81/200\n",
      "384/384 - 3s - loss: 0.6844 - AUC: 0.5640\n",
      "Epoch 82/200\n",
      "384/384 - 3s - loss: 0.6843 - AUC: 0.5640\n",
      "Epoch 83/200\n",
      "384/384 - 4s - loss: 0.6843 - AUC: 0.5640\n",
      "Epoch 84/200\n",
      "384/384 - 3s - loss: 0.6843 - AUC: 0.5639\n",
      "Epoch 85/200\n",
      "384/384 - 3s - loss: 0.6842 - AUC: 0.5643\n",
      "Epoch 86/200\n",
      "384/384 - 3s - loss: 0.6842 - AUC: 0.5642\n",
      "Epoch 87/200\n",
      "384/384 - 3s - loss: 0.6842 - AUC: 0.5644\n",
      "Epoch 88/200\n",
      "384/384 - 3s - loss: 0.6842 - AUC: 0.5644\n",
      "Epoch 89/200\n",
      "384/384 - 3s - loss: 0.6841 - AUC: 0.5646\n",
      "Epoch 90/200\n",
      "384/384 - 4s - loss: 0.6841 - AUC: 0.5645\n",
      "Epoch 91/200\n",
      "384/384 - 3s - loss: 0.6841 - AUC: 0.5643\n",
      "Epoch 92/200\n",
      "384/384 - 3s - loss: 0.6840 - AUC: 0.5648\n",
      "Epoch 93/200\n",
      "384/384 - 3s - loss: 0.6840 - AUC: 0.5648\n",
      "Epoch 94/200\n",
      "384/384 - 4s - loss: 0.6840 - AUC: 0.5648\n",
      "Epoch 95/200\n",
      "384/384 - 3s - loss: 0.6841 - AUC: 0.5644\n",
      "Epoch 96/200\n",
      "384/384 - 3s - loss: 0.6839 - AUC: 0.5650\n",
      "Epoch 97/200\n",
      "384/384 - 3s - loss: 0.6839 - AUC: 0.5649\n",
      "Epoch 98/200\n",
      "384/384 - 3s - loss: 0.6840 - AUC: 0.5649\n",
      "Epoch 99/200\n",
      "384/384 - 3s - loss: 0.6839 - AUC: 0.5653\n",
      "Epoch 100/200\n",
      "384/384 - 3s - loss: 0.6840 - AUC: 0.5648\n",
      "Epoch 101/200\n",
      "384/384 - 3s - loss: 0.6838 - AUC: 0.5654\n",
      "Epoch 102/200\n",
      "384/384 - 3s - loss: 0.6839 - AUC: 0.5652\n",
      "Epoch 103/200\n",
      "384/384 - 3s - loss: 0.6838 - AUC: 0.5653\n",
      "Epoch 104/200\n",
      "384/384 - 3s - loss: 0.6838 - AUC: 0.5654\n",
      "Epoch 105/200\n",
      "384/384 - 4s - loss: 0.6839 - AUC: 0.5650\n",
      "Epoch 106/200\n",
      "384/384 - 3s - loss: 0.6837 - AUC: 0.5655\n",
      "Epoch 107/200\n",
      "384/384 - 3s - loss: 0.6837 - AUC: 0.5655\n",
      "Epoch 108/200\n",
      "384/384 - 3s - loss: 0.6837 - AUC: 0.5658\n",
      "Epoch 109/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5656\n",
      "Epoch 110/200\n",
      "384/384 - 3s - loss: 0.6837 - AUC: 0.5655\n",
      "Epoch 111/200\n",
      "384/384 - 4s - loss: 0.6837 - AUC: 0.5658\n",
      "Epoch 112/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5660\n",
      "Epoch 113/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5659\n",
      "Epoch 114/200\n",
      "384/384 - 3s - loss: 0.6837 - AUC: 0.5658\n",
      "Epoch 115/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5661\n",
      "Epoch 116/200\n",
      "384/384 - 4s - loss: 0.6836 - AUC: 0.5658\n",
      "Epoch 117/200\n",
      "384/384 - 3s - loss: 0.6837 - AUC: 0.5658\n",
      "Epoch 118/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5659\n",
      "Epoch 119/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5657\n",
      "Epoch 120/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5660\n",
      "Epoch 121/200\n",
      "384/384 - 3s - loss: 0.6836 - AUC: 0.5662\n",
      "Epoch 122/200\n",
      "384/384 - 3s - loss: 0.6835 - AUC: 0.5660\n",
      "Epoch 123/200\n",
      "384/384 - 3s - loss: 0.6835 - AUC: 0.5665\n",
      "Epoch 124/200\n",
      "384/384 - 3s - loss: 0.6835 - AUC: 0.5664\n",
      "Epoch 125/200\n",
      "384/384 - 3s - loss: 0.6835 - AUC: 0.5663\n",
      "Epoch 126/200\n",
      "384/384 - 3s - loss: 0.6835 - AUC: 0.5662\n",
      "Epoch 127/200\n",
      "384/384 - 4s - loss: 0.6834 - AUC: 0.5665\n",
      "Epoch 128/200\n",
      "384/384 - 3s - loss: 0.6835 - AUC: 0.5660\n",
      "Epoch 129/200\n",
      "384/384 - 3s - loss: 0.6834 - AUC: 0.5666\n",
      "Epoch 130/200\n",
      "384/384 - 3s - loss: 0.6834 - AUC: 0.5667\n",
      "Epoch 131/200\n",
      "384/384 - 3s - loss: 0.6834 - AUC: 0.5663\n",
      "Epoch 132/200\n",
      "384/384 - 4s - loss: 0.6834 - AUC: 0.5664\n",
      "Epoch 133/200\n",
      "384/384 - 3s - loss: 0.6833 - AUC: 0.5665\n",
      "Epoch 134/200\n",
      "384/384 - 3s - loss: 0.6834 - AUC: 0.5664\n",
      "Epoch 135/200\n",
      "384/384 - 3s - loss: 0.6833 - AUC: 0.5669\n",
      "Epoch 136/200\n",
      "384/384 - 3s - loss: 0.6833 - AUC: 0.5672\n",
      "Epoch 137/200\n",
      "384/384 - 3s - loss: 0.6833 - AUC: 0.5666\n",
      "Epoch 138/200\n",
      "384/384 - 4s - loss: 0.6833 - AUC: 0.5670\n",
      "Epoch 139/200\n",
      "384/384 - 3s - loss: 0.6833 - AUC: 0.5664\n",
      "Epoch 140/200\n",
      "384/384 - 3s - loss: 0.6832 - AUC: 0.5670\n",
      "Epoch 141/200\n",
      "384/384 - 3s - loss: 0.6833 - AUC: 0.5669\n",
      "Epoch 142/200\n",
      "384/384 - 3s - loss: 0.6832 - AUC: 0.5669\n",
      "Epoch 143/200\n",
      "384/384 - 3s - loss: 0.6832 - AUC: 0.5674\n",
      "Epoch 144/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5674\n",
      "Epoch 145/200\n",
      "384/384 - 3s - loss: 0.6832 - AUC: 0.5672\n",
      "Epoch 146/200\n",
      "384/384 - 3s - loss: 0.6832 - AUC: 0.5671\n",
      "Epoch 147/200\n",
      "384/384 - 3s - loss: 0.6830 - AUC: 0.5676\n",
      "Epoch 148/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5669\n",
      "Epoch 149/200\n",
      "384/384 - 4s - loss: 0.6832 - AUC: 0.5670\n",
      "Epoch 150/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5675\n",
      "Epoch 151/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5674\n",
      "Epoch 152/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5675\n",
      "Epoch 153/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5675\n",
      "Epoch 154/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5676\n",
      "Epoch 155/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5675\n",
      "Epoch 156/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5674\n",
      "Epoch 157/200\n",
      "384/384 - 3s - loss: 0.6831 - AUC: 0.5673\n",
      "Epoch 158/200\n",
      "384/384 - 3s - loss: 0.6830 - AUC: 0.5677\n",
      "Epoch 159/200\n",
      "384/384 - 3s - loss: 0.6830 - AUC: 0.5675\n",
      "Epoch 160/200\n",
      "384/384 - 4s - loss: 0.6830 - AUC: 0.5673\n",
      "Epoch 161/200\n",
      "384/384 - 3s - loss: 0.6830 - AUC: 0.5676\n",
      "Epoch 162/200\n",
      "384/384 - 3s - loss: 0.6830 - AUC: 0.5675\n",
      "Epoch 163/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5680\n",
      "Epoch 164/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5680\n",
      "Epoch 165/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5675\n",
      "Epoch 166/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5675\n",
      "Epoch 167/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5678\n",
      "Epoch 168/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5678\n",
      "Epoch 169/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5680\n",
      "Epoch 170/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5680\n",
      "Epoch 171/200\n",
      "384/384 - 4s - loss: 0.6828 - AUC: 0.5684\n",
      "Epoch 172/200\n",
      "384/384 - 3s - loss: 0.6828 - AUC: 0.5683\n",
      "Epoch 173/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5679\n",
      "Epoch 174/200\n",
      "384/384 - 3s - loss: 0.6828 - AUC: 0.5684\n",
      "Epoch 175/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5679\n",
      "Epoch 176/200\n",
      "384/384 - 3s - loss: 0.6828 - AUC: 0.5679\n",
      "Epoch 177/200\n",
      "384/384 - 3s - loss: 0.6828 - AUC: 0.5682\n",
      "Epoch 178/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5685\n",
      "Epoch 179/200\n",
      "384/384 - 3s - loss: 0.6828 - AUC: 0.5685\n",
      "Epoch 180/200\n",
      "384/384 - 3s - loss: 0.6828 - AUC: 0.5681\n",
      "Epoch 181/200\n",
      "384/384 - 3s - loss: 0.6828 - AUC: 0.5683\n",
      "Epoch 182/200\n",
      "384/384 - 4s - loss: 0.6828 - AUC: 0.5681\n",
      "Epoch 183/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5685\n",
      "Epoch 184/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5685\n",
      "Epoch 185/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5685\n",
      "Epoch 186/200\n",
      "384/384 - 3s - loss: 0.6829 - AUC: 0.5678\n",
      "Epoch 187/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5687\n",
      "Epoch 188/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5687\n",
      "Epoch 189/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5683\n",
      "Epoch 190/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5682\n",
      "Epoch 191/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5688\n",
      "Epoch 192/200\n",
      "384/384 - 3s - loss: 0.6827 - AUC: 0.5688\n",
      "Epoch 193/200\n",
      "384/384 - 4s - loss: 0.6827 - AUC: 0.5687\n",
      "Epoch 194/200\n",
      "384/384 - 3s - loss: 0.6825 - AUC: 0.5690\n",
      "Epoch 195/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5686\n",
      "Epoch 196/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5687\n",
      "Epoch 197/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5685\n",
      "Epoch 198/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5688\n",
      "Epoch 199/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5688\n",
      "Epoch 200/200\n",
      "384/384 - 3s - loss: 0.6826 - AUC: 0.5689\n"
     ]
    }
   ],
   "source": [
    "epochs = 200\n",
    "batch_size = 4096\n",
    "hidden_units = [160, 160, 160]\n",
    "dropout_rates = [0.2, 0.2, 0.2, 0.2]\n",
    "label_smoothing = 1e-2\n",
    "learning_rate = 1e-3\n",
    "\n",
    "tf.keras.backend.clear_session()\n",
    "tf.random.set_seed(SEED)\n",
    "clf = create_mlp(\n",
    "    len(features), 5, hidden_units, dropout_rates, label_smoothing, learning_rate\n",
    "    )\n",
    "\n",
    "clf.fit(X_train, y, epochs=epochs, batch_size=batch_size, verbose=2)\n",
    "\n",
    "# save model\n",
    "clf.save(f'model.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:44:42.228392Z",
     "iopub.status.busy": "2021-02-18T04:44:42.227424Z",
     "iopub.status.idle": "2021-02-18T04:44:42.230471Z",
     "shell.execute_reply": "2021-02-18T04:44:42.229958Z"
    },
    "papermill": {
     "duration": 1.311848,
     "end_time": "2021-02-18T04:44:42.230576",
     "exception": false,
     "start_time": "2021-02-18T04:44:40.918728",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "del X_train"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:44:44.899015Z",
     "iopub.status.busy": "2021-02-18T04:44:44.897758Z",
     "iopub.status.idle": "2021-02-18T04:50:32.142578Z",
     "shell.execute_reply": "2021-02-18T04:50:32.139698Z"
    },
    "papermill": {
     "duration": 348.570292,
     "end_time": "2021-02-18T04:50:32.142720",
     "exception": false,
     "start_time": "2021-02-18T04:44:43.572428",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "0it [00:00, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "615/615 [==============================] - 9s 15ms/step - loss: 0.6831 - AUC: 0.5672 - val_loss: 0.6789 - val_AUC: 0.5845\n",
      "Epoch 2/192\n",
      "615/615 [==============================] - 8s 13ms/step - loss: 0.6829 - AUC: 0.5679 - val_loss: 0.6794 - val_AUC: 0.5827\n",
      "Epoch 3/192\n",
      "615/615 [==============================] - 5s 9ms/step - loss: 0.6828 - AUC: 0.5681 - val_loss: 0.6800 - val_AUC: 0.5808\n",
      "Epoch 4/192\n",
      "615/615 [==============================] - 6s 9ms/step - loss: 0.6827 - AUC: 0.5687 - val_loss: 0.6802 - val_AUC: 0.5802\n",
      "Epoch 5/192\n",
      "615/615 [==============================] - 5s 8ms/step - loss: 0.6826 - AUC: 0.5687 - val_loss: 0.6806 - val_AUC: 0.5783\n",
      "Epoch 6/192\n",
      "615/615 [==============================] - 5s 9ms/step - loss: 0.6827 - AUC: 0.5683 - val_loss: 0.6807 - val_AUC: 0.5773\n",
      "Epoch 7/192\n",
      "615/615 [==============================] - 5s 8ms/step - loss: 0.6824 - AUC: 0.5694 - val_loss: 0.6811 - val_AUC: 0.5771\n",
      "Epoch 8/192\n",
      "615/615 [==============================] - 5s 8ms/step - loss: 0.6826 - AUC: 0.5688 - val_loss: 0.6813 - val_AUC: 0.5761\n",
      "Epoch 9/192\n",
      "615/615 [==============================] - ETA: 0s - loss: 0.6824 - AUC: 0.5693\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 0.00010000000474974513.\n",
      "615/615 [==============================] - 5s 8ms/step - loss: 0.6824 - AUC: 0.5693 - val_loss: 0.6813 - val_AUC: 0.5755\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "1it [01:01, 61.05s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "614/614 [==============================] - 6s 10ms/step - loss: 0.6829 - AUC: 0.5683 - val_loss: 0.6771 - val_AUC: 0.5890\n",
      "Epoch 2/192\n",
      "614/614 [==============================] - 8s 14ms/step - loss: 0.6826 - AUC: 0.5689 - val_loss: 0.6771 - val_AUC: 0.5885\n",
      "Epoch 3/192\n",
      "614/614 [==============================] - 5s 9ms/step - loss: 0.6825 - AUC: 0.5697 - val_loss: 0.6772 - val_AUC: 0.5882\n",
      "Epoch 4/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5691 - val_loss: 0.6774 - val_AUC: 0.5877\n",
      "Epoch 5/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5692 - val_loss: 0.6776 - val_AUC: 0.5873\n",
      "Epoch 6/192\n",
      "614/614 [==============================] - 6s 9ms/step - loss: 0.6823 - AUC: 0.5698 - val_loss: 0.6775 - val_AUC: 0.5870\n",
      "Epoch 7/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6823 - AUC: 0.5701 - val_loss: 0.6776 - val_AUC: 0.5868\n",
      "Epoch 8/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6822 - AUC: 0.5701 - val_loss: 0.6777 - val_AUC: 0.5868\n",
      "Epoch 9/192\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6823 - AUC: 0.5698\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000474974514e-05.\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6823 - AUC: 0.5698 - val_loss: 0.6777 - val_AUC: 0.5863\n",
      "Epoch 10/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6822 - AUC: 0.5701 - val_loss: 0.6778 - val_AUC: 0.5862\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2it [01:59, 60.33s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6826 - AUC: 0.5683 - val_loss: 0.6768 - val_AUC: 0.5928\n",
      "Epoch 2/192\n",
      "614/614 [==============================] - 9s 14ms/step - loss: 0.6826 - AUC: 0.5685 - val_loss: 0.6770 - val_AUC: 0.5926\n",
      "Epoch 3/192\n",
      "614/614 [==============================] - 5s 9ms/step - loss: 0.6826 - AUC: 0.5686 - val_loss: 0.6771 - val_AUC: 0.5923\n",
      "Epoch 4/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5690 - val_loss: 0.6769 - val_AUC: 0.5927\n",
      "Epoch 5/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5687 - val_loss: 0.6771 - val_AUC: 0.5923\n",
      "Epoch 6/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5688 - val_loss: 0.6771 - val_AUC: 0.5923\n",
      "Epoch 7/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6824 - AUC: 0.5694 - val_loss: 0.6770 - val_AUC: 0.5924\n",
      "Epoch 8/192\n",
      "614/614 [==============================] - 6s 10ms/step - loss: 0.6824 - AUC: 0.5690 - val_loss: 0.6770 - val_AUC: 0.5924\n",
      "Epoch 9/192\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6823 - AUC: 0.5691\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.0000000656873453e-06.\n",
      "614/614 [==============================] - 5s 9ms/step - loss: 0.6823 - AUC: 0.5691 - val_loss: 0.6771 - val_AUC: 0.5922\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "3it [02:53, 58.35s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "615/615 [==============================] - 5s 9ms/step - loss: 0.6825 - AUC: 0.5690 - val_loss: 0.6772 - val_AUC: 0.5898\n",
      "Epoch 2/192\n",
      "615/615 [==============================] - 8s 13ms/step - loss: 0.6825 - AUC: 0.5692 - val_loss: 0.6772 - val_AUC: 0.5898\n",
      "Epoch 3/192\n",
      "615/615 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5695 - val_loss: 0.6772 - val_AUC: 0.5898\n",
      "Epoch 4/192\n",
      "615/615 [==============================] - 6s 10ms/step - loss: 0.6825 - AUC: 0.5692 - val_loss: 0.6772 - val_AUC: 0.5900\n",
      "Epoch 5/192\n",
      "615/615 [==============================] - 6s 9ms/step - loss: 0.6824 - AUC: 0.5695 - val_loss: 0.6771 - val_AUC: 0.5901\n",
      "Epoch 6/192\n",
      "615/615 [==============================] - 5s 8ms/step - loss: 0.6826 - AUC: 0.5688 - val_loss: 0.6772 - val_AUC: 0.5899\n",
      "Epoch 7/192\n",
      "615/615 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5691 - val_loss: 0.6772 - val_AUC: 0.5899\n",
      "Epoch 8/192\n",
      "615/615 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5689 - val_loss: 0.6772 - val_AUC: 0.5899\n",
      "Epoch 9/192\n",
      "615/615 [==============================] - 5s 9ms/step - loss: 0.6824 - AUC: 0.5697 - val_loss: 0.6772 - val_AUC: 0.5899\n",
      "Epoch 10/192\n",
      "615/615 [==============================] - 6s 10ms/step - loss: 0.6826 - AUC: 0.5691 - val_loss: 0.6772 - val_AUC: 0.5898\n",
      "Epoch 11/192\n",
      "615/615 [==============================] - 5s 9ms/step - loss: 0.6824 - AUC: 0.5695 - val_loss: 0.6772 - val_AUC: 0.5898\n",
      "Epoch 12/192\n",
      "615/615 [==============================] - 5s 8ms/step - loss: 0.6824 - AUC: 0.5696 - val_loss: 0.6773 - val_AUC: 0.5898\n",
      "Epoch 13/192\n",
      "613/615 [============================>.] - ETA: 0s - loss: 0.6825 - AUC: 0.5693\n",
      "Epoch 00013: ReduceLROnPlateau reducing learning rate to 1.0000001111620805e-07.\n",
      "615/615 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5693 - val_loss: 0.6772 - val_AUC: 0.5898\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "4it [04:08, 63.42s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6826 - AUC: 0.5691 - val_loss: 0.6771 - val_AUC: 0.5881\n",
      "Epoch 2/192\n",
      "614/614 [==============================] - 9s 15ms/step - loss: 0.6825 - AUC: 0.5697 - val_loss: 0.6771 - val_AUC: 0.5882\n",
      "Epoch 3/192\n",
      "614/614 [==============================] - 7s 11ms/step - loss: 0.6824 - AUC: 0.5697 - val_loss: 0.6771 - val_AUC: 0.5881\n",
      "Epoch 4/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5696 - val_loss: 0.6772 - val_AUC: 0.5879\n",
      "Epoch 5/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6824 - AUC: 0.5695 - val_loss: 0.6772 - val_AUC: 0.5880\n",
      "Epoch 6/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5695 - val_loss: 0.6771 - val_AUC: 0.5880\n",
      "Epoch 7/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6824 - AUC: 0.5697 - val_loss: 0.6772 - val_AUC: 0.5880\n",
      "Epoch 8/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5695 - val_loss: 0.6772 - val_AUC: 0.5879\n",
      "Epoch 9/192\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6825 - AUC: 0.5694\n",
      "Epoch 00009: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-08.\n",
      "614/614 [==============================] - 7s 12ms/step - loss: 0.6825 - AUC: 0.5694 - val_loss: 0.6771 - val_AUC: 0.5880\n",
      "Epoch 10/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5694 - val_loss: 0.6771 - val_AUC: 0.5881\n",
      "Epoch 11/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5694 - val_loss: 0.6772 - val_AUC: 0.5881\n",
      "Epoch 12/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6824 - AUC: 0.5697 - val_loss: 0.6772 - val_AUC: 0.5880\n",
      "Epoch 13/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5696 - val_loss: 0.6772 - val_AUC: 0.5878\n",
      "Epoch 14/192\n",
      "614/614 [==============================] - 5s 8ms/step - loss: 0.6825 - AUC: 0.5696 - val_loss: 0.6771 - val_AUC: 0.5881\n",
      "Epoch 15/192\n",
      "614/614 [==============================] - 6s 9ms/step - loss: 0.6824 - AUC: 0.5698 - val_loss: 0.6772 - val_AUC: 0.5880\n",
      "Epoch 16/192\n",
      "614/614 [==============================] - 7s 11ms/step - loss: 0.6825 - AUC: 0.5696 - val_loss: 0.6771 - val_AUC: 0.5881\n",
      "Epoch 17/192\n",
      "614/614 [==============================] - ETA: 0s - loss: 0.6825 - AUC: 0.5696\n",
      "Epoch 00017: ReduceLROnPlateau reducing learning rate to 1.000000082740371e-09.\n",
      "614/614 [==============================] - 5s 9ms/step - loss: 0.6825 - AUC: 0.5696 - val_loss: 0.6771 - val_AUC: 0.5881\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5it [05:47, 69.44s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 5min 18s, sys: 22.7 s, total: 5min 41s\n",
      "Wall time: 5min 47s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "\n",
    "if CV_STRATEGY == 'PurgedGroupTimeSeriesSplit':\n",
    "    gkf = PurgedGroupTimeSeriesSplit(n_splits=FOLDS, group_gap=20)\n",
    "    splits = list(gkf.split(y, groups=train['date'].values))    \n",
    "    \n",
    "elif CV_STRATEGY == \"GroupKFold\":\n",
    "    cv = GroupKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "    splits = cv.split(train, train['resp'].values.astype(int), 'date')\n",
    "\n",
    "elif CV_STRATEGY ==  \"StratifiedGroupKFold\":\n",
    "    cv = StratifiedGroupKFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "    splits = cv.split(train, train['resp'].values.astype(int), 'date')\n",
    "\n",
    "models = []\n",
    "for fold, (train_indices, test_indices) in tqdm(enumerate(splits)):\n",
    "    X_train, X_test = X[train_indices], X[test_indices]\n",
    "    y_train, y_test = y[train_indices], y[test_indices]\n",
    "    \n",
    "    # model\n",
    "    tf.keras.backend.clear_session()\n",
    "    model = clf\n",
    "    \n",
    "    # callbacks\n",
    "    er = tf.keras.callbacks.EarlyStopping(patience=8, restore_best_weights=True, monitor='val_loss')\n",
    "    ReduceLR = tf.keras.callbacks.ReduceLROnPlateau(monitor='val_loss', factor=0.1, patience=8, verbose=1, mode='min')\n",
    "    model_checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(filepath=f'./model_{SEED}_{fold}.hdf5', save_weights_only=True, verbose=0, monitor='val_loss', save_best_only=True)\n",
    "    nn_callbacks = [er, ReduceLR, model_checkpoint_callback]\n",
    "    \n",
    "    # fit\n",
    "    model.fit(X_train, y_train, validation_data=(X_test,y_test), \n",
    "              epochs=192, batch_size=2048, callbacks=nn_callbacks)\n",
    "    models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:50:38.631896Z",
     "iopub.status.busy": "2021-02-18T04:50:38.631064Z",
     "iopub.status.idle": "2021-02-18T04:50:38.636966Z",
     "shell.execute_reply": "2021-02-18T04:50:38.637420Z"
    },
    "papermill": {
     "duration": 3.225336,
     "end_time": "2021-02-18T04:50:38.637557",
     "exception": false,
     "start_time": "2021-02-18T04:50:35.412221",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 s, sys: 0 ns, total: 4 s\n",
      "Wall time: 8.82 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if NN_NAME == '1dcnn':\n",
    "    models = []\n",
    "\n",
    "    for fold in range(FOLDS):\n",
    "        # 1dcnn\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = create_1dcnn(X.shape[-1], y.shape[-1], encoder)\n",
    "        model.load_weights(pathlib.Path(f'/kaggle/working/model_{SEED}_{fold}.hdf5'))\n",
    "        models.append(model)\n",
    "        \n",
    "    models = [models[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:50:45.263361Z",
     "iopub.status.busy": "2021-02-18T04:50:45.262628Z",
     "iopub.status.idle": "2021-02-18T04:50:45.266516Z",
     "shell.execute_reply": "2021-02-18T04:50:45.267176Z"
    },
    "papermill": {
     "duration": 3.172661,
     "end_time": "2021-02-18T04:50:45.267363",
     "exception": false,
     "start_time": "2021-02-18T04:50:42.094702",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 s, sys: 0 ns, total: 4 s\n",
      "Wall time: 8.11 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if NN_NAME == 'resnet':\n",
    "    models = []\n",
    "\n",
    "    for fold in range(FOLDS):\n",
    "        tf.keras.backend.clear_session()\n",
    "        model = create_resnet(X.shape[-1], y.shape[-1], encoder)\n",
    "        model.load_weights(pathlib.Path(f'/kaggle/working/model_{SEED}_{fold}.hdf5'))\n",
    "        models.append(model)\n",
    "        \n",
    "    models = [models[-1]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:50:52.205712Z",
     "iopub.status.busy": "2021-02-18T04:50:52.203521Z",
     "iopub.status.idle": "2021-02-18T04:50:52.550985Z",
     "shell.execute_reply": "2021-02-18T04:50:52.550175Z"
    },
    "papermill": {
     "duration": 4.113712,
     "end_time": "2021-02-18T04:50:52.551136",
     "exception": false,
     "start_time": "2021-02-18T04:50:48.437424",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 276 ms, sys: 72.1 ms, total: 348 ms\n",
      "Wall time: 348 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "\n",
    "if NN_NAME == 'mlp':\n",
    "    model = tf.keras.models.load_model('./model.h5')\n",
    "    models = [model]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2021-02-18T04:50:58.904245Z",
     "iopub.status.busy": "2021-02-18T04:50:58.903611Z",
     "iopub.status.idle": "2021-02-18T04:55:17.178664Z",
     "shell.execute_reply": "2021-02-18T04:55:17.178057Z"
    },
    "papermill": {
     "duration": 261.462828,
     "end_time": "2021-02-18T04:55:17.178788",
     "exception": false,
     "start_time": "2021-02-18T04:50:55.715960",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "15219it [04:18, 58.93it/s]\n"
     ]
    }
   ],
   "source": [
    "f = np.median\n",
    "th = 0.500\n",
    "\n",
    "import janestreet\n",
    "env = janestreet.make_env()\n",
    "for (test_df, pred_df) in tqdm(env.iter_test()):\n",
    "    if test_df['weight'].item() > 0:\n",
    "        x_tt = test_df.loc[:, features].values\n",
    "        \n",
    "        # GBDT inference with treelite\n",
    "        batch = treelite_runtime.Batch.from_npy2d(x_tt)\n",
    "        xgb_pred = predictor.predict(batch)\n",
    "    \n",
    "        # NN inference\n",
    "        if np.isnan(x_tt[:, 1:].sum()):\n",
    "            x_tt[:, 1:] = np.nan_to_num(x_tt[:, 1:]) + np.isnan(x_tt[:, 1:]) * f_mean\n",
    "        \n",
    "        pred = np.mean([model(x_tt, training = False).numpy() for model in models],axis=0)\n",
    "        pred = f(pred)\n",
    "        \n",
    "        # ensemble\n",
    "        pred_df.action = np.where(0.9*pred + 0.1*xgb_pred >= th, 1, 0).astype(int)\n",
    "    else:\n",
    "        pred_df.action = 0\n",
    "    env.predict(pred_df)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "papermill": {
   "duration": 2105.71654,
   "end_time": "2021-02-18T04:55:23.092241",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2021-02-18T04:20:17.375701",
   "version": "2.1.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
